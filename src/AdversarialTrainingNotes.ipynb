{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import common libraries\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = \"census.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load\n",
    "\n",
    "dataset_df = pd.read_csv(dataset_file, sep=\",\")\n",
    "\n",
    "# replace -1 with 0 in the label\n",
    "# dataset_df['income_greater_than_50k'][ dataset_df['income_greater_than_50k'] == -1  ] = 0\n",
    "\n",
    "# simulate attacks of len 10\n",
    "attack_lens = [ 10 for i in range(len(dataset_df)//10) ]\n",
    "attack_lens += [len(dataset_df)%10] \n",
    "\n",
    "attack_lens = np.ones(len(dataset_df),dtype=np.int ) \n",
    "\n",
    "train_lgb = lightgbm.Dataset( data  = dataset_df.iloc[:,:-1].values, \n",
    "                              label = dataset_df.iloc[:,-1].values, \n",
    "                              group = attack_lens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our true metric\n",
    "\n",
    "# self-defined eval metric\n",
    "# f(preds: array, train_data: Dataset) -> name: string, value: array, is_higher_better: bool\n",
    "\n",
    "def attack_eval(preds, train_data):\n",
    "    labels      = train_data.get_label()\n",
    "    attack_lens = train_data.get_group()\n",
    "    \n",
    "    norm = 1.0 / float(len(labels))\n",
    "        \n",
    "    exp_loss = lambda h,t: np.log( 1.0 + np.exp(-t*h) )\n",
    "    \n",
    "    sum_max = 0.0\n",
    "    offset = 0\n",
    "    for atk in attack_lens:\n",
    "        losses = [ exp_loss(h,t) for h,t in zip(preds[offset:offset+atk], labels[offset:offset+atk]) ]\n",
    "        sum_max += max(losses)\n",
    "        \n",
    "        offset += atk\n",
    "    \n",
    "    avg_loss = norm * sum_max\n",
    "    \n",
    "    return 'X-adv', avg_loss, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-defined objective function\n",
    "# f(preds: array, train_data: Dataset) -> grad: array, hess: array\n",
    "\n",
    "def attack_grad(preds, train_data):\n",
    "    labels      = train_data.get_label()\n",
    "    attack_lens = train_data.get_group()\n",
    "    e_preds = preds\n",
    "    \n",
    "    grads = np.zeros_like(labels, dtype=np.float64)\n",
    "    hess  = np.zeros_like(grads)\n",
    "\n",
    "    norm = 1.0 / float(len(labels))\n",
    "    \n",
    "    offset = 0\n",
    "    for atk in attack_lens:\n",
    "        inv_sum = 1.0 / np.sum( 1.0 + np.exp(- e_preds[offset:offset+atk] * labels[offset:offset+atk]) )\n",
    "\n",
    "        for x in range(atk):\n",
    "            x_loss = np.exp( - labels[offset+x] * e_preds[offset+x] ) \n",
    "            \n",
    "            x_grad = inv_sum * x_loss\n",
    "            \n",
    "#            print (norm * x_grad * (- labels[offset+x]))\n",
    "            \n",
    "            grads[offset+x] = norm * x_grad * (- labels[offset+x])\n",
    "#            print (x_grad, norm)\n",
    "            \n",
    "            hess[offset+x]  = norm * x_grad * (1.0 - x_grad)\n",
    "            \n",
    "        offset += atk\n",
    "        \n",
    "    return grads, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's X-adv: 0.637024\n",
      "[2]\ttraining's X-adv: 0.591143\n",
      "[3]\ttraining's X-adv: 0.552535\n",
      "[4]\ttraining's X-adv: 0.519896\n",
      "[5]\ttraining's X-adv: 0.49259\n",
      "[6]\ttraining's X-adv: 0.469267\n",
      "[7]\ttraining's X-adv: 0.449134\n",
      "[8]\ttraining's X-adv: 0.431365\n",
      "[9]\ttraining's X-adv: 0.415989\n",
      "[10]\ttraining's X-adv: 0.402811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'training': defaultdict(list,\n",
       "             {'X-adv': [0.6370235022114553,\n",
       "               0.5911428919150238,\n",
       "               0.5525352394904304,\n",
       "               0.519895506290343,\n",
       "               0.4925900377997718,\n",
       "               0.46926737486227543,\n",
       "               0.4491338717819763,\n",
       "               0.4313651191801964,\n",
       "               0.4159888290017059,\n",
       "               0.4028105177822682]})}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 32,\n",
    "    'min_data_in_leaf': 5\n",
    "}    \n",
    "\n",
    "lgbm_info = {}\n",
    "\n",
    "lgbm_model = lightgbm.train( params, train_lgb, num_boost_round=10,\n",
    "                             feval = attack_eval,\n",
    "                             fobj  = attack_grad,\n",
    "                             valid_sets = [train_lgb], \n",
    "                             evals_result = lgbm_info,\n",
    "                             verbose_eval= True )\n",
    "\n",
    "\n",
    "\n",
    "lgbm_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Training a.k.a. fast gradient sign method\n",
    "\n",
    "Paper: \"EXPLAINING AND HARNESSING ADVERSARIAL EXAMPLES\", Ian J. Goodfellow, Jonathon Shlens & Christian Szegedy. ICLR 2015.\n",
    "\n",
    "\n",
    "Method cannot be applied directly.\n",
    "\n",
    "We assume to have in input the attacked datasets, where the first instance of each group is the original one, and the other are the attacks.\n",
    "\n",
    "The method selects just one attack, i.e., the one somehow close to the greatest gradient, i.e., the one causing the greatest loss.\n",
    "\n",
    "The resulting dataset has the same number of original and attacked instances.\n",
    "\n",
    "The process is repeated at each iteration/tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this almost a copy paste from the eval function, not very nice\n",
    "def pointwise_loss(raw_data, raw_labels, raw_groups, model):\n",
    "    \n",
    "    # compute preds on the full attack dataset\n",
    "    preds = model.predict(raw_data)\n",
    "\n",
    "    # logloss\n",
    "    log_loss = lambda h,t: np.log( 1.0 + np.exp(-t*h) )\n",
    "    \n",
    "    # compute loss on every instance\n",
    "    losses = np.array( [ log_loss(h,t) for h,t in zip(preds, raw_labels) ] )\n",
    "\n",
    "    # nomalize (useless)\n",
    "    norm = 1.0 / float(len(raw_labels))\n",
    "    losses = norm * losses\n",
    "    \n",
    "    return losses\n",
    "\n",
    "# crate the (LGBM) adversarial dataset \n",
    "def adv_training(raw_data, raw_labels, raw_groups, model):\n",
    "    \n",
    "    if model==None:\n",
    "        # first iteration, get only original instances\n",
    "        orig_instances = [0] + list( np.cumsum(raw_groups[:-1]) )\n",
    "        new_rows   = raw_data[orig_instances,:]\n",
    "        new_labels = raw_labels[orig_instances]\n",
    "        new_groups = np.ones_like(raw_groups, dtype=np.int)\n",
    "\n",
    "    else:\n",
    "        # compute pointwise losses\n",
    "        losses = pointwise_loss(raw_data, raw_labels, raw_groups, model)\n",
    "        # new instances to be added to the model\n",
    "        new_instances = []\n",
    "        new_groups = []\n",
    "        # iterate groups\n",
    "        offset = 0\n",
    "        for atk in raw_groups:\n",
    "            new_instances += [offset] # keep original\n",
    "            new_groups    += [1]      # one instance in the group\n",
    "            if atk>1:\n",
    "                # get instance with max loss (not including the first in the group)\n",
    "                adv_instance  = np.argmax(losses[offset+1:offset+atk])\n",
    "                new_instances += [adv_instance + 1]\n",
    "                new_groups[-1] = 2    # two instances in the group\n",
    "                \n",
    "            offset += atk\n",
    "\n",
    "        # select relevant rows\n",
    "        new_instances = np.array(new_instances, dtype=np.int) # maybe this speeds up a bit\n",
    "        new_rows   = raw_data[new_instances,:]\n",
    "        new_labels = raw_labels[new_instances]\n",
    "        new_groups = np.array(new_groups, dtype=np.int)\n",
    "\n",
    "    # create the training dataset for LGBM\n",
    "    new_training = lightgbm.Dataset( data  = new_rows, label = new_labels, group = new_groups)\n",
    "    \n",
    "    return new_training\n",
    "\n",
    "# self-defined objective function\n",
    "# f(preds: array, train_data: Dataset) -> grad: array, hess: array\n",
    "\n",
    "def fgsm_grad(preds, train_data):\n",
    "    labels      = train_data.get_label()\n",
    "    \n",
    "    # compute derivative of logistic loss\n",
    "    exp_th = np.exp(preds * labels)\n",
    "    grads = -labels / (1.0 + exp_th) \n",
    "    hess  = exp_th * (1.0 / (1.0 + exp_th)**2 )\n",
    "    \n",
    "    # normalize\n",
    "    norm = 1.0 / float(len(labels))\n",
    "    grads *= norm\n",
    "    hess *= norm\n",
    "        \n",
    "    return grads, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load\n",
    "# !!!! This should load the attacked dataset and not the original one\n",
    "dataset_file = \"census.csv\"\n",
    "dataset_df = pd.read_csv(dataset_file, sep=\",\")\n",
    "\n",
    "# simulate attacks of len 10\n",
    "attack_lens = [ 10 for i in range(len(dataset_df)//10) ]\n",
    "attack_lens += [len(dataset_df)%10] \n",
    "\n",
    "# attack_lens = np.ones(len(dataset_df),dtype=np.int ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree: 1\n",
      "[1]\ttraining's X-adv: 0.635451\n",
      "Tree: 1\n",
      "[2]\ttraining's X-adv: 0.306789\n",
      "Tree: 1\n",
      "[3]\ttraining's X-adv: 0.284487\n",
      "Tree: 1\n",
      "[4]\ttraining's X-adv: 0.266459\n",
      "Tree: 1\n",
      "[5]\ttraining's X-adv: 0.251478\n",
      "Tree: 1\n",
      "[6]\ttraining's X-adv: 0.239128\n",
      "Tree: 1\n",
      "[7]\ttraining's X-adv: 0.228335\n",
      "Tree: 1\n",
      "[8]\ttraining's X-adv: 0.218966\n",
      "Tree: 1\n",
      "[9]\ttraining's X-adv: 0.210484\n",
      "Tree: 1\n",
      "[10]\ttraining's X-adv: 0.203279\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NUM_TREES = 10\n",
    "\n",
    "lgbm_model = None\n",
    "for t in range(NUM_TREES):\n",
    "    print (\"Tree:\", 1)\n",
    "    \n",
    "    # create adversarial dataset\n",
    "    \n",
    "    # dataset_df is something coming from gabriele\n",
    "    # you can avoid dataframes and use original data\n",
    "    adv_train = adv_training( dataset_df.iloc[:,:-1].values, \n",
    "                              dataset_df.iloc[:,-1].values, \n",
    "                              attack_lens, \n",
    "                              lgbm_model)\n",
    "    \n",
    "    \n",
    "    # training params\n",
    "    params = {\n",
    "        'learning_rate': 0.1,\n",
    "        'num_leaves': 32,\n",
    "        'min_data_in_leaf': 5\n",
    "    }    \n",
    "\n",
    "    # training eval stats\n",
    "    lgbm_info = {}\n",
    "\n",
    "    # add a new tree to the previous model \n",
    "    #   by using the new adversarial training dataset\n",
    "    lgbm_model = lightgbm.train( params, adv_train, \n",
    "                                 init_model = lgbm_model,\n",
    "                                 num_boost_round=1,\n",
    "                                 feval = attack_eval,\n",
    "                                 fobj  = fgsm_grad,\n",
    "                                 valid_sets = [adv_train], \n",
    "                                 evals_result = lgbm_info,\n",
    "                                 verbose_eval = True )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
