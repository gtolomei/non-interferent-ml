{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!{sys.executable} -m pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nilib import *\n",
    "\n",
    "#import os\n",
    "#import json\n",
    "#import glob\n",
    "#import pickle\n",
    "import dill\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import lightgbm\n",
    "#import functools\n",
    "import parallel_robust_forest\n",
    "#from os import listdir\n",
    "#from os.path import isfile, join\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix, precision_score, recall_score\n",
    "from nilib import *\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "\n",
    "from mlxtend.evaluate import mcnemar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load attacked datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load an attacked dataset with a specific budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attacked_dataset(DATASET_NAME, budget):\n",
    "    DATASET_DIR=\"../data/{}\".format(DATASET_NAME)\n",
    "    ATK_DIR=DATASET_DIR + \"/attacks\"\n",
    "    TRAINING_FILENAME_ATT=ATK_DIR + \"/\" + \"train_B{}.atks.bz2\"\n",
    "    VALIDATION_FILENAME_ATT=ATK_DIR + \"/\" + \"valid_B{}.atks.bz2\"\n",
    "    TEST_FILENAME_ATT=ATK_DIR + \"/\" + \"test_B{}.atks.bz2\"\n",
    "\n",
    "    # load train/valid/test (attacked)\n",
    "    train_att, valid_att, test_att = load_atk_train_valid_test(TRAINING_FILENAME_ATT.format(budget), \n",
    "                                                                  VALIDATION_FILENAME_ATT.format(budget), \n",
    "                                                                  TEST_FILENAME_ATT.format(budget))\n",
    "\n",
    "    test_groups = test_att['instance_id'].value_counts().sort_index().values\n",
    "    test_att = test_att.iloc[:, 1:]\n",
    "\n",
    "    valid_groups = valid_att['instance_id'].value_counts().sort_index().values\n",
    "    valid_att = valid_att.iloc[:, 1:]\n",
    "\n",
    "    train_groups = train_att['instance_id'].value_counts().sort_index().values\n",
    "    train_att = train_att.iloc[:, 1:]\n",
    "    \n",
    "    return train_att, train_groups, valid_att, valid_groups, test_att, test_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Eval Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_file):\n",
    "    model = None\n",
    "    try:\n",
    "        model = lightgbm.Booster(model_file=model_file)\n",
    "    except:\n",
    "        print(\"LightGBM loading exception\")\n",
    "        try:\n",
    "            with open(model_file, 'rb') as mf:\n",
    "                model = dill.load(mf)\n",
    "                print(model)\n",
    "                model.n_jobs = 16\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Dill loading exception\")\n",
    "            pass\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(preds):\n",
    "    if np.min(preds)<-0.001:\n",
    "        return np.where(preds>=0,  1.0, -1.0)\n",
    "    else:\n",
    "        return np.where(preds>=.5, 1.0, -1.0)\n",
    "    \n",
    "def model_predict(model,test_set):\n",
    "    X = test_set.iloc[:,:-1].values\n",
    "\n",
    "    if isinstance(model, BaggingClassifier):\n",
    "        return model.predict_proba(X)[:,1]\n",
    "    else:\n",
    "        return model.predict(test_set.iloc[:,:-1])\n",
    "\n",
    "def model_worst_predict(model, test_set, test_groups):\n",
    "    labels = test_set.iloc[:,-1].values\n",
    "    preds  = model_predict(model, test_set)\n",
    "    \n",
    "    offset = 0\n",
    "    true_labels = []\n",
    "    worst_predictions = []\n",
    "    \n",
    "    for g in test_groups:\n",
    "        true_label = labels[offset]\n",
    "        true_labels.append(true_label)\n",
    "        predictions_att = preds[offset:offset+g]\n",
    "        if true_label == 1:\n",
    "            worst_predictions.append(np.min(predictions_att))\n",
    "        else:\n",
    "            worst_predictions.append(np.max(predictions_att))\n",
    "    \n",
    "        offset += g\n",
    "\n",
    "    return np.array(true_labels), np.array(worst_predictions)\n",
    "\n",
    "def eval_model_ua(model, test, test_groups):\n",
    "    y_true, y_pred = model_worst_predict(model, test, test_groups)\n",
    "    y_pred = binarize(y_pred)\n",
    "    \n",
    "    correct_preds = y_true == y_pred\n",
    "    correct_preds = correct_preds.astype(int)\n",
    "    \n",
    "    return correct_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# McNemar Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcnemar_test(robust_model, base_model,\n",
    "                 test_set, test_set_groups):\n",
    "    \n",
    "    our_model = load_model(robust_model)\n",
    "    ref_model = load_model(base_model)\n",
    "\n",
    "    our_model_correct = eval_model_ua(our_model, test_set, test_set_groups)\n",
    "    ref_model_correct = eval_model_ua(ref_model, test_set, test_set_groups)\n",
    "\n",
    "    contingency_matrix = np.array( [ [np.sum(our_model_correct*ref_model_correct), \n",
    "                                        np.sum((1-our_model_correct)*ref_model_correct)],\n",
    "                                     [np.sum((our_model_correct)*(1-ref_model_correct)),\n",
    "                                        np.sum((1-our_model_correct)*(1-ref_model_correct))] \n",
    "                                   ])\n",
    "\n",
    "    print(contingency_matrix)\n",
    "\n",
    "    chi2, p = mcnemar(ary=contingency_matrix, corrected=True)\n",
    "\n",
    "    print('chi-squared:', chi2)\n",
    "    print('p-value:', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing original files...\n",
      "Loading: ../data/wine/attacks/train_B20.atks.bz2\n",
      "Loading: ../data/wine/attacks/valid_B20.atks.bz2\n",
      "Loading: ../data/wine/attacks/test_B20.atks.bz2\n",
      "Train/Valid/Test sizes: (21361, 14) (2933, 14) (6176, 14)\n",
      "Train/Valid/Test split: 0.70 0.10 0.20\n",
      "   ... with instance ids\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (18278, 14) (6016, 14) (6176, 14)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "Saving processed files *.atks.bz2\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(affine=None, attacker=None,\n",
      "                                                    feature_blacklist={},\n",
      "                                                    max_depth=8,\n",
      "                                                    max_features=0.8,\n",
      "                                                    max_samples=0.8,\n",
      "                                                    min_instances_per_node=20,\n",
      "                                                    replace_features=False,\n",
      "                                                    replace_samples=False,\n",
      "                                                    seed=0,\n",
      "                                                    split_optimizer=None,\n",
      "                                                    tree_id=0),\n",
      "                  bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "                  max_samples=1.0, n_estimators=20, n_jobs=None,\n",
      "                  oob_score=False, random_state=None, verbose=0,\n",
      "                  warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.20.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[908  83]\n",
      " [ 74 235]]\n",
      "chi-squared: 0.40764331210191085\n",
      "p-value: 0.5231680971364009\n",
      "Pre-processing original files...\n",
      "Loading: ../data/wine/attacks/train_B40.atks.bz2\n",
      "Loading: ../data/wine/attacks/valid_B40.atks.bz2\n",
      "Loading: ../data/wine/attacks/test_B40.atks.bz2\n",
      "Train/Valid/Test sizes: (72409, 14) (10145, 14) (20817, 14)\n",
      "Train/Valid/Test split: 0.70 0.10 0.20\n",
      "   ... with instance ids\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (61947, 14) (20607, 14) (20817, 14)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "Saving processed files *.atks.bz2\n",
      "LightGBM loading exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.20.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=RobustDecisionTree(affine=None, attacker=None,\n",
      "                                                    feature_blacklist={},\n",
      "                                                    max_depth=8,\n",
      "                                                    max_features=0.8,\n",
      "                                                    max_samples=0.8,\n",
      "                                                    min_instances_per_node=20,\n",
      "                                                    replace_features=False,\n",
      "                                                    replace_samples=False,\n",
      "                                                    seed=0,\n",
      "                                                    split_optimizer=None,\n",
      "                                                    tree_id=0),\n",
      "                  bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "                  max_samples=1.0, n_estimators=100, n_jobs=None,\n",
      "                  oob_score=False, random_state=None, verbose=0,\n",
      "                  warm_start=False)\n",
      "[[874  66]\n",
      " [112 248]]\n",
      "chi-squared: 11.376404494382022\n",
      "p-value: 0.000743829600416684\n",
      "Pre-processing original files...\n",
      "Loading: ../data/wine/attacks/train_B60.atks.bz2\n",
      "Loading: ../data/wine/attacks/valid_B60.atks.bz2\n",
      "Loading: ../data/wine/attacks/test_B60.atks.bz2\n",
      "Train/Valid/Test sizes: (300592, 14) (40873, 14) (87644, 14)\n",
      "Train/Valid/Test split: 0.70 0.10 0.20\n",
      "   ... with instance ids\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (257182, 14) (84283, 14) (87644, 14)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "Saving processed files *.atks.bz2\n",
      "LightGBM loading exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.20.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=RobustDecisionTree(affine=None, attacker=None,\n",
      "                                                    feature_blacklist={},\n",
      "                                                    max_depth=8,\n",
      "                                                    max_features=0.8,\n",
      "                                                    max_samples=0.8,\n",
      "                                                    min_instances_per_node=20,\n",
      "                                                    replace_features=False,\n",
      "                                                    replace_samples=False,\n",
      "                                                    seed=0,\n",
      "                                                    split_optimizer=None,\n",
      "                                                    tree_id=0),\n",
      "                  bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "                  max_samples=1.0, n_estimators=100, n_jobs=None,\n",
      "                  oob_score=False, random_state=None, verbose=0,\n",
      "                  warm_start=False)\n",
      "[[885  49]\n",
      " [ 88 278]]\n",
      "chi-squared: 10.540145985401459\n",
      "p-value: 0.001168091930950677\n",
      "Pre-processing original files...\n",
      "Loading: ../data/wine/attacks/train_B80.atks.bz2\n",
      "Loading: ../data/wine/attacks/valid_B80.atks.bz2\n",
      "Loading: ../data/wine/attacks/test_B80.atks.bz2\n",
      "Train/Valid/Test sizes: (782368, 14) (104000, 14) (229891, 14)\n",
      "Train/Valid/Test split: 0.70 0.09 0.21\n",
      "   ... with instance ids\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (669296, 14) (217072, 14) (229891, 14)\n",
      "Train/Valid/Test split: 0.60 0.19 0.21\n",
      "Saving processed files *.atks.bz2\n",
      "LightGBM loading exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.20.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=RobustDecisionTree(affine=None, attacker=None,\n",
      "                                                    feature_blacklist={},\n",
      "                                                    max_depth=8,\n",
      "                                                    max_features=0.8,\n",
      "                                                    max_samples=0.8,\n",
      "                                                    min_instances_per_node=20,\n",
      "                                                    replace_features=False,\n",
      "                                                    replace_samples=False,\n",
      "                                                    seed=0,\n",
      "                                                    split_optimizer=None,\n",
      "                                                    tree_id=0),\n",
      "                  bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "                  max_samples=1.0, n_estimators=100, n_jobs=None,\n",
      "                  oob_score=False, random_state=None, verbose=0,\n",
      "                  warm_start=False)\n",
      "[[883  46]\n",
      " [ 99 272]]\n",
      "chi-squared: 18.648275862068967\n",
      "p-value: 1.5718935652564088e-05\n",
      "Pre-processing original files...\n",
      "Loading: ../data/wine/attacks/train_B100.atks.bz2\n",
      "Loading: ../data/wine/attacks/valid_B100.atks.bz2\n",
      "Loading: ../data/wine/attacks/test_B100.atks.bz2\n",
      "Train/Valid/Test sizes: (1465269, 14) (196232, 14) (430155, 14)\n",
      "Train/Valid/Test split: 0.70 0.09 0.21\n",
      "   ... with instance ids\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (1253941, 14) (407560, 14) (430155, 14)\n",
      "Train/Valid/Test split: 0.60 0.19 0.21\n",
      "Saving processed files *.atks.bz2\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(affine=None, attacker=None,\n",
      "                                                    feature_blacklist={},\n",
      "                                                    max_depth=8,\n",
      "                                                    max_features=0.8,\n",
      "                                                    max_samples=0.8,\n",
      "                                                    min_instances_per_node=20,\n",
      "                                                    replace_features=False,\n",
      "                                                    replace_samples=False,\n",
      "                                                    seed=0,\n",
      "                                                    split_optimizer=None,\n",
      "                                                    tree_id=0),\n",
      "                  bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "                  max_samples=1.0, n_estimators=20, n_jobs=None,\n",
      "                  oob_score=False, random_state=None, verbose=0,\n",
      "                  warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.20.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[865  47]\n",
      " [104 284]]\n",
      "chi-squared: 20.7682119205298\n",
      "p-value: 5.183626513798672e-06\n",
      "Pre-processing original files...\n",
      "Loading: ../data/wine/attacks/train_B120.atks.bz2\n",
      "Loading: ../data/wine/attacks/valid_B120.atks.bz2\n",
      "Loading: ../data/wine/attacks/test_B120.atks.bz2\n",
      "Train/Valid/Test sizes: (2722930, 14) (362407, 14) (805753, 14)\n",
      "Train/Valid/Test split: 0.70 0.09 0.21\n",
      "   ... with instance ids\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (2330524, 14) (754813, 14) (805753, 14)\n",
      "Train/Valid/Test split: 0.60 0.19 0.21\n",
      "Saving processed files *.atks.bz2\n",
      "LightGBM loading exception\n",
      "[Errno 2] No such file or directory: '../out/models/wine/par-robust_wine_L-sse_B120_T20_D8_I20.model'\n",
      "Dill loading exception\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-948cfc31cea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Incorrect groups\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mmcnemar_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrobust_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-b16287588707>\u001b[0m in \u001b[0;36mmcnemar_test\u001b[0;34m(robust_model, base_model, test_set, test_set_groups)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mref_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mour_model_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model_ua\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mour_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mref_model_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model_ua\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-375fb8ff0f1a>\u001b[0m in \u001b[0;36meval_model_ua\u001b[0;34m(model, test, test_groups)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0meval_model_ua\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_worst_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-375fb8ff0f1a>\u001b[0m in \u001b[0;36mmodel_worst_predict\u001b[0;34m(model, test_set, test_groups)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_worst_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mpreds\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmodel_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-375fb8ff0f1a>\u001b[0m in \u001b[0;36mmodel_predict\u001b[0;34m(model, test_set)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_worst_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "DATASET_NAME=\"wine\"\n",
    "\n",
    "# Final Models\n",
    "robust_models = [\"../out/models/wine/par-robust_wine_L-sse_B20_T20_D8_I20.model\",  # 20 Trees\n",
    "                 \"../out/models/wine/par-robust_wine_L-sse_B40_T100_D8_I20.model\",\n",
    "                 \"../out/models/wine/par-robust_wine_L-sse_B60_T100_D8_I20.model\",\n",
    "                 \"../out/models/wine/par-robust_wine_L-sse_B80_T100_D8_I20.model\",\n",
    "                 \"../out/models/wine/par-robust_wine_L-sse_B100_T20_D8_I20.model\", # 20 Trees\n",
    "                 \"../out/models/wine/par-robust_wine_L-sse_B120_T20_D8_I20.model\", # MISSINGS\n",
    "                ]\n",
    "\n",
    "base_models =   [  \"../out/models/wine/adv-boosting_wine_B20_T100_S0050_L256_R99.model\",\n",
    "                   \"../out/models/wine/adv-boosting_wine_B40_T100_S0050_L256_R100.model\",\n",
    "                   \"../out/models/wine/adv-boosting_wine_B60_T100_S0050_L256_R99.model\",\n",
    "                   \"../out/models/wine/adv-boosting_wine_B80_T100_S0050_L256_R100.model\",\n",
    "                   \"../out/models/wine/adv-boosting_wine_B100_T100_S0050_L256_R100.model\",\n",
    "                   \"../out/models/wine/adv-boosting_wine_B120_T100_S0050_L256_R100.model\"\n",
    "             ]\n",
    "\n",
    "budgets = [20,40,60,80,100,120]\n",
    "\n",
    "for budget, robust_model, base_model in zip(budgets, robust_models, base_models):\n",
    "\n",
    "    _,_,_,_, test_set, test_set_groups = load_attacked_dataset(DATASET_NAME, budget)\n",
    "    assert len(test_set)==np.sum(test_set_groups), \"Incorrect groups\"\n",
    "    \n",
    "    mcnemar_test(robust_model, base_model, test_set, test_set_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing original files...\n",
      "Loading: ../data/credit/attacks/train_B40.atks.bz2\n",
      "Loading: ../data/credit/attacks/valid_B40.atks.bz2\n",
      "Loading: ../data/credit/attacks/test_B40.atks.bz2\n",
      "Train/Valid/Test sizes: (1650064, 25) (509022, 25) (506132, 25)\n",
      "Train/Valid/Test split: 0.62 0.19 0.19\n",
      "   ... with instance ids\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (1650064, 25) (509022, 25) (506132, 25)\n",
      "Train/Valid/Test split: 0.62 0.19 0.19\n",
      "Saving processed files *.atks.bz2\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(affine=None, attacker=None,\n",
      "                                                    feature_blacklist={},\n",
      "                                                    max_depth=8,\n",
      "                                                    max_features=0.8,\n",
      "                                                    max_samples=0.8,\n",
      "                                                    min_instances_per_node=20,\n",
      "                                                    replace_features=False,\n",
      "                                                    replace_samples=False,\n",
      "                                                    seed=0,\n",
      "                                                    split_optimizer=None,\n",
      "                                                    tree_id=0),\n",
      "                  bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "                  max_samples=1.0, n_estimators=100, n_jobs=None,\n",
      "                  oob_score=False, random_state=None, verbose=0,\n",
      "                  warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.20.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME=\"credit\"\n",
    "\n",
    "# Final Models\n",
    "robust_models = [#\"../out/models/credit/par-robust_credit_B10_T100_D8_I20.model\",\n",
    "                 #\"../out/models/credit/par-robust_credit_B30_T100_D8_I20.model\",\n",
    "                 \"../out/models/credit/par-robust_credit_B40_T100_D8_I20.model\",\n",
    "                 \"../out/models/credit/par-robust_credit_B60_T100_D8_I20.model\"\n",
    "                 #\"../out/models/credit/par-robust_credit_L-sse_B60_T100_D8_I20.model\"\n",
    "                ]\n",
    "\n",
    "base_models = [#\"../out/models/credit/adv-boosting_credit_B10_T100_S0050_L256_R56.model\",\n",
    "               #\"../out/models/credit/adv-boosting_credit_B30_T100_S0050_L256_R40.model\",\n",
    "               \"../out/models/credit/adv-boosting_credit_B40_T100_S0050_L256_R56.model\",              \n",
    "               \"../out/models/credit/adv-boosting_credit_B60_T100_S0050_L256_R50.model\"\n",
    "              ]\n",
    "\n",
    "budgets = [40,60]#[10,30,40,60]\n",
    "\n",
    "for budget, robust_model, base_model in zip(budgets, robust_models, base_models):\n",
    "\n",
    "    _,_,_,_, test_set, test_set_groups = load_attacked_dataset(DATASET_NAME, budget)\n",
    "    assert len(test_set)==np.sum(test_set_groups), \"Incorrect groups\"\n",
    "    \n",
    "    mcnemar_test(robust_model, base_model, test_set, test_set_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CENSUS 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"census\"\n",
    "budget = 120\n",
    "robust_model = \"../out/models/census/par-robust_census_B120_T100_D8_I20.model\"\n",
    "base_model   = \"../out/models/census/adv-boosting_census_B120_T100_S0050_L256_R94.model\"\n",
    "\n",
    "_,_,_,_, test_set, test_set_groups = load_attacked_dataset(DATASET_NAME, budget)\n",
    "assert len(test_set)==np.sum(test_set_groups), \"Incorrect groups\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcnemar_test(robust_model, base_model, test_set, test_set_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CENSUS 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME  = \"census\"\n",
    "budget        = 90\n",
    "robust_model  = \"../out/models/census/par-robust_census_B90_T100_D8_I20.model\"\n",
    "base_model    = \"../out/models/census/adv-boosting_census_B90_T100_S0050_L256_R98.model\"\n",
    "\n",
    "_,_,_,_, test_set, test_set_groups = load_attacked_dataset(DATASET_NAME, budget)\n",
    "assert len(test_set)==np.sum(test_set_groups), \"Incorrect groups\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcnemar_test(robust_model, base_model, test_set, test_set_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CENSUS 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME  = \"census\"\n",
    "budget        = 60\n",
    "robust_model  = \"../out/models/census/par-robust_census_B60_T100_D8_I20.model\"\n",
    "base_model    = \"../out/models/census/icml2019_census_B60_T100_D8_I20.model\"\n",
    "\n",
    "_,_,_,_, test_set, test_set_groups = load_attacked_dataset(DATASET_NAME, budget)\n",
    "assert len(test_set)==np.sum(test_set_groups), \"Incorrect groups\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcnemar_test(robust_model, base_model, test_set, test_set_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CENSUS 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME  = \"census\"\n",
    "budget        = 30\n",
    "robust_model  = \"../out/models/census/par-robust_census_B30_T100_D8_I20.model\"\n",
    "base_model    = \"../out/models/census/adv-boosting_census_B30_T100_S0050_L256_R100.model\"\n",
    "\n",
    "_,_,_,_, test_set, test_set_groups = load_attacked_dataset(DATASET_NAME, budget)\n",
    "assert len(test_set)==np.sum(test_set_groups), \"Incorrect groups\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcnemar_test(robust_model, base_model, test_set, test_set_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
