{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBDT - LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm\n",
    "import pickle\n",
    "import json\n",
    "import functools\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from nilib import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path to dataset files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"wine\" # wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR=\"../data/{}\".format(DATASET_NAME)\n",
    "MODELS_DIR=\"../out/models/{}\".format(DATASET_NAME)\n",
    "TRAINING_FILENAME=DATASET_DIR + \"/\" + \"train_ori.csv.bz2\"\n",
    "VALIDATION_FILENAME=DATASET_DIR + \"/\" + \"valid_ori.csv.bz2\"\n",
    "TEST_FILENAME=DATASET_DIR + \"/\" + \"test_ori.csv.bz2\"\n",
    "MODEL_FILENAME=MODELS_DIR + \"/std-gbdt_{}\".format(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gradient_boosting_baseline(train_file, valid_file, test_file, output_model_file):\n",
    "    \n",
    "    exp = pd.DataFrame(columns=['num_trees', 'learning_rate', 'num_leaves', 'best_round', 'metric', 'filename'])\n",
    "    \n",
    "    # load train/valid/test\n",
    "    train, valid, test, cat_fx = load_atk_train_valid_test(train_file, valid_file, test_file)\n",
    "    \n",
    "    assert \"instance_id\" not in train.columns.values, \"Wrong training set file for GBDT\"\n",
    "\n",
    "    # get index of categorical features \n",
    "    cat_fx = np.where(train.columns.isin(cat_fx))[0]\n",
    "    cat_fx = list([int(x) for x in cat_fx])  \n",
    "    print(\"CatFX:\", train.columns.values[cat_fx])\n",
    "    \n",
    "\n",
    "    for num_trees in [200]:\n",
    "        for learning_rate in [0.01, 0.05, 0.1]:\n",
    "            for num_leaves in [8, 16, 24]:\n",
    "                # datasets\n",
    "                lgbm_train = lightgbm.Dataset(data=train.iloc[:,:-1].values, \n",
    "                                              label=train.iloc[:,-1].values,\n",
    "                                              categorical_feature = cat_fx)\n",
    "\n",
    "                lgbm_valid = lightgbm.Dataset(data=valid.iloc[:,:-1].values, \n",
    "                                              label=valid.iloc[:,-1].values,\n",
    "                                              categorical_feature = cat_fx)\n",
    "\n",
    "                # run train\n",
    "                lgbm_params = { 'learning_rate': learning_rate, \n",
    "                                'num_leaves': num_leaves} \n",
    "                lgbm_info = {}\n",
    "                lgbm_model = lightgbm.train(lgbm_params, lgbm_train, \n",
    "                                            num_boost_round = num_trees,\n",
    "                                            fobj            = optimize_log_loss, \n",
    "                                            feval           = avg_log_loss,\n",
    "                                            evals_result    = lgbm_info,\n",
    "                                            valid_sets      = [lgbm_train, lgbm_valid], \n",
    "                                            valid_names     = ['train', 'valid'],\n",
    "                                            verbose_eval    = 50)\n",
    "                \n",
    "                best_valid_iter = np.argmin(lgbm_info['valid']['avg_binary_log_loss'])\n",
    "                \n",
    "                model_file_name = \"{:s}_T{:d}_S{:04d}_L{:d}_R{:d}.model\".format(output_model_file,\n",
    "                                                                            num_trees,\n",
    "                                                                            int(learning_rate*1000),\n",
    "                                                                            num_leaves,\n",
    "                                                                            best_valid_iter + 1\n",
    "                                                                           )\n",
    "                \n",
    "                # update experimental results\n",
    "                exp = exp.append({'num_trees': num_trees, \n",
    "                                  'learning_rate':learning_rate,\n",
    "                                  'num_leaves':num_leaves, \n",
    "                                  'best_round':best_valid_iter+1, \n",
    "                                  'metric':lgbm_info['valid']['avg_binary_log_loss'][best_valid_iter],\n",
    "                                  'filename':model_file_name},\n",
    "                                 ignore_index=True)\n",
    "                \n",
    "        \n",
    "                lgbm_model.save_model(model_file_name)\n",
    "                print(\"Model saved to\", model_file_name)\n",
    "\n",
    "    \n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-processed files...\n",
      "CatFX: []\n",
      "[50]\ttrain's avg_binary_log_loss: 0.592468\tvalid's avg_binary_log_loss: 0.597697\n",
      "[100]\ttrain's avg_binary_log_loss: 0.543457\tvalid's avg_binary_log_loss: 0.551507\n",
      "[150]\ttrain's avg_binary_log_loss: 0.516441\tvalid's avg_binary_log_loss: 0.527646\n",
      "[200]\ttrain's avg_binary_log_loss: 0.498774\tvalid's avg_binary_log_loss: 0.513444\n",
      "Model saved to ../out/models/wine/std-gbdt_wine_T200_S0010_L8_R200.model\n",
      "[50]\ttrain's avg_binary_log_loss: 0.578771\tvalid's avg_binary_log_loss: 0.590698\n",
      "[100]\ttrain's avg_binary_log_loss: 0.522085\tvalid's avg_binary_log_loss: 0.53955\n",
      "[150]\ttrain's avg_binary_log_loss: 0.489238\tvalid's avg_binary_log_loss: 0.51091\n",
      "[200]\ttrain's avg_binary_log_loss: 0.467173\tvalid's avg_binary_log_loss: 0.494643\n",
      "Model saved to ../out/models/wine/std-gbdt_wine_T200_S0010_L16_R200.model\n",
      "[50]\ttrain's avg_binary_log_loss: 0.569699\tvalid's avg_binary_log_loss: 0.583678\n",
      "[100]\ttrain's avg_binary_log_loss: 0.506591\tvalid's avg_binary_log_loss: 0.529356\n",
      "[150]\ttrain's avg_binary_log_loss: 0.468617\tvalid's avg_binary_log_loss: 0.499162\n",
      "[200]\ttrain's avg_binary_log_loss: 0.442704\tvalid's avg_binary_log_loss: 0.481114\n",
      "Model saved to ../out/models/wine/std-gbdt_wine_T200_S0010_L24_R200.model\n",
      "[50]\ttrain's avg_binary_log_loss: 0.484098\tvalid's avg_binary_log_loss: 0.502343\n",
      "[100]\ttrain's avg_binary_log_loss: 0.445264\tvalid's avg_binary_log_loss: 0.474934\n",
      "[150]\ttrain's avg_binary_log_loss: 0.423226\tvalid's avg_binary_log_loss: 0.462973\n",
      "[200]\ttrain's avg_binary_log_loss: 0.405289\tvalid's avg_binary_log_loss: 0.456145\n",
      "Model saved to ../out/models/wine/std-gbdt_wine_T200_S0050_L8_R199.model\n",
      "[50]\ttrain's avg_binary_log_loss: 0.447972\tvalid's avg_binary_log_loss: 0.482545\n",
      "[100]\ttrain's avg_binary_log_loss: 0.392844\tvalid's avg_binary_log_loss: 0.451099\n",
      "[150]\ttrain's avg_binary_log_loss: 0.357536\tvalid's avg_binary_log_loss: 0.436771\n",
      "[200]\ttrain's avg_binary_log_loss: 0.330664\tvalid's avg_binary_log_loss: 0.42903\n",
      "Model saved to ../out/models/wine/std-gbdt_wine_T200_S0050_L16_R199.model\n",
      "[50]\ttrain's avg_binary_log_loss: 0.421346\tvalid's avg_binary_log_loss: 0.471161\n",
      "[100]\ttrain's avg_binary_log_loss: 0.3532\tvalid's avg_binary_log_loss: 0.438746\n",
      "[150]\ttrain's avg_binary_log_loss: 0.309357\tvalid's avg_binary_log_loss: 0.427987\n",
      "[200]\ttrain's avg_binary_log_loss: 0.274847\tvalid's avg_binary_log_loss: 0.424057\n",
      "Model saved to ../out/models/wine/std-gbdt_wine_T200_S0050_L24_R200.model\n",
      "[50]\ttrain's avg_binary_log_loss: 0.445722\tvalid's avg_binary_log_loss: 0.479627\n",
      "[100]\ttrain's avg_binary_log_loss: 0.404691\tvalid's avg_binary_log_loss: 0.462285\n",
      "[150]\ttrain's avg_binary_log_loss: 0.372611\tvalid's avg_binary_log_loss: 0.450055\n",
      "[200]\ttrain's avg_binary_log_loss: 0.348249\tvalid's avg_binary_log_loss: 0.443143\n",
      "Model saved to ../out/models/wine/std-gbdt_wine_T200_S0100_L8_R200.model\n",
      "[50]\ttrain's avg_binary_log_loss: 0.392793\tvalid's avg_binary_log_loss: 0.451511\n",
      "[100]\ttrain's avg_binary_log_loss: 0.330813\tvalid's avg_binary_log_loss: 0.431629\n",
      "[150]\ttrain's avg_binary_log_loss: 0.285001\tvalid's avg_binary_log_loss: 0.421283\n",
      "[200]\ttrain's avg_binary_log_loss: 0.247945\tvalid's avg_binary_log_loss: 0.415696\n",
      "Model saved to ../out/models/wine/std-gbdt_wine_T200_S0100_L16_R200.model\n",
      "[50]\ttrain's avg_binary_log_loss: 0.354496\tvalid's avg_binary_log_loss: 0.443266\n",
      "[100]\ttrain's avg_binary_log_loss: 0.276477\tvalid's avg_binary_log_loss: 0.421581\n",
      "[150]\ttrain's avg_binary_log_loss: 0.222437\tvalid's avg_binary_log_loss: 0.418188\n",
      "[200]\ttrain's avg_binary_log_loss: 0.18419\tvalid's avg_binary_log_loss: 0.416054\n",
      "Model saved to ../out/models/wine/std-gbdt_wine_T200_S0100_L24_R185.model\n",
      "  num_trees  learning_rate num_leaves best_round  avg_binary_log_loss  \\\n",
      "0       200           0.01          8        200             0.513444   \n",
      "1       200           0.01         16        200             0.494643   \n",
      "2       200           0.01         24        200             0.481114   \n",
      "3       200           0.05          8        199             0.456109   \n",
      "4       200           0.05         16        199             0.429011   \n",
      "5       200           0.05         24        200             0.424057   \n",
      "6       200           0.10          8        200             0.443143   \n",
      "7       200           0.10         16        200             0.415696   \n",
      "8       200           0.10         24        185             0.414575   \n",
      "\n",
      "                                            filename  \n",
      "0  ../out/models/wine/std-gbdt_wine_T200_S0010_L8...  \n",
      "1  ../out/models/wine/std-gbdt_wine_T200_S0010_L1...  \n",
      "2  ../out/models/wine/std-gbdt_wine_T200_S0010_L2...  \n",
      "3  ../out/models/wine/std-gbdt_wine_T200_S0050_L8...  \n",
      "4  ../out/models/wine/std-gbdt_wine_T200_S0050_L1...  \n",
      "5  ../out/models/wine/std-gbdt_wine_T200_S0050_L2...  \n",
      "6  ../out/models/wine/std-gbdt_wine_T200_S0100_L8...  \n",
      "7  ../out/models/wine/std-gbdt_wine_T200_S0100_L1...  \n",
      "8  ../out/models/wine/std-gbdt_wine_T200_S0100_L2...  \n",
      "best model is: ../out/models/wine/std-gbdt_wine_T200_S0100_L24_R185.model\n"
     ]
    }
   ],
   "source": [
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               MODEL_FILENAME\n",
    "                                              )  \n",
    "\n",
    "experiments.to_csv(MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
