{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBDT - LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm\n",
    "import pickle\n",
    "import json\n",
    "import functools\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from nilib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gradient_boosting_baseline(train_file, valid_file, test_file, output_model_file, \n",
    "                                     drop_cols=None, random_forest = False):\n",
    "    \n",
    "    exp = pd.DataFrame(columns=['num_trees', 'learning_rate', 'num_leaves', 'best_round', 'metric', 'filename'])\n",
    "    \n",
    "    # load train/valid/test\n",
    "    train, valid, test = load_atk_train_valid_test(train_file, valid_file, test_file)\n",
    "    \n",
    "    assert \"instance_id\" not in train.columns.values, \"Wrong training set file for GBDT\"\n",
    "\n",
    "    # dropping some of the columns\n",
    "    if drop_cols is not None:\n",
    "        print (\"Dropping columns:\", drop_cols)\n",
    "        train.drop(columns=drop_cols, inplace=True)\n",
    "        valid.drop(columns=drop_cols, inplace=True)\n",
    "        test.drop(columns=drop_cols, inplace=True)\n",
    "    \n",
    "\n",
    "    for num_trees in [100]:\n",
    "        for learning_rate in [0.05]: #[0.01, 0.05]:\n",
    "            for num_leaves in [2**8]: #[16, 24]:\n",
    "                # datasets\n",
    "                lgbm_train = lightgbm.Dataset(data=train.iloc[:,:-1], \n",
    "                                              label=train.iloc[:,-1])\n",
    "\n",
    "                lgbm_valid = lightgbm.Dataset(data=valid.iloc[:,:-1], \n",
    "                                              label=valid.iloc[:,-1])\n",
    "\n",
    "                # run train\n",
    "                lgbm_params = { 'learning_rate': learning_rate, \n",
    "                                'num_leaves': num_leaves,\n",
    "                                'max_depth': 8,\n",
    "                                'objective': 'regression'\n",
    "                              } \n",
    "                if random_forest:\n",
    "                    lgbm_params['boosting'] = 'rf'\n",
    "                    lgbm_params['bagging_fraction'] = 0.8\n",
    "                    lgbm_params['feature_fraction' ] = 0.8\n",
    "                    lgbm_params['bagging_freq'] = 1\n",
    "\n",
    "                lgbm_info = {}\n",
    "                lgbm_model = lightgbm.train(lgbm_params, lgbm_train, \n",
    "                                            num_boost_round = num_trees,\n",
    "#                                             fobj            = optimize_log_loss, \n",
    "#                                             feval           = avg_log_loss,\n",
    "                                            evals_result    = lgbm_info,\n",
    "                                            valid_sets      = [lgbm_train, lgbm_valid], \n",
    "                                            valid_names     = ['train', 'valid'],\n",
    "                                            verbose_eval    = 10)\n",
    "                \n",
    "                best_valid_iter = np.argmin(lgbm_info['valid']['l2'])\n",
    "                \n",
    "                model_file_name = \"{:s}_T{:d}_S{:04d}_L{:d}_R{:d}.model\".format(output_model_file,\n",
    "                                                                            num_trees,\n",
    "                                                                            int(learning_rate*1000),\n",
    "                                                                            num_leaves,\n",
    "                                                                            best_valid_iter + 1\n",
    "                                                                           )\n",
    "                \n",
    "                # update experimental results\n",
    "                exp = exp.append({'num_trees': num_trees, \n",
    "                                  'learning_rate':learning_rate,\n",
    "                                  'num_leaves':num_leaves, \n",
    "                                  'best_round':best_valid_iter+1, \n",
    "                                  'metric':lgbm_info['valid']['l2'][best_valid_iter],\n",
    "                                  'filename':model_file_name},\n",
    "                                 ignore_index=True)\n",
    "                \n",
    "        \n",
    "                lgbm_model.save_model(model_file_name)\n",
    "                print(\"Model saved to\", model_file_name)\n",
    "    \n",
    "    return exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WINE Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"wine\"\n",
    "DATASET_DIR=\"../data/{}\".format(DATASET_NAME)\n",
    "ATK_DIR=DATASET_DIR + \"/attacks\"\n",
    "MODELS_DIR=\"../out/models/{}\".format(DATASET_NAME)\n",
    "TRAINING_FILENAME=DATASET_DIR + \"/\" + \"train.csv.bz2\"\n",
    "VALIDATION_FILENAME=DATASET_DIR + \"/\" + \"valid.csv.bz2\"\n",
    "TEST_FILENAME=DATASET_DIR + \"/\" + \"test.csv.bz2\"\n",
    "MODEL_FILENAME=MODELS_DIR + \"/std-gbdt_{}\".format(DATASET_NAME)\n",
    "RED_MODEL_FILENAME=MODELS_DIR + \"/red-gbdt_{}\".format(DATASET_NAME)\n",
    "RF_MODEL_FILENAME=MODELS_DIR + \"/rf-gbdt_{}\".format(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing original files...\n",
      "Loading: ../data/wine/train.csv.bz2\n",
      "Loading: ../data/wine/valid.csv.bz2\n",
      "Loading: ../data/wine/test.csv.bz2\n",
      "Train/Valid/Test sizes: (4547, 13) (650, 13) (1300, 13)\n",
      "Train/Valid/Test split: 0.70 0.10 0.20\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (3898, 13) (1299, 13) (1300, 13)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "Saving processed files *.atks.bz2\n",
      "[10]\ttrain's l2: 0.658938\tvalid's l2: 0.73916\n",
      "[20]\ttrain's l2: 0.527671\tvalid's l2: 0.660676\n",
      "[30]\ttrain's l2: 0.451371\tvalid's l2: 0.624959\n",
      "[40]\ttrain's l2: 0.407846\tvalid's l2: 0.609611\n",
      "[50]\ttrain's l2: 0.371556\tvalid's l2: 0.598689\n",
      "[60]\ttrain's l2: 0.34594\tvalid's l2: 0.593508\n",
      "[70]\ttrain's l2: 0.331191\tvalid's l2: 0.58887\n",
      "[80]\ttrain's l2: 0.317604\tvalid's l2: 0.585445\n",
      "[90]\ttrain's l2: 0.306344\tvalid's l2: 0.583606\n",
      "[100]\ttrain's l2: 0.292753\tvalid's l2: 0.58101\n",
      "Model saved to ../out/models/wine/std-gbdt_wine_T100_S0050_L256_R100.model\n",
      "  num_trees  learning_rate num_leaves best_round   metric  \\\n",
      "0       100           0.05        256        100  0.58101   \n",
      "\n",
      "                                            filename  \n",
      "0  ../out/models/wine/std-gbdt_wine_T100_S0050_L2...  \n",
      "best model is: ../out/models/wine/std-gbdt_wine_T100_S0050_L256_R100.model\n"
     ]
    }
   ],
   "source": [
    "# FULL GDBT\n",
    "\n",
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               MODEL_FILENAME\n",
    "                                              )  \n",
    "\n",
    "experiments.to_csv(MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REDUCED GDBT\n",
    "\n",
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               RED_MODEL_FILENAME,\n",
    "                                               drop_cols=[\"alcohol\", \"residual_sugar\", \"volatile_acidity\"]\n",
    "                                              )  \n",
    "\n",
    "experiments.to_csv(RED_MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing original files...\n",
      "Loading: ../data/wine/train.csv.bz2\n",
      "Loading: ../data/wine/valid.csv.bz2\n",
      "Loading: ../data/wine/test.csv.bz2\n",
      "Train/Valid/Test sizes: (4547, 13) (650, 13) (1300, 13)\n",
      "Train/Valid/Test split: 0.70 0.10 0.20\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (3898, 13) (1299, 13) (1300, 13)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "Saving processed files *.atks.bz2\n",
      "[10]\ttrain's l2: 0.520077\tvalid's l2: 0.62858\n",
      "[20]\ttrain's l2: 0.512319\tvalid's l2: 0.626062\n",
      "[30]\ttrain's l2: 0.507472\tvalid's l2: 0.621204\n",
      "[40]\ttrain's l2: 0.506059\tvalid's l2: 0.62197\n",
      "[50]\ttrain's l2: 0.503661\tvalid's l2: 0.621407\n",
      "[60]\ttrain's l2: 0.50284\tvalid's l2: 0.620475\n",
      "[70]\ttrain's l2: 0.503065\tvalid's l2: 0.620394\n",
      "[80]\ttrain's l2: 0.503063\tvalid's l2: 0.620651\n",
      "[90]\ttrain's l2: 0.502976\tvalid's l2: 0.620229\n",
      "[100]\ttrain's l2: 0.502296\tvalid's l2: 0.620133\n",
      "Model saved to ../out/models/wine/rf-gbdt_wine_T100_S0050_L256_R68.model\n",
      "  num_trees  learning_rate num_leaves best_round    metric  \\\n",
      "0       100           0.05        256         68  0.619958   \n",
      "\n",
      "                                            filename  \n",
      "0  ../out/models/wine/rf-gbdt_wine_T100_S0050_L25...  \n",
      "best model is: ../out/models/wine/rf-gbdt_wine_T100_S0050_L256_R68.model\n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "\n",
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               RF_MODEL_FILENAME,\n",
    "                                               random_forest=True\n",
    "                                              )  \n",
    "\n",
    "experiments.to_csv(RF_MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CENSUS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"census\"\n",
    "DATASET_DIR=\"../data/{}\".format(DATASET_NAME)\n",
    "ATK_DIR=DATASET_DIR + \"/attacks\"\n",
    "MODELS_DIR=\"../out/models/{}\".format(DATASET_NAME)\n",
    "TRAINING_FILENAME=DATASET_DIR + \"/\" + \"train.csv.bz2\"\n",
    "VALIDATION_FILENAME=DATASET_DIR + \"/\" + \"valid.csv.bz2\"\n",
    "TEST_FILENAME=DATASET_DIR + \"/\" + \"test.csv.bz2\"\n",
    "MODEL_FILENAME=MODELS_DIR + \"/std-gbdt_{}\".format(DATASET_NAME)\n",
    "RED_MODEL_FILENAME=MODELS_DIR + \"/red-gbdt_{}\".format(DATASET_NAME)\n",
    "RF_MODEL_FILENAME=MODELS_DIR + \"/rf-gbdt_{}\".format(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# FULL GDBT\n",
    "\n",
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               MODEL_FILENAME\n",
    "                                              )  \n",
    "\n",
    "experiments.to_csv(MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REDUCED GDBT\n",
    "\n",
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               RED_MODEL_FILENAME,\n",
    "                                               drop_cols=['workclass','marital_status',\n",
    "                                                          'occupation', 'education_num',\n",
    "                                                          'hours_per_week','capital_gain' ]\n",
    "                                              )\n",
    "\n",
    "experiments.to_csv(RED_MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST\n",
    "\n",
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               RF_MODEL_FILENAME,\n",
    "                                               random_forest=True\n",
    "                                              )  \n",
    "\n",
    "experiments.to_csv(RF_MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPAM Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"spam\"\n",
    "DATASET_DIR=\"../data/{}\".format(DATASET_NAME)\n",
    "ATK_DIR=DATASET_DIR + \"/attacks\"\n",
    "MODELS_DIR=\"../out/models/{}\".format(DATASET_NAME)\n",
    "TRAINING_FILENAME=DATASET_DIR + \"/\" + \"train.csv.bz2\"\n",
    "VALIDATION_FILENAME=DATASET_DIR + \"/\" + \"valid.csv.bz2\"\n",
    "TEST_FILENAME=DATASET_DIR + \"/\" + \"test.csv.bz2\"\n",
    "MODEL_FILENAME=MODELS_DIR + \"/std-gbdt_{}\".format(DATASET_NAME)\n",
    "RED_MODEL_FILENAME=MODELS_DIR + \"/red-gbdt_{}\".format(DATASET_NAME)\n",
    "RF_MODEL_FILENAME=MODELS_DIR + \"/rf-gbdt_{}\".format(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# FULL GDBT\n",
    "\n",
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               MODEL_FILENAME\n",
    "                                              )  \n",
    "\n",
    "experiments.to_csv(MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REDUCED GDBT\n",
    "\n",
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               RED_MODEL_FILENAME,\n",
    "                                               drop_cols=['char_freq_!', 'word_freq_remove',\n",
    "                                                          'char_freq_$', 'capital_run_length_average',\n",
    "                                                          'capital_run_length_total' ]\n",
    "                                              )\n",
    "\n",
    "experiments.to_csv(RED_MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST\n",
    "\n",
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               RF_MODEL_FILENAME,\n",
    "                                               random_forest=True\n",
    "                                              )  \n",
    "\n",
    "experiments.to_csv(RF_MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###------------_####\n",
    "def print_fx_imp(model, colnames):\n",
    "    fx_uses = model.feature_importance(importance_type='split')\n",
    "    fx_gain = model.feature_importance(importance_type='gain')\n",
    "\n",
    "    for i,f in enumerate(np.argsort(fx_gain)[::-1]):\n",
    "        print (\"{:2d} {:20s} {:.3f} {:4d}\".format(i, colnames[f], fx_gain[f], fx_uses[f]))\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/wine/raw/train.csv.bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" -- GDBT --\")    \n",
    "gbdt = lightgbm.Booster(model_file=\"../out/models/wine/std-gbdt_wine_T100_S0050_L256_R97.model\")\n",
    "print(gbdt.num_trees())\n",
    "print_fx_imp(gbdt, df.columns)\n",
    "\n",
    "print(\" -- Reduced GDBT --\")    \n",
    "redf = lightgbm.Booster(model_file=\"../out/models/wine/red-gbdt_wine_T100_S0050_L256_R100.model\")\n",
    "print(redf.num_trees())\n",
    "#print_fx_imp(redf,train.drop(columns=['char_freq_!', 'word_freq_remove',\n",
    "#                                                          'char_freq_$', 'capital_run_length_average',\n",
    "#                                                         'capital_run_length_total', 'word_freq_hp' ]).columns\n",
    "#            )\n",
    "\n",
    "\n",
    "# print(\" -- Adv. Boosting --\")    \n",
    "# advb = lightgbm.Booster(model_file=\"../out/models/census/adv-boosting_census_B30_T100_S0050_L24_R100.model\")\n",
    "# print(advb.num_trees())\n",
    "# print_fx_imp(advb, TRAIN.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREDIT Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"credit\"\n",
    "DATASET_DIR=\"../data/{}\".format(DATASET_NAME)\n",
    "ATK_DIR=DATASET_DIR + \"/attacks\"\n",
    "MODELS_DIR=\"../out/models/{}\".format(DATASET_NAME)\n",
    "TRAINING_FILENAME=DATASET_DIR + \"/\" + \"train.csv.bz2\"\n",
    "VALIDATION_FILENAME=DATASET_DIR + \"/\" + \"valid.csv.bz2\"\n",
    "TEST_FILENAME=DATASET_DIR + \"/\" + \"test.csv.bz2\"\n",
    "MODEL_FILENAME=MODELS_DIR + \"/std-gbdt_{}\".format(DATASET_NAME)\n",
    "RED_MODEL_FILENAME=MODELS_DIR + \"/red-gbdt_{}\".format(DATASET_NAME)\n",
    "RF_MODEL_FILENAME=MODELS_DIR + \"/rf-gbdt_{}\".format(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL GDBT\n",
    "\n",
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               MODEL_FILENAME\n",
    "                                              )  \n",
    "\n",
    "experiments.to_csv(MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REDUCED GDBT\n",
    "\n",
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               RED_MODEL_FILENAME,\n",
    "                                               drop_cols=['PAY_0', 'BILL_AMT1', 'PAY_2', 'LIMIT_BAL'] # SET TO THE LIST OF ATTACKED FEATURES\n",
    "                                              )\n",
    "\n",
    "experiments.to_csv(RED_MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST\n",
    "\n",
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               RF_MODEL_FILENAME,\n",
    "                                               random_forest=True\n",
    "                                              )  \n",
    "\n",
    "experiments.to_csv(RF_MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEBSITES Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"websites\"\n",
    "DATASET_DIR=\"../data/{}\".format(DATASET_NAME)\n",
    "ATK_DIR=DATASET_DIR + \"/attacks\"\n",
    "MODELS_DIR=\"../out/models/{}\".format(DATASET_NAME)\n",
    "TRAINING_FILENAME=DATASET_DIR + \"/\" + \"train.csv.bz2\"\n",
    "VALIDATION_FILENAME=DATASET_DIR + \"/\" + \"valid.csv.bz2\"\n",
    "TEST_FILENAME=DATASET_DIR + \"/\" + \"test.csv.bz2\"\n",
    "MODEL_FILENAME=MODELS_DIR + \"/std-gbdt_{}\".format(DATASET_NAME)\n",
    "RED_MODEL_FILENAME=MODELS_DIR + \"/red-gbdt_{}\".format(DATASET_NAME)\n",
    "RF_MODEL_FILENAME=MODELS_DIR + \"/rf-gbdt_{}\".format(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing original files...\n",
      "Loading: ../data/websites/train.csv.bz2\n",
      "Loading: ../data/websites/valid.csv.bz2\n",
      "Loading: ../data/websites/test.csv.bz2\n",
      "Train/Valid/Test sizes: (1068, 14) (356, 14) (356, 14)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (1068, 14) (356, 14) (356, 14)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "Saving processed files *.atks.bz2\n",
      "[10]\ttrain's l2: 0.242588\tvalid's l2: 0.104841\n",
      "[20]\ttrain's l2: 0.169659\tvalid's l2: 0.119277\n",
      "[30]\ttrain's l2: 0.128631\tvalid's l2: 0.120082\n",
      "[40]\ttrain's l2: 0.103857\tvalid's l2: 0.120464\n",
      "[50]\ttrain's l2: 0.0867307\tvalid's l2: 0.127315\n",
      "[60]\ttrain's l2: 0.0753108\tvalid's l2: 0.126461\n",
      "[70]\ttrain's l2: 0.0674525\tvalid's l2: 0.127927\n",
      "[80]\ttrain's l2: 0.0619007\tvalid's l2: 0.12823\n",
      "[90]\ttrain's l2: 0.0572583\tvalid's l2: 0.128215\n",
      "[100]\ttrain's l2: 0.0537401\tvalid's l2: 0.129009\n",
      "Model saved to ../out/models/websites/std-gbdt_websites_T100_S0050_L256_R5.model\n",
      "  num_trees  learning_rate num_leaves best_round    metric  \\\n",
      "0       100           0.05        256          5  0.103229   \n",
      "\n",
      "                                            filename  \n",
      "0  ../out/models/websites/std-gbdt_websites_T100_...  \n",
      "best model is: ../out/models/websites/std-gbdt_websites_T100_S0050_L256_R5.model\n"
     ]
    }
   ],
   "source": [
    "# FULL GDBT\n",
    "\n",
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               MODEL_FILENAME\n",
    "                                              )  \n",
    "\n",
    "experiments.to_csv(MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REDUCED GDBT\n",
    "\n",
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               RED_MODEL_FILENAME,\n",
    "                                               drop_cols=[] # SET TO THE LIST OF ATTACKED FEATURES\n",
    "                                              )\n",
    "\n",
    "experiments.to_csv(RED_MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST\n",
    "\n",
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               RF_MODEL_FILENAME,\n",
    "                                               random_forest=True\n",
    "                                              )  \n",
    "\n",
    "experiments.to_csv(RF_MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Distress "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"financial\"\n",
    "DATASET_DIR=\"../data/{}\".format(DATASET_NAME)\n",
    "ATK_DIR=DATASET_DIR + \"/attacks\"\n",
    "MODELS_DIR=\"../out/models/{}\".format(DATASET_NAME)\n",
    "TRAINING_FILENAME=DATASET_DIR + \"/\" + \"train.csv.bz2\"\n",
    "VALIDATION_FILENAME=DATASET_DIR + \"/\" + \"valid.csv.bz2\"\n",
    "TEST_FILENAME=DATASET_DIR + \"/\" + \"test.csv.bz2\"\n",
    "MODEL_FILENAME=MODELS_DIR + \"/std-gbdt_{}\".format(DATASET_NAME)\n",
    "RED_MODEL_FILENAME=MODELS_DIR + \"/red-gbdt_{}\".format(DATASET_NAME)\n",
    "RF_MODEL_FILENAME=MODELS_DIR + \"/rf-gbdt_{}\".format(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing original files...\n",
      "Loading: ../data/financial/train.csv.bz2\n",
      "Loading: ../data/financial/valid.csv.bz2\n",
      "Loading: ../data/financial/test.csv.bz2\n",
      "Train/Valid/Test sizes: (2202, 84) (734, 84) (736, 84)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (2203, 84) (734, 84) (735, 84)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "Saving processed files *.atks.bz2\n",
      "[10]\ttrain's l2: 0.13062\tvalid's l2: 0.135682\n",
      "[20]\ttrain's l2: 0.120916\tvalid's l2: 0.130935\n",
      "[30]\ttrain's l2: 0.112371\tvalid's l2: 0.126817\n",
      "[40]\ttrain's l2: 0.105103\tvalid's l2: 0.123654\n",
      "[50]\ttrain's l2: 0.0991287\tvalid's l2: 0.121445\n",
      "[60]\ttrain's l2: 0.0939611\tvalid's l2: 0.119651\n",
      "[70]\ttrain's l2: 0.0892309\tvalid's l2: 0.11822\n",
      "[80]\ttrain's l2: 0.085182\tvalid's l2: 0.117024\n",
      "[90]\ttrain's l2: 0.081519\tvalid's l2: 0.115942\n",
      "[100]\ttrain's l2: 0.0781675\tvalid's l2: 0.115107\n",
      "Model saved to ../out/models/financial/std-gbdt_financial_T100_S0010_L256_R100.model\n",
      "  num_trees  learning_rate num_leaves best_round    metric  \\\n",
      "0       100           0.01        256        100  0.115107   \n",
      "\n",
      "                                            filename  \n",
      "0  ../out/models/financial/std-gbdt_financial_T10...  \n",
      "best model is: ../out/models/financial/std-gbdt_financial_T100_S0010_L256_R100.model\n"
     ]
    }
   ],
   "source": [
    "# FULL GDBT\n",
    "\n",
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               MODEL_FILENAME\n",
    "                                              )  \n",
    "\n",
    "experiments.to_csv(MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REDUCED GDBT\n",
    "\n",
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               RED_MODEL_FILENAME,\n",
    "                                               drop_cols=[] # SET TO THE LIST OF ATTACKED FEATURES\n",
    "                                              )\n",
    "\n",
    "experiments.to_csv(RED_MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing original files...\n",
      "Loading: ../data/financial/train.csv.bz2\n",
      "Loading: ../data/financial/valid.csv.bz2\n",
      "Loading: ../data/financial/test.csv.bz2\n",
      "Train/Valid/Test sizes: (2202, 84) (734, 84) (736, 84)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (2203, 84) (734, 84) (735, 84)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "Saving processed files *.atks.bz2\n",
      "[10]\ttrain's l2: 0.0741182\tvalid's l2: 0.111513\n",
      "[20]\ttrain's l2: 0.0743626\tvalid's l2: 0.11311\n",
      "[30]\ttrain's l2: 0.0745657\tvalid's l2: 0.112359\n",
      "[40]\ttrain's l2: 0.0748962\tvalid's l2: 0.112413\n",
      "[50]\ttrain's l2: 0.0743016\tvalid's l2: 0.112821\n",
      "[60]\ttrain's l2: 0.0745339\tvalid's l2: 0.112573\n",
      "[70]\ttrain's l2: 0.0749791\tvalid's l2: 0.112432\n",
      "[80]\ttrain's l2: 0.0750759\tvalid's l2: 0.112305\n",
      "[90]\ttrain's l2: 0.0751625\tvalid's l2: 0.11246\n",
      "[100]\ttrain's l2: 0.0752458\tvalid's l2: 0.112652\n",
      "Model saved to ../out/models/financial/rf-gbdt_financial_T100_S0050_L256_R7.model\n",
      "  num_trees  learning_rate num_leaves best_round    metric  \\\n",
      "0       100           0.05        256          7  0.109741   \n",
      "\n",
      "                                            filename  \n",
      "0  ../out/models/financial/rf-gbdt_financial_T100...  \n",
      "best model is: ../out/models/financial/rf-gbdt_financial_T100_S0050_L256_R7.model\n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "\n",
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               RF_MODEL_FILENAME,\n",
    "                                               random_forest=True\n",
    "                                              )  \n",
    "\n",
    "experiments.to_csv(RF_MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###------------_####\n",
    "def print_fx_imp(model, colnames):\n",
    "    fx_uses = model.feature_importance(importance_type='split')\n",
    "    fx_gain = model.feature_importance(importance_type='gain')\n",
    "\n",
    "    for i,f in enumerate(np.argsort(fx_gain)[::-1]):\n",
    "        print (\"{:2d} {:20s} {:.3f} {:4d}\".format(i, colnames[f], fx_gain[f], fx_uses[f]))\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/financial/raw/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- GDBT --\n",
      "100\n",
      " 0 x82                  1450191.221  320\n",
      " 1 Company              397806.522  693\n",
      " 2 x80                  214362.329  311\n",
      " 3 x30                  70387.155   98\n",
      " 4 x33                  64393.008   76\n",
      " 5 x56                  55164.777   99\n",
      " 6 x54                  51505.891  120\n",
      " 7 x26                  48233.233  137\n",
      " 8 x19                  47749.092   97\n",
      " 9 x31                  46238.511  101\n",
      "10 x52                  45855.731   69\n",
      "11 x51                  43187.993  130\n",
      "12 x22                  42519.931   85\n",
      "13 x41                  38283.714   72\n",
      "14 x40                  37769.541   80\n",
      "15 x43                  36778.803   81\n",
      "16 x60                  35857.685   95\n",
      "17 x34                  33937.908   88\n",
      "18 x29                  31576.337   69\n",
      "19 x15                  31082.085   66\n",
      "20 x11                  30978.140   66\n",
      "21 x48                  28640.856   69\n",
      "22 x68                  28603.746   33\n",
      "23 x27                  26807.277   60\n",
      "24 x81                  26134.594   53\n",
      "25 x7                   23449.374   59\n",
      "26 x10                  20972.959   65\n",
      "27 x57                  20419.685   58\n",
      "28 x37                  18192.698   51\n",
      "29 x12                  16465.978   42\n",
      "30 x4                   16185.895   65\n",
      "31 x8                   15765.668   32\n",
      "32 x32                  15670.466   31\n",
      "33 x53                  15114.412   43\n",
      "34 x23                  14708.719   35\n",
      "35 x45                  14670.649   41\n",
      "36 x24                  14322.111   42\n",
      "37 x21                  13800.187   51\n",
      "38 x36                  13484.363   32\n",
      "39 x58                  13454.105   35\n",
      "40 x46                  13034.959   34\n",
      "41 x17                  12594.959   44\n",
      "42 x9                   12068.865   33\n",
      "43 x20                  11613.919   34\n",
      "44 x16                  10911.572   31\n",
      "45 x25                  10496.522   26\n",
      "46 x28                  10261.579   26\n",
      "47 x18                  10199.479   27\n",
      "48 x59                  9846.250   34\n",
      "49 x49                  9212.281   17\n",
      "50 x3                   8925.625   20\n",
      "51 Time                 8011.146   23\n",
      "52 x6                   7792.962   22\n",
      "53 x5                   7139.620   24\n",
      "54 x1                   6957.572   21\n",
      "55 x38                  6411.306   37\n",
      "56 x47                  6129.458   21\n",
      "57 x44                  6101.537   27\n",
      "58 x42                  5941.171   15\n",
      "59 x35                  5248.375    8\n",
      "60 x39                  3382.192   12\n",
      "61 x55                  3081.345   10\n",
      "62 x78                  2935.473   10\n",
      "63 x65                  2435.229    4\n",
      "64 x69                  1855.872    9\n",
      "65 x73                  1703.502    8\n",
      "66 x63                  1618.007    7\n",
      "67 x77                  1503.147    4\n",
      "68 x66                  1292.250    1\n",
      "69 x62                  1253.494    3\n",
      "70 x13                  1163.696    2\n",
      "71 x50                  1110.427    4\n",
      "72 x67                  1102.834    6\n",
      "73 x64                  955.012    5\n",
      "74 Financial Distress   664.225    5\n",
      "75 x2                   591.241    7\n",
      "76 x71                  365.715    3\n",
      "77 x74                  264.160    3\n",
      "78 x61                  121.762    1\n",
      "79 x70                  85.354    1\n",
      "80 x76                  0.000    0\n",
      "81 x72                  0.000    0\n",
      "82 x79                  0.000    0\n",
      "83 x14                  0.000    0\n",
      "84 x75                  0.000    0\n"
     ]
    }
   ],
   "source": [
    "print(\" -- GDBT --\")    \n",
    "gbdt = lightgbm.Booster(model_file=\"../out/models/financial/std-gbdt_financial_T100_S0050_L256_R37.model\")\n",
    "print(gbdt.num_trees())\n",
    "print_fx_imp(gbdt, df.columns)\n",
    "\n",
    "#print(\" -- Reduced GDBT --\")    \n",
    "#redf = lightgbm.Booster(model_file=\"../out/models/wine/red-gbdt_wine_T100_S0050_L256_R100.model\")\n",
    "#print(redf.num_trees())\n",
    "#print_fx_imp(redf,train.drop(columns=['char_freq_!', 'word_freq_remove',\n",
    "#                                                          'char_freq_$', 'capital_run_length_average',\n",
    "#                                                         'capital_run_length_total', 'word_freq_hp' ]).columns\n",
    "#            )\n",
    "\n",
    "\n",
    "# print(\" -- Adv. Boosting --\")    \n",
    "# advb = lightgbm.Booster(model_file=\"../out/models/census/adv-boosting_census_B30_T100_S0050_L24_R100.model\")\n",
    "# print(advb.num_trees())\n",
    "# print_fx_imp(advb, TRAIN.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
