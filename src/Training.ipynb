{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Models\n",
    "\n",
    "This notebook contains the code used for training the following learning models:\n",
    "\n",
    "-  **Standard GBDT** (_baseline 1_)\n",
    "-  **Adversarial Boosting** (_baseline 2_)\n",
    "-  **Non-Interferent GBDT** (our proposal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "\n",
    " - http://lightgbm.readthedocs.io/en/latest/\n",
    " - http://lightgbm.readthedocs.io/en/latest/Python-Intro.html\n",
    " - https://github.com/Microsoft/LightGBM/tree/master/examples/python-guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm\n",
    "import pickle\n",
    "import json\n",
    "import functools\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode(dataset, categorical_features):\n",
    "    dataset_le = dataset.copy()\n",
    "    for column in dataset_le.columns:\n",
    "        if column in categorical_features:\n",
    "            dataset_le[column] = dataset_le[column].astype('category')\n",
    "            dataset_le[column] = dataset_le[column].cat.codes.astype(np.int32)\n",
    "    return dataset_le\n",
    "\n",
    "def load_atk_train_valid_test( atk_train_file, atk_valid_file, atk_test_file, \n",
    "                               train_split=0.6, valid_split=0.2,\n",
    "                               force=False):\n",
    "    \n",
    "    \n",
    "    if  ( force or \n",
    "          not os.path.exists(atk_train_file+\".cat.bz2\") or\n",
    "          not os.path.exists(atk_valid_file+\".cat.bz2\") or\n",
    "          not os.path.exists(atk_test_file+\".cat.bz2\") or \n",
    "          not os.path.exists(atk_train_file+\".cat.json\") ):\n",
    "    \n",
    "        print (\"Pre-processing original files...\")\n",
    "\n",
    "        print (\"Loading:\", atk_train_file)\n",
    "        print (\"Loading:\", atk_valid_file)\n",
    "        print (\"Loading:\", atk_test_file)\n",
    "\n",
    "        train = pd.read_csv(atk_train_file)\n",
    "        valid = pd.read_csv(atk_valid_file)\n",
    "        test  = pd.read_csv(atk_test_file)\n",
    "        \n",
    "        print (\"Train/Valid/Test sizes:\", train.shape, valid.shape, test.shape)\n",
    "        print (\"Train/Valid/Test split: {:.2f} {:.2f} {:.2f}\"\n",
    "                   .format( train.shape[0]/(train.shape[0]+valid.shape[0]+test.shape[0]),\n",
    "                            valid.shape[0]/(train.shape[0]+valid.shape[0]+test.shape[0]),\n",
    "                            test.shape[0] /(train.shape[0]+valid.shape[0]+test.shape[0]) ) )\n",
    "\n",
    "        # concat to process correctly label encoding\n",
    "        full = pd.concat( [train, valid, test] )\n",
    "\n",
    "        # get index of categorical features (-1 because of instance_id)\n",
    "        cat_fx = full.columns.values[ np.where(full.dtypes=='object')[0] ]\n",
    "        cat_fx = list(cat_fx)    \n",
    "        full = label_encode(full, cat_fx)\n",
    "        with open(atk_train_file+\".cat.json\", 'w') as fp:\n",
    "            json.dump(cat_fx, fp)\n",
    "        print (\"CatFX:\", cat_fx)\n",
    "\n",
    "        # split-back into train valid test\n",
    "        train_size = int( full.shape[0]*train_split )\n",
    "        valid_size = int( full.shape[0]*valid_split )\n",
    "        train_cat = full.iloc[0:train_size,:]\n",
    "        valid_cat = full.iloc[train_size:train_size+valid_size,:]\n",
    "        test_cat  = full.iloc[train_size+valid_size:,:]    \n",
    "\n",
    "        print (\"Train/Valid/Test sizes:\", train_cat.shape, valid_cat.shape, test_cat.shape)\n",
    "        print (\"Train/Valid/Test split: {:.2f} {:.2f} {:.2f}\"\n",
    "                   .format( train_cat.shape[0]/(train_cat.shape[0]+valid_cat.shape[0]+test_cat.shape[0]),\n",
    "                            valid_cat.shape[0]/(train_cat.shape[0]+valid_cat.shape[0]+test_cat.shape[0]),\n",
    "                            test_cat.shape[0] /(train_cat.shape[0]+valid_cat.shape[0]+test_cat.shape[0]) ) )\n",
    "\n",
    "        # save to file\n",
    "        print (\"Saving processed files *.cat.bz2\")\n",
    "        train_cat.to_csv(atk_train_file+\".cat.bz2\", compression=\"bz2\", index=False)\n",
    "        valid_cat.to_csv(atk_valid_file+\".cat.bz2\", compression=\"bz2\", index=False)\n",
    "        test_cat.to_csv (atk_test_file+\".cat.bz2\",  compression=\"bz2\", index=False)\n",
    "        \n",
    "    else:\n",
    "        print (\"Loading pre-processed files...\")\n",
    "\n",
    "        train_cat = pd.read_csv(atk_train_file+\".cat.bz2\")\n",
    "        valid_cat = pd.read_csv(atk_valid_file+\".cat.bz2\")\n",
    "        test_cat  = pd.read_csv(atk_test_file+\".cat.bz2\")\n",
    "        \n",
    "        with open(atk_train_file+\".cat.json\", 'r') as fp:\n",
    "            cat_fx = json.load(fp)\n",
    "    \n",
    "    # return data\n",
    "    return train_cat, valid_cat, test_cat, cat_fx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard\n",
    "\n",
    "The following function, called <code>optimize_log_loss</code>, is the one that should be optimized (i.e., minimized) for learning _standard_ and _baseline_ approaches. More specifically, this is the standard binary log loss which is used to train any _standard_ or _baseline_ model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $L$ = <code>optimize_log_loss</code>\n",
    "\n",
    "$$\n",
    "L = \\frac{1}{|\\mathcal{D}|} \\cdot \\sum_{(\\mathbf{x},y) \\in \\mathcal{D}}\\ell(h(\\mathbf{x}), y)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "\\ell(h(\\mathbf{x}), y) = log(1+e^{(-yh(\\mathbf{x}))})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_log_loss(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    exp_pl = np.exp(preds * labels)\n",
    "    # http://www.wolframalpha.com/input/?i=differentiate+log(1+%2B+exp(-kx)+)\n",
    "    grads = -labels / (1.0 +  exp_pl)  \n",
    "    # http://www.wolframalpha.com/input/?i=d%5E2%2Fdx%5E2+log(1+%2B+exp(-kx)+)\n",
    "    hess = labels**2 * exp_pl / (1.0 + exp_pl)**2 \n",
    "\n",
    "    # this is to optimize average logloss\n",
    "    norm = 1.0/len(preds)\n",
    "    grads *= norm\n",
    "    hess *= norm\n",
    "    \n",
    "    return grads, hess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom\n",
    "\n",
    "In addition to the standard binary log loss used to train a model, we introduce our custom <code>optimize_non_interferent_log_loss</code>, which is computed as the weighted combination of two objective functions, as follows:\n",
    "\n",
    "-  $L$ = <code>optimize_log_loss</code> (standard, already seen above);\n",
    "-  $L^A$ = <code>optimize_log_loss_uma</code> (custom, defined below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $L^A$ = <code>optimize_log_loss_uma</code>\n",
    "\n",
    "This function is used to train a **full** _non-interferent_ model; in other words, full non-interferent models are learned by optimizing (i.e., minimizing) the function which measures the binary log loss **under the maximal attack** possible.\n",
    "\n",
    "$$\n",
    "L^A = \\frac{1}{|\\mathcal{D}|} \\cdot \\sum_{(\\mathbf{x},y) \\in \\mathcal{D}} \\log  \\left( \\sum_{\\mathbf{x}' \\in \\mathit{MaxAtk}({\\mathbf{x}},{A})} e^{\\ell(h(\\mathbf{x}'), y)} \\right).\n",
    "$$\n",
    "\n",
    "where still:\n",
    "\n",
    "$$\n",
    "\\ell(h(\\mathbf{x}), y) = log(1+e^{(-yh(\\mathbf{x}))})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_log_loss_uma(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    attack_lens = train_data.get_group()\n",
    "    \n",
    "    grads = np.zeros_like(labels, dtype=np.float64)\n",
    "    hess = np.zeros_like(grads)\n",
    "    \n",
    "    if attack_lens is not None:\n",
    "\n",
    "        norm = 1.0 / float(len(attack_lens))\n",
    "\n",
    "        offset = 0\n",
    "        for atk in attack_lens:\n",
    "            exp_pl = np.exp(- preds[offset:offset+atk] * labels[offset:offset+atk])\n",
    "\n",
    "            inv_sum = 1.0 / np.sum(1.0 + exp_pl)\n",
    "\n",
    "            x_grad = inv_sum * exp_pl\n",
    "\n",
    "            grads[offset:offset+atk] = norm * x_grad * (- labels[offset:offset+atk])\n",
    "            hess[offset:offset+atk]  = norm * x_grad * (1.0 - x_grad)\n",
    "\n",
    "            offset += atk    \n",
    "    \n",
    "    return grads, hess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>optimize_non_interferent_log_loss</code>\n",
    "\n",
    "$$\n",
    "\\alpha\\cdot L^A + (1-\\alpha)\\cdot L\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\alpha \\cdot \\underbrace{\\Bigg[\\frac{1}{|\\mathcal{D}|} \\cdot \\sum_{(\\mathbf{x},y) \\in \\mathcal{D}} \\log  \\left( \\sum_{\\mathbf{x}' \\in \\mathit{MaxAtk}({\\mathbf{x}},{A})} e^{\\ell(h(\\mathbf{x}'), y)} \\right)\\Bigg]}_{L^A} + (1-\\alpha) \\cdot \\underbrace{\\Bigg[\\frac{1}{|\\mathcal{D}|} \\cdot \\sum_{(\\mathbf{x},y) \\in \\mathcal{D}} \\ell(h(\\mathbf{x}, y))\\Bigg]}_{L}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_non_interferent_log_loss(preds, train_data, alpha=1.0):\n",
    "    # binary logloss under maximal attack\n",
    "    grads_uma, hess_uma = optimize_log_loss_uma(preds, train_data)\n",
    "    \n",
    "    # binary logloss (plain)\n",
    "    grads_plain, hess_plain = optimize_log_loss(preds, train_data)\n",
    "    \n",
    "    # combine the above two losses together\n",
    "    grads = alpha*grads_uma + (1.0-alpha)*grads_plain\n",
    "    hess  = alpha*hess_uma  + (1.0-alpha)*hess_plain\n",
    "    \n",
    "    return grads, hess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using one objective function for both _standard_ and _non-interferent_ learning\n",
    "\n",
    "The advantage of the <code>optimize_non_interferent_log_loss</code> function defined above is that we can wrap it so that we can use it as the only objective function (<code>fobj</code>) passed in to LightGBM. \n",
    "\n",
    "In other words, if we call <code>fobj=optimize_non_interferent_log_loss</code> with <code>alpha=0.0</code>, this will end up optimizing (i.e., minimizing) the \"vanilla\" objective function (i.e., the standard binary log loss, defined by the function <code>optimize_log_loss</code> above).\n",
    "\n",
    "Conversely, calling <code>fobj=optimize_non_interferent_log_loss</code> with <code>alpha=1.0</code> turns into optimizing (i.e., minimizing) the full non-interferent objective function (i.e., the custom binary log loss under max attack, defined by the function <code>optimize_log_loss_uma</code> above).\n",
    "\n",
    "Anything that sits in between (i.e., <code>0 < alpha < 1</code>) optimizes an objective function that trades off between the standard and the full non-interferent term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard\n",
    "\n",
    "The following function is the one used for evaluating the quality of the learned model (either _standard_, _adversarial-boosting_, or _non-interferent_). This is the standard <code>avg_log_loss</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(p):\n",
    "    return np.log(p/(1-p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>avg_log_loss</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-defined eval metric\n",
    "# f(preds: array, train_data: Dataset) -> name: string, value: array, is_higher_better: bool\n",
    "def avg_log_loss(preds, train_data):\n",
    "    \n",
    "    labels = train_data.get_label()\n",
    "    losses = np.log(1.0 + np.exp(-preds*labels))\n",
    "    avg_loss = np.mean(losses)\n",
    "    \n",
    "    return 'avg_binary_log_loss', avg_loss, False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom\n",
    "\n",
    "Similarly to what we have done for <code>fobj</code>, <code>feval</code> can be computed from a weighted combination of two evaluation metrics:\n",
    "\n",
    "-  <code>avg_log_loss</code> (standard, defined above);\n",
    "-  <code>avg_log_loss_uma</code> (custom, defined below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>avg_log_loss_uma</code>\n",
    "\n",
    "This is the binary log loss yet modified to operate on groups of perturbed instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our custom metrics\n",
    "def binary_log_loss(pred, true_label):\n",
    "\n",
    "    return np.log(1.0 + np.exp(-pred * true_label))\n",
    "\n",
    "# self-defined eval metric\n",
    "# f(preds: array, train_data: Dataset) -> name: string, value: array, is_higher_better: bool\n",
    "def avg_log_loss_uma(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    attack_lens = train_data.get_group()\n",
    "    \n",
    "    offset = 0\n",
    "    max_logloss = []\n",
    "    avg_max_logloss = 0.0\n",
    "    \n",
    "    if attack_lens is not None:\n",
    "    \n",
    "        for atk in attack_lens:\n",
    "            losses = [binary_log_loss(h,t) for h,t in zip(preds[offset:offset+atk], labels[offset:offset+atk])]\n",
    "            max_logloss.append(max(losses))\n",
    "\n",
    "            offset += atk\n",
    "        \n",
    "        avg_max_logloss = np.mean(max_logloss)  \n",
    "\n",
    "    return 'avg_binary_log_loss_under_max_attack', avg_max_logloss, False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>feval=avg_non_interferent_log_loss</code>\n",
    "\n",
    "Used for measuring the validity of any model (either _standard_, _baseline_, or _non-interferent_). More precisely, <code>avg_non_interferent_log_loss</code> is the weighted sum of the binary log loss and the binary log loss under maximal attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_non_interferent_log_loss(preds, train_data, alpha=1.0):\n",
    "    \n",
    "    # binary logloss under maximal attack\n",
    "    _, loss_uma, _    = avg_log_loss_uma(preds, train_data)\n",
    "    \n",
    "    # binary logloss (plain)\n",
    "    _, loss_plain, _  = avg_log_loss(preds, train_data)\n",
    "    \n",
    "    # combine the above two losses together\n",
    "    weighted_loss = alpha*loss_uma + (1.0-alpha)*loss_plain\n",
    "\n",
    "    return 'avg_non_interferent_log_loss [alpha={:.2f}]'.format(alpha), weighted_loss, False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_adv_boosting_data(model, data, groups):\n",
    "    ''' \n",
    "    model  : is the LightGBM Model\n",
    "    data   : data matrix with all valid attacks (last column is label)\n",
    "    groups : grouping of same attacked instance \n",
    "    returns the new data matrix and new groups\n",
    "    \n",
    "    WARNING: currently works only for binary classification\n",
    "    '''\n",
    "    # score the datataset\n",
    "    labels = data[:,-1]\n",
    "    \n",
    "    predictions = model.predict(data[:,:-1]) # exclude labels\n",
    "    # binarize\n",
    "    predictions = (predictions>0).astype(np.float)\n",
    "    predictions = 2*predictions - 1\n",
    "    \n",
    "    # check mispredictions\n",
    "    matchings = labels * predictions\n",
    "    \n",
    "    # select original data + attacked instances\n",
    "    new_selected = [] # id of selected instances\n",
    "    new_groups   = []\n",
    "    \n",
    "    offset = 0\n",
    "    for g in groups:\n",
    "        if g==0:\n",
    "            print (\"Error !!!!\")\n",
    "        elif g==1:\n",
    "            # there are no attacks, just add original\n",
    "            new_selected += [offset]\n",
    "            new_groups   += [1]\n",
    "        else:\n",
    "            # get a slice of the matching scores\n",
    "            g_matchings = matchings[offset:offset+g]\n",
    "\n",
    "            # most misclassified (smallest margin)\n",
    "            # skip original\n",
    "            adv_instance = np.argmin(g_matchings[1:])+1\n",
    "\n",
    "            # add original and adversarial\n",
    "            new_selected += [offset, adv_instance]\n",
    "            new_groups   += [2]\n",
    "        \n",
    "        offset += g\n",
    "    \n",
    "    new_dataset = data[new_selected,:]\n",
    "    \n",
    "    return new_dataset, new_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_adv_boosting_model(train, valid, cat_fx, input_model=None, num_trees=1, params=None):\n",
    "    ''' \n",
    "    model  : is the LightGBM Model\n",
    "    data   : data matrix with all valid attacks (last column is label)\n",
    "    returns the new model (is model modified inplace?)\n",
    "    '''\n",
    "    \n",
    "    if cat_fx is None or len(cat_fx)==0:\n",
    "        cat_fx = \"auto\"\n",
    "\n",
    "    lgbm_train = lightgbm.Dataset(data=train[:,:-1], \n",
    "                                  label=train[:,-1],\n",
    "                                  categorical_feature = cat_fx)\n",
    "    \n",
    "    lgbm_valid = lightgbm.Dataset(data=valid[:,:-1], \n",
    "                                  label=valid[:,-1],\n",
    "                                  categorical_feature = cat_fx)\n",
    "    \n",
    "    lgbm_info = {}\n",
    "    lgbm_model = lightgbm.train(params, lgbm_train, \n",
    "                                num_boost_round = num_trees, \n",
    "                                init_model = input_model,\n",
    "                                fobj = optimize_log_loss, \n",
    "                                feval = avg_log_loss,\n",
    "                                evals_result = lgbm_info,\n",
    "                                valid_sets   = [lgbm_train, lgbm_valid], \n",
    "                                valid_names  = ['train', 'valid'],\n",
    "                                verbose_eval=25)\n",
    "\n",
    "    return lgbm_model, lgbm_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdvBoosting(atk_train, valid, trees, \n",
    "                 cat_fx,\n",
    "                 params,\n",
    "                 output_model_file,\n",
    "                 partial_save=100, \n",
    "                 adv_rounds=1):\n",
    "    ''' \n",
    "    atk_data: full dataset including all valid attacks\n",
    "    atk_groups: lenght of each attack set\n",
    "    trees: total number of trees to be produced\n",
    "    adv_rounds: adversarial instance injecting frequency\n",
    "    '''\n",
    "    # temp lgbm file\n",
    "    temp = output_model_file+\".tmp\"\n",
    "    \n",
    "    # get groups and remove instance ids\n",
    "    atk_groups = atk_train['instance_id'].value_counts().sort_index().values\n",
    "    #atk_train.drop('instance_id', axis=1, inplace=True)\n",
    "    \n",
    "    # get index of categorical features \n",
    "    cat_fx = np.where(atk_train.columns.isin(cat_fx) )[0]\n",
    "    cat_fx = list([int(x) for x in cat_fx])  \n",
    "    # print (\"CatFX:\", atk_train.columns.values[cat_fx])\n",
    "\n",
    "    # prepare data (avoiding pandas)\n",
    "    atk_data   = atk_train.iloc[:,1:].values\n",
    "    valid = valid.values\n",
    "\n",
    "    # train first trees\n",
    "    original_ids = np.cumsum(atk_groups[:-1])\n",
    "    original_ids = np.insert(original_ids, 0, 0)\n",
    "    \n",
    "    model, model_info = extend_adv_boosting_model(atk_data[original_ids, :], \n",
    "                                                  valid,\n",
    "                                                  cat_fx=cat_fx,\n",
    "                                                  input_model=None, \n",
    "                                                  num_trees=adv_rounds, \n",
    "                                                  params=params )\n",
    "    \n",
    "    best_model = model\n",
    "    best_info = model_info\n",
    "    best_loss = model_info['valid']['avg_binary_log_loss']\n",
    "    best_round = 1\n",
    "        \n",
    "    # train remaining trees\n",
    "    for t in range(adv_rounds+1, trees+1, adv_rounds):\n",
    "        # attack dataset\n",
    "        adv_data, adv_offsets = gen_adv_boosting_data(model, atk_data, atk_groups)\n",
    "        \n",
    "        # train additional trees\n",
    "        model.save_model(temp)\n",
    "        model, model_info = extend_adv_boosting_model(adv_data, \n",
    "                                                      valid,\n",
    "                                                      cat_fx=cat_fx,\n",
    "                                                      input_model=temp, \n",
    "                                                      num_trees=adv_rounds, \n",
    "                                                      params=params)\n",
    "\n",
    "        if model_info['valid']['avg_binary_log_loss'] < best_loss:\n",
    "            best_model = model\n",
    "            best_info = model_info\n",
    "            best_loss = np.min(model_info['valid']['avg_binary_log_loss'])\n",
    "            best_round = t\n",
    "        \n",
    "        # save partial model\n",
    "        if t % partial_save == 0 and t != trees:\n",
    "            partial_filename = \"{:s}_T{:d}-of-{:d}_S{:04d}_L{:d}.model.tmp\".format(output_model_file, \n",
    "                                                                                   t, \n",
    "                                                                                   trees, \n",
    "                                                                                   int(params['learning_rate'] * 1000),\n",
    "                                                                                   params['num_leaves']\n",
    "                                                                                  )\n",
    "            \n",
    "            print(\"Save partial model to {}\".format(partial_filename))\n",
    "            model.save_model(filename=partial_filename)\n",
    "            \n",
    "    \n",
    "    return model, model_info, best_loss, best_round"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Standard GBDT (_baseline 1_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gradient_boosting_baseline( train_file, valid_file, test_file,\n",
    "                                output_model_file):\n",
    "    \n",
    "    exp = pd.DataFrame(columns=['num_trees', 'learning_rate', 'num_leaves', 'best_round', 'avg_binary_log_loss'])\n",
    "    \n",
    "    # load train/valid/test\n",
    "    train, valid, test, cat_fx = load_atk_train_valid_test(train_file, valid_file, test_file)\n",
    "\n",
    "    # get index of categorical features \n",
    "    cat_fx = np.where(train.columns.isin(cat_fx) )[0]\n",
    "    cat_fx = list([int(x) for x in cat_fx])  \n",
    "    print (\"CatFX:\", train.columns.values[cat_fx])\n",
    "    \n",
    "\n",
    "    for num_trees in [50, 100, 150, 200, 250]:\n",
    "        best_model = None\n",
    "        best_info = None\n",
    "        best_loss = np.inf\n",
    "        for learning_rate in [0.001, 0.01, 0.1, 1.0]:\n",
    "            for num_leaves in [8, 16, 24]:\n",
    "                # datasets\n",
    "                lgbm_train = lightgbm.Dataset(data=train.values[:,:-1], \n",
    "                                              label=train.values[:,-1],\n",
    "                                              categorical_feature = cat_fx)\n",
    "\n",
    "                lgbm_valid = lightgbm.Dataset(data=valid.values[:,:-1], \n",
    "                                              label=valid.values[:,-1],\n",
    "                                              categorical_feature = cat_fx)\n",
    "\n",
    "                # run train\n",
    "                lgbm_params = { 'learning_rate': learning_rate, \n",
    "                                'num_leaves': num_leaves} \n",
    "                lgbm_info = {}\n",
    "                lgbm_model = lightgbm.train(lgbm_params, lgbm_train, \n",
    "                                            num_boost_round = num_trees,\n",
    "                                            fobj            = optimize_log_loss, \n",
    "                                            feval           = avg_log_loss,\n",
    "                                            evals_result    = lgbm_info,\n",
    "                                            valid_sets      = [lgbm_train, lgbm_valid], \n",
    "                                            valid_names     = ['train', 'valid'],\n",
    "                                            verbose_eval    = 25)\n",
    "\n",
    "                if np.min(lgbm_info['valid']['avg_binary_log_loss']) < best_loss:\n",
    "                    best_model = lgbm_model\n",
    "                    best_info = lgbm_info\n",
    "                    best_loss = np.min(lgbm_info['valid']['avg_binary_log_loss'])\n",
    "                    \n",
    "                best_valid_iter = np.argmin(lgbm_info['valid']['avg_binary_log_loss'])\n",
    "                \n",
    "                # update experimental results\n",
    "                exp = exp.append({'num_trees': num_trees, \n",
    "                                  'learning_rate':learning_rate,\n",
    "                                  'num_leaves':num_leaves, \n",
    "                                  'best_round':best_valid_iter+1, \n",
    "                                  'avg_binary_log_loss':lgbm_info['valid']['avg_binary_log_loss'][best_valid_iter]},\n",
    "                                 ignore_index=True)\n",
    "                \n",
    "        \n",
    "        # save file\n",
    "        best_valid_iter = np.argmin(best_info['valid']['avg_binary_log_loss'])\n",
    "\n",
    "        model_file_name = \"{:s}_T{:d}_S{:04d}_L{:d}_R{:d}.model\".format(output_model_file,\n",
    "                                                                        num_trees,\n",
    "                                                                        int(learning_rate*1000),\n",
    "                                                                        num_leaves,\n",
    "                                                                        best_valid_iter + 1\n",
    "                                                                       )\n",
    "        \n",
    "        best_model.save_model(model_file_name, num_iteration=best_valid_iter+1)\n",
    "        print (\"Model saved to\", model_file_name)\n",
    "\n",
    "    \n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable/disable LGBM Baseline\n",
    "if True:\n",
    "    experiments = train_gradient_boosting_baseline(\"../data/census/train_ori.csv.bz2\",\n",
    "                                                     \"../data/census/valid_ori.csv.bz2\",\n",
    "                                                     \"../data/census/test_ori.csv.bz2\",\n",
    "                                                     \"../out/models/std_gbdt_census\")  \n",
    "\n",
    "    experiments.to_csv('../out/models/std_gbdt_census.csv', index=False)\n",
    "\n",
    "    print (experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Adversarial Boosting (_baseline 2_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adversarial_boosting(train_file, valid_file, test_file, output_model_file):\n",
    "    \n",
    "    exp = pd.DataFrame(columns=['num_trees', 'learning_rate', 'num_leaves', 'best_round', 'avg_binary_log_loss'])\n",
    "    \n",
    "    # load train/valid/test\n",
    "    train, valid, test, cat_fx = load_atk_train_valid_test(train_file, valid_file, test_file)\n",
    "\n",
    "    # get index of categorical features \n",
    "    cat_fx = np.where(train.columns.isin(cat_fx) )[0]\n",
    "    cat_fx = list([int(x) for x in cat_fx])  \n",
    "    print (\"CatFX:\", train.columns.values[cat_fx])\n",
    "    \n",
    "\n",
    "    for num_trees in [50, 100, 150, 200, 250]:\n",
    "        for learning_rate in [0.001, 0.01, 0.1, 1.0]:\n",
    "            for num_leaves in [8, 16, 24]:\n",
    "                      \n",
    "                lgbm_params = { 'learning_rate': learning_rate, \n",
    "                                'num_leaves': num_leaves} \n",
    "                \n",
    "                lgbm_model, lgbm_info, best_loss, best_valid_iter = AdvBoosting(train,\n",
    "                                                    valid,\n",
    "                                                    trees=num_trees, \n",
    "                                                    cat_fx = cat_fx, \n",
    "                                                    output_model_file=output_model_file, \n",
    "                                                    adv_rounds=1,\n",
    "                                                    params=lgbm_params)\n",
    "                \n",
    "\n",
    "                # update experimental results\n",
    "                exp = exp.append({'num_trees': num_trees, \n",
    "                                  'learning_rate':learning_rate,\n",
    "                                  'num_leaves':num_leaves, \n",
    "                                  'best_round':best_valid_iter, \n",
    "                                  'avg_binary_log_loss':best_loss},\n",
    "                                 ignore_index=True)\n",
    "        \n",
    "        # save file\n",
    "        model_file_name = \"{:s}_T{:d}_S{:04d}_L{:d}_R{:d}.model\".format(output_model_file,\n",
    "                                                                                num_trees,\n",
    "                                                                                int(learning_rate*1000),\n",
    "                                                                                num_leaves,\n",
    "                                                                                best_valid_iter\n",
    "                                                                               )\n",
    "        lgbm_model.save_model(model_file_name, num_iteration=best_valid_iter)\n",
    "        print (\"Model saved to\", model_file_name)\n",
    "                \n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# enable/disable\n",
    "if True:\n",
    "    for B in [5, 15, 150, 300]:\n",
    "\n",
    "        experiments = train_adversarial_boosting ( \"../data/census/train_B{:d}.csv.bz2\".format(B),\n",
    "                                                   \"../data/census/valid_B{:d}.csv.bz2\".format(B),\n",
    "                                                   \"../data/census/test_B{:d}.csv.bz2\".format(B),\n",
    "                                                   \"../out/models/adv_boosting_census_B{:d}\".format(B))  \n",
    "\n",
    "        experiments.to_csv('../out/models/adv_boosting_census_B{:d}.csv'.format(B), index=False)\n",
    "\n",
    "        print (experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Non-Interferent GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_non_interferent(train_file, valid_file, test_file, output_model_file):\n",
    "    \n",
    "    exp = pd.DataFrame(columns=['num_trees', 'learning_rate', 'num_leaves', 'alpha', 'best_round', 'avg_binary_log_loss'])\n",
    "    \n",
    "    # load train/valid/test\n",
    "    train, valid, test, cat_fx = load_atk_train_valid_test(train_file, valid_file, test_file)\n",
    "\n",
    "    # get index of categorical features \n",
    "    cat_fx = np.where(train.columns.isin(cat_fx) )[0]\n",
    "    cat_fx = list([int(x) for x in cat_fx])  \n",
    "    print (\"CatFX:\", train.columns.values[cat_fx])\n",
    "    \n",
    "\n",
    "    for num_trees in [50, 100, 150, 200, 250]:\n",
    "        for alpha in [0.25, 0.50, 0.75, 1.00]:\n",
    "            best_model = None\n",
    "            best_info = None\n",
    "            best_loss = np.inf\n",
    "            awesome_hack = \"avg_non_interferent_log_loss\" + \" [alpha={:.2f}]\".format(alpha)\n",
    "            \n",
    "            for learning_rate in [0.001, 0.01, 0.1, 1.0]:\n",
    "                for num_leaves in [8, 16, 24]:\n",
    "                    # datasets\n",
    "                    lgbm_train = lightgbm.Dataset(data=train.values[:,:-1], \n",
    "                                                  label=train.values[:,-1],\n",
    "                                                  categorical_feature = cat_fx)\n",
    "\n",
    "                    lgbm_valid = lightgbm.Dataset(data=valid.values[:,:-1], \n",
    "                                                  label=valid.values[:,-1],\n",
    "                                                  categorical_feature = cat_fx)\n",
    "\n",
    "                    # run train\n",
    "                    lgbm_params = { 'learning_rate': learning_rate, \n",
    "                                    'num_leaves': num_leaves} \n",
    "                    lgbm_info = {}\n",
    "                    lgbm_model = lightgbm.train(lgbm_params, lgbm_train, \n",
    "                                                num_boost_round = num_trees,\n",
    "                                                fobj            = functools.partial(optimize_non_interferent_log_loss, alpha=alpha),\n",
    "                                                feval           = functools.partial(avg_non_interferent_log_loss, alpha=alpha),\n",
    "                                                evals_result    = lgbm_info,\n",
    "                                                valid_sets      = [lgbm_train, lgbm_valid], \n",
    "                                                valid_names     = ['train', 'valid'],\n",
    "                                                verbose_eval    = 25)\n",
    "                    \n",
    "                    \n",
    "                    if np.min(lgbm_info['valid'][awesome_hack]) < best_loss:\n",
    "                        best_model = lgbm_model\n",
    "                        best_info = lgbm_info\n",
    "                        best_loss = np.min(lgbm_info['valid'][awesome_hack])\n",
    "                \n",
    "\n",
    "                    # save file\n",
    "                    \n",
    "                    best_valid_iter = np.argmin(lgbm_info['valid'][awesome_hack])\n",
    "\n",
    "                    # update experimental results\n",
    "                    exp = exp.append({'num_trees': num_trees, \n",
    "                                      'learning_rate':learning_rate,\n",
    "                                      'num_leaves':num_leaves, \n",
    "                                      'alpha': alpha,\n",
    "                                      'best_round':best_valid_iter+1, \n",
    "                                      'avg_binary_log_loss':lgbm_info['valid'][awesome_hack][best_valid_iter]},\n",
    "                                     ignore_index=True)\n",
    "            \n",
    "            best_valid_iter = np.argmin(best_info['valid'][awesome_hack])\n",
    "            \n",
    "            model_file_name = \"{:s}_T{:d}_S{:04d}_L{:d}_A{:03d}_R{:d}.model\".format(output_model_file,\n",
    "                                                                                    num_trees,\n",
    "                                                                                    int(learning_rate*1000),\n",
    "                                                                                    num_leaves,\n",
    "                                                                                    int(alpha * 100),\n",
    "                                                                                    best_valid_iter + 1\n",
    "                                                                                   )\n",
    "            best_model.save_model(model_file_name, num_iteration=best_valid_iter+1)\n",
    "            print (\"Model saved to\", model_file_name)\n",
    "            \n",
    "                    \n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable/disable\n",
    "if True:\n",
    "    for B in [5, 15, 150, 300]:\n",
    "\n",
    "        experiments = train_non_interferent(\"../data/census/train_B{:d}.csv.bz2\".format(B),\n",
    "                                                   \"../data/census/valid_B{:d}.csv.bz2\".format(B),\n",
    "                                                   \"../data/census/test_B{:d}.csv.bz2\".format(B),\n",
    "                                                   \"../out/models/non_interferent_census_B{:d}\".format(B))  \n",
    "\n",
    "        experiments.to_csv('../out/models/non_interferent_census_B{:d}.csv'.format(B), index=False)\n",
    "\n",
    "        print (experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(train_file, valid_file, test_file, output_model_file):\n",
    "    \n",
    "    exp = pd.DataFrame(columns=['C', 'avg_binary_log_loss'])\n",
    "    \n",
    "    # load train/valid/test\n",
    "    train, valid, test, cat_fx = load_atk_train_valid_test(train_file, valid_file, test_file)\n",
    "    X_train = train.iloc[:,:-1].values\n",
    "    y_train = train.iloc[:,-1].values\n",
    "    y_train[y_train == -1] = 0\n",
    "    \n",
    "    X_valid = valid.iloc[:,:-1].values\n",
    "    y_valid = valid.iloc[:,-1].values\n",
    "    \n",
    "    for c in [0.01, 0.1, 1, 10]:\n",
    "        \n",
    "        model = SVC(kernel='rbf', probability=True)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_preds = model.predict_proba(X_valid)[:,0]\n",
    "        cur_avg_binary_log_loss = np.mean(binary_log_loss(y_preds, y_valid))\n",
    "        \n",
    "        model_file_name = \"{:s}_C{:04d}.model\".format(output_model_file, int(c * 1000))\n",
    "        \n",
    "        with open(model_file_name, 'wb') as fout:\n",
    "            pickle.dump(model, fout)\n",
    "        \n",
    "        print (\"Model saved to\", model_file_name)\n",
    "        \n",
    "        # update experimental results\n",
    "        exp = exp.append({'C': c, \n",
    "                          'avg_binary_log_loss':cur_avg_binary_log_loss},\n",
    "                         ignore_index=True)\n",
    "    \n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable/disable LGBM Baseline\n",
    "if True:\n",
    "    experiments = train_svm ( \"../data/census/train_ori.csv.bz2\",\n",
    "                                                     \"../data/census/valid_ori.csv.bz2\",\n",
    "                                                     \"../data/census/test_ori.csv.bz2\",\n",
    "                                                     \"../out/models/svm_census\")  \n",
    "\n",
    "    experiments.to_csv('../out/models/svm_census.csv', index=False)\n",
    "\n",
    "    print (experiments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
