{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path to dataset files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"wine\"\n",
    "PATH=\"../data/{}\".format(DATASET_NAME)\n",
    "TRAINING_SET=\"train.csv\"\n",
    "VALIDATION_SET=\"valid.csv\"\n",
    "TEST_SET=\"test.csv\"\n",
    "N_TRAIN_INSTANCES=None # replace this with None to load the whole training set\n",
    "N_TEST_INSTANCES=None # replace this with None to load the whole test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column names (i.e., features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides', 'free_sulfur_dioxide',\n",
    "            'total_sulfur_dioxide', 'density', 'pH', 'sulphites', 'alcohol', 'is_white', 'quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, \n",
    "                 dataset_filename, \n",
    "                 sep=\",\", \n",
    "                 header=None,\n",
    "                 nrows=None,\n",
    "                 names=colnames, \n",
    "                 index_col=False, \n",
    "                 na_values='?'):\n",
    "    \n",
    "    return pd.read_csv(path+\"/\"+dataset_filename, \n",
    "                       sep=sep, \n",
    "                       header=header,\n",
    "                       nrows=nrows,\n",
    "                       names=colnames, \n",
    "                       index_col=index_col, \n",
    "                       na_values='?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_dataset(PATH, TRAINING_SET, header=0, nrows=N_TRAIN_INSTANCES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Shape of training set: {}\".format(train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = load_dataset(PATH, VALIDATION_SET, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Shape of validation set: {}\".format(valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_dataset(PATH, TEST_SET, header=0, nrows=N_TEST_INSTANCES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Shape of test set: {}\".format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_data(data, label, threshold):\n",
    "    \n",
    "    data[label] = np.where(data[label] >= threshold, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarize_data(train, \"quality\", 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarize_data(valid, \"quality\", 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarize_data(test, \"quality\", 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perturbing dataset\n",
    "\n",
    "Let $\\mathcal{D} = \\{(\\mathbf{x_i}, y_i)\\}_{i=\\{1,\\ldots, m\\}}$ be the dataset of interest, where $\\mathbf{x_i} \\subseteq \\mathbb{R}^n = (x_{i,1}, \\ldots, x_{i,n})^T$.\n",
    "\n",
    "Use the set of rules defined above to perturb every single instance $(\\mathbf{x_i}, y_i)\\in \\mathcal{D}$.\n",
    "\n",
    "In general, one could assume the attacker has a budget $b_i$ for perturbing the instance $(\\mathbf{x_i}, y_i)$, therefore the overall budget $B$ of the attacker is $B = \\sum_{i=1}^m b_i$. \n",
    "\n",
    "Moreover, each feature $x_{*,j}$ is associated with a cost $c_j$ which the attacker has to pay in order to perturb exactly the $j$-th feature.\n",
    "\n",
    "In this first (simplified) attempt, we assume the attacker has full budget at its disposal for perturbing every instance, and the cost of perturbing an individual feature is the same for all features; in other words, $b_i = B~\\forall i=1,\\ldots,m$ and $c_j = C~\\forall j=1,\\dots,n$ (e.g., $C = 1$ _budget unit_). \n",
    "\n",
    "It turns out the _actual_ total budget available to the attacker is $m\\cdot B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_alcohol(x):\n",
    "    x_copy = x.copy()\n",
    "    if x_copy['alcohol'] <= 10.0:\n",
    "        x_copy['alcohol'] += 0.75\n",
    "        \n",
    "    return x_copy\n",
    "    \n",
    "def perturb_residual_sugar(x):\n",
    "    x_copy = x.copy()\n",
    "    if x_copy['residual_sugar'] >= 8.0:\n",
    "        x_copy['residual_sugar'] -= 1.2\n",
    "        \n",
    "    return x_copy\n",
    "    \n",
    "def perturb_volatile_acidity(x):\n",
    "    x_copy = x.copy()\n",
    "    if x_copy['volatile_acidity'] >= 0.6:\n",
    "        x_copy['volatile_acidity'] -= 0.3\n",
    "    \n",
    "    return x_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains(ls, x):\n",
    "    \"\"\"\n",
    "    Returns if a pandas.Series object (x) belongs to a list of pandas.Series objects (ls).\n",
    "\n",
    "    This function takes as input list of pandas.Series objects (ls) and returns True\n",
    "    if this contains the second input argument (i.e., the pandas.Series object x), False otherwise.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ls : list\n",
    "        A list of pandas.Series objects\n",
    "\n",
    "    x : pandas.Series\n",
    "        A series object\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "\n",
    "    \"\"\"\n",
    "    if not ls:\n",
    "        return False\n",
    "    for s in ls:\n",
    "        if s.equals(x):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_empty(queue):\n",
    "    return len(queue) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_equal_perturbation(a, b):\n",
    "    return a[0].equals(b[0]) and a[1] == b[1] and a[2] == b[2]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_instance(x, x_id, features, budget, max_budget_per_feature, costs, skip_class=1):\n",
    "    \"\"\"\n",
    "    Returns the set of possible perturbations of a given instance.\n",
    "\n",
    "    This function takes as input an instance and returns a set of perturbations of that instance, \n",
    "    using the specified amount of budget and considering the cost of perturbing each individual feature.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : pandas.Series\n",
    "        The original instance\n",
    "    x_id : int\n",
    "        The instance identifier (will be the same for all perturbations associated with this instance)\n",
    "    features : list\n",
    "        The list of features which can be perturbed (i.e., those for which an attack rule is defined)\n",
    "    budget : float\n",
    "        The attacker's budget\n",
    "    max_budget_per_feature : dict\n",
    "        The maximum allowed amount of budget units that can be spend on each feature\n",
    "    costs : dict\n",
    "        A mapping between each feature and its cost of perturbation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        The set of perturbations (including the original instance, placed at the very beginning)\n",
    "    float\n",
    "        The residual budget available for the remaining instances of the original dataset\n",
    "        (At this stage, we assume each instance will get the same amount of budget, \n",
    "        i.e., the attacker is given back the full initial budget for perturbing each instance)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize the queue (FIFO) with both the original instance, the initial budget, and an empty dictionary of budget units spent so far\n",
    "    queue = [(x, budget, {})]\n",
    "    # visited perturbations\n",
    "    seen = [(x, budget, {})]\n",
    "    # initialize the set of perturbations of this instance with the empty list\n",
    "    perturbations = []\n",
    "    # caching already performed perturbations for a certain feature\n",
    "    feature_perturbations = {}\n",
    "    # save the inital budget\n",
    "    initial_budget = budget\n",
    "    \n",
    "    # loop until the queue is not empty\n",
    "    while not is_empty(queue):\n",
    "        item = queue.pop() # dequeue the first inserted element\n",
    "        x = item[0] # get the instance\n",
    "        b = item[1] # get the residual budget\n",
    "        budget_units_spent = item[2] # get the dictionary containing the amount of budget spent on each feature, so far\n",
    "        \n",
    "        #print(\"Dequeuing item from queue [current budget = {}]\".format(b))\n",
    "        \n",
    "        # if the set of perturbations does not contain already x\n",
    "        if not contains(perturbations, x):\n",
    "            perturbations.append(x) # append the transformed instance to the list of perturbations (NOTE: the first one will be the original - i.e., non-perturbed - instance)\n",
    "\n",
    "            \n",
    "#         if x[-1]==skip_class:\n",
    "#             continue\n",
    "            \n",
    "            \n",
    "        # loop through all the features subject to the set of attack rules\n",
    "        for f in features:\n",
    "            # check if there is enough budget to perform an attack on feature f\n",
    "            if costs[f] <= b and budget_units_spent.get(f, 0) + costs[f] <= max_budget_per_feature[f]: \n",
    "                # if so, just call off to the proper function, which will perturb x on f\n",
    "                # and returns the list of all perturbations from x on f\n",
    "                x_prime = globals()[\"perturb_\"+str(f)](x)\n",
    "                \n",
    "                # the perturbation of x on f is inserted into the queue (enqueued) only if the attack rule applies\n",
    "                # to check this, it is enough to test for equality between x_prime and x\n",
    "                if not x_prime.equals(x): # i.e., the rule applies to the current instance\n",
    "                    # only if x_prime != x (i.e., the rule applies) we can subtract from the current budget\n",
    "                    # the value of the cost of perturbing f\n",
    "                    updated_budget_units_spent = budget_units_spent.copy()\n",
    "                    # update the number of budget units spend on feature f\n",
    "                    if not f in updated_budget_units_spent:\n",
    "                        updated_budget_units_spent[f] = costs[f]\n",
    "                    else:\n",
    "                        updated_budget_units_spent[f] += costs[f]\n",
    "\n",
    "                    #print(\"Update budget units spent on feature [{}] [old budget units spent = {}; new budget units spent = {}]\"\n",
    "                    #      .format(f, budget_units_spent.get(f, 0), updated_budget_units_spent[f]))\n",
    "\n",
    "                    #print(\"Enqueue the current perturbation [initial budget = {}; residual budget = {}]\"\n",
    "                    #      .format(initial_budget, b - costs[f]))\n",
    "                    item = (x_prime, b - costs[f], updated_budget_units_spent)\n",
    "                    if not any(item_prime for item_prime in seen if is_equal_perturbation(item, item_prime)):\n",
    "                        queue.insert(0, item)\n",
    "                        seen.append(item)\n",
    "            \n",
    "            #print()\n",
    "        \n",
    "        \n",
    "    # print(\"Create the dataframe containing the computed perturbations of instance [ID = #{}]\".format(x_id))\n",
    "    perturbations_df = pd.DataFrame(perturbations)\n",
    "    perturbations_df.insert(loc=0, \n",
    "                                column=\"instance_id\", \n",
    "                                value=[x_id for i in range(perturbations_df.shape[0])], \n",
    "                                allow_duplicates=True)\n",
    "    \n",
    "    \n",
    "    return perturbations_df, initial_budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_dataset(data, budget, max_budget_per_feature, costs, features):\n",
    "    \"\"\"\n",
    "    Returns the dataset extended with all instance perturbations.\n",
    "\n",
    "    This function takes as input a dataset and returns another dataset which is obtained from the original\n",
    "    by adding all the possible perturbations an attacker with budget B can apply to every instance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas.DataFrame\n",
    "        The original dataset\n",
    "    features : list\n",
    "        The list of features which can be perturbed (i.e., those for which an attack rule is defined)\n",
    "    budget : float\n",
    "        The attacker's budget\n",
    "    max_budget_per_feature : dict\n",
    "        The maximum allowed amount of budget units that can be spend on each feature\n",
    "    costs : dict\n",
    "        A mapping between each feature and its cost of perturbation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        The perturbed dataset\n",
    "\n",
    "    \"\"\"\n",
    "    # check if the dataset is valid\n",
    "    if data is None or data.empty:\n",
    "        print(\"***** No dataset available! *****\\n\")\n",
    "        return # if not, just return None\n",
    "    # prepare the perturbed dataset to be returned, initially empty with an extra \"instance_id\" column\n",
    "    cols = [\"instance_id\"] + data.columns.tolist()\n",
    "    perturbed_data = pd.DataFrame(columns=cols)\n",
    "    \n",
    "    # start with instance_id = 1\n",
    "    instance_id = 1\n",
    "    \n",
    "    # loop through every single instance in the original dataset\n",
    "    print(\"***** Loop through all the original instances... *****\\n\")\n",
    "    for index, instance in data.iterrows():\n",
    "        if instance_id%100==0:\n",
    "            print(\"***** Trying to perturb instance [ID = #{}]... *****\\n\".format(instance_id))\n",
    "        # check if there is still some budget to spend before trying to perturb the current instance\n",
    "        #print(\"***** Checking if budget residual is positive... *****\\n\")\n",
    "        \n",
    "        if(budget):\n",
    "            #print(\"***** Budget residual = {} *****\\n\".format(budget))\n",
    "            # retrieve the set of perturbations obtained from the current instance, along with residual budget\n",
    "            # this is provided by calling off to the `perturb_instance` function\n",
    "            # print(\"***** Perturb instance [ID = #{}]... *****\\n\".format(instance_id))\n",
    "            perturbations, budget = perturb_instance(instance, instance_id, features, budget, max_budget_per_feature, costs)\n",
    "            # append the set of perturbations obtained from the current instance to the perturbed dataset\n",
    "            #print(\"***** Append the latest perturbations to the final dataset *****\\n\")\n",
    "            perturbed_data = perturbed_data.append(perturbations)\n",
    "            # move to the next instance_id\n",
    "            instance_id += 1\n",
    "            \n",
    "        # otherwise, the budget is exhausted \n",
    "        # (note that, at this stage, we are allowing the budget to be negative after the latest perturbation;\n",
    "        # a smoother strategy would be to check the residual budget before actually committing the perturbations)\n",
    "        else:\n",
    "            print(\"***** No more budget available! [budget residual = {}] *****\\n\".format(budget))\n",
    "            break\n",
    "        \n",
    "    # eventually, return the perturbed dataset\n",
    "    print(\"***** Return the final perturbed dataset *****\\n\")\n",
    "    return perturbed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of \"attackable\" features\n",
    "features = ['alcohol', 'residual_sugar', 'volatile_acidity']\n",
    "\n",
    "# dictionary containing the cost of perturbing each feature (in budget unit)\n",
    "costs = {\n",
    "    'alcohol'     : 10,\n",
    "    'residual_sugar': 10,\n",
    "    'volatile_acidity' : 10\n",
    "}\n",
    "\n",
    "# dictionary containing the maximum allowed amount of budget units that can be spent on each feature\n",
    "max_budget_per_feature = {\n",
    "    'alcohol'     : 100,\n",
    "    'residual_sugar': 100,\n",
    "    'volatile_acidity'    : 100\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serialize both original (\\_ori) and perturbed (\\_att) datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoke perturbation on the following datasets:\n",
    "\n",
    "-  Training set\n",
    "-  Validation set\n",
    "-  Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_dataset(p_data, \n",
    "                      path, \n",
    "                      dataset_filename, \n",
    "                      suffix, \n",
    "                      sep=\",\", \n",
    "                      compression=\"bz2\", \n",
    "                      index=False):\n",
    "    \n",
    "    p_data.to_csv(path+\"/\"+dataset_filename.split(\".\")[0]+suffix, \n",
    "                  sep=sep, \n",
    "                  compression=compression, \n",
    "                  index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialize_dataset(train, PATH, TRAINING_SET, \"_ori.csv.bz2\")\n",
    "serialize_dataset(valid, PATH, VALIDATION_SET, \"_ori.csv.bz2\")\n",
    "serialize_dataset(test, PATH, TEST_SET, \"_ori.csv.bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tutto\n",
    "# 2 gain + il resto\n",
    "# hours + education\n",
    "# fino a education\n",
    "B = [20, 30, 40]\n",
    "B = [20]\n",
    "\n",
    "for budget in B:\n",
    "    train_att = perturb_dataset(train, budget, max_budget_per_feature, costs, features)\n",
    "    valid_att = perturb_dataset(valid, budget, max_budget_per_feature, costs, features)\n",
    "    test_att = perturb_dataset(test, budget, max_budget_per_feature, costs, features)\n",
    "    \n",
    "    serialize_dataset(train_att, PATH, TRAINING_SET, \"_B{}\".format(budget)+\".csv.bz2\")\n",
    "    serialize_dataset(valid_att, PATH, VALIDATION_SET, \"_B{}\".format(budget)+\".csv.bz2\")\n",
    "    serialize_dataset(test_att, PATH, TEST_SET, \"_B{}\".format(budget)+\".csv.bz2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
