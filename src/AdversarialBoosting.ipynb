{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "\n",
    " - http://lightgbm.readthedocs.io/en/latest/\n",
    " - http://lightgbm.readthedocs.io/en/latest/Python-Intro.html\n",
    " - https://github.com/Microsoft/LightGBM/tree/master/examples/python-guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm\n",
    "import pickle\n",
    "import json\n",
    "import functools\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from nilib import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_adv_boosting_data(model, data, groups, num_atks=1):\n",
    "    ''' \n",
    "    model  : is the LightGBM Model\n",
    "    data   : data matrix with all valid attacks (last column is label)\n",
    "    groups : grouping of same attacked instance \n",
    "    returns the new data matrix and new groups\n",
    "    \n",
    "    WARNING: currently works only for binary classification\n",
    "    '''\n",
    "    # score the datataset\n",
    "    labels = data.iloc[:,-1]\n",
    "    \n",
    "    # check mispredictions\n",
    "    predictions = model.predict(data.iloc[:,:-1]) # exclude labels\n",
    "    matchings = labels * predictions\n",
    "    \n",
    "    # select original data + attacked instances\n",
    "    new_selected = [] # id of selected instances\n",
    "    new_groups   = []\n",
    "    \n",
    "    offset = 0\n",
    "    for g in groups:\n",
    "        if g==0:\n",
    "            print (\"Error !!!!\")\n",
    "        elif g==1:\n",
    "            # there are no attacks, just add original\n",
    "            new_selected += [offset]\n",
    "            new_groups   += [1]\n",
    "        else:\n",
    "            # get a slice of the matching scores\n",
    "            g_matchings = matchings[offset:offset+g]\n",
    "\n",
    "            # most misclassified (smallest margin)\n",
    "            # skip original\n",
    "            #adv_instance = np.argmin(g_matchings[1:])+1\n",
    "            adv_instances = np.argsort(g_matchings[1:])\n",
    "            adv_instances = adv_instances[:num_atks]\n",
    "            adv_instances += offset +1\n",
    "\n",
    "            # add original and adversarial\n",
    "            new_selected += [offset] + list(adv_instances)\n",
    "            new_groups   += [1 + len(adv_instances)]\n",
    "        \n",
    "        offset += g\n",
    "    \n",
    "    new_dataset = data.iloc[new_selected,:]\n",
    "    \n",
    "    return new_dataset, new_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_adv_boosting_model(train, valid, input_model=None, num_trees=1, params=None):\n",
    "    ''' \n",
    "    model  : is the LightGBM Model\n",
    "    data   : data matrix with all valid attacks (last column is label)\n",
    "    returns the new model (is model modified inplace?)\n",
    "    '''\n",
    "    \n",
    "    assert train.shape[1]==valid.shape[1], \"Train/Valid Mismatch!\"\n",
    "\n",
    "    lgbm_train = lightgbm.Dataset(data=train.iloc[:,:-1], \n",
    "                                  label=train.iloc[:,-1])\n",
    "    \n",
    "    lgbm_valid = lightgbm.Dataset(data=valid.iloc[:,:-1], \n",
    "                                  label=valid.iloc[:,-1])\n",
    "    \n",
    "    lgbm_info = {}\n",
    "    lgbm_model = lightgbm.train(params, lgbm_train, \n",
    "                                num_boost_round = num_trees, \n",
    "                                init_model = input_model,\n",
    "#                                 fobj = optimize_log_loss,\n",
    "#                                 feval = avg_log_loss,\n",
    "                                evals_result = lgbm_info,\n",
    "                                valid_sets   = [lgbm_train, lgbm_valid], \n",
    "                                valid_names  = ['train', 'valid'],\n",
    "                                verbose_eval=1)\n",
    "\n",
    "    return lgbm_model, lgbm_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdvBoosting(atk_train, atk_valid, trees,\n",
    "                 params,\n",
    "                 output_model_file,\n",
    "                 partial_save=1000, \n",
    "                 adv_rounds=1):\n",
    "    ''' \n",
    "    atk_data: full dataset including all valid attacks\n",
    "    atk_groups: lenght of each attack set\n",
    "    trees: total number of trees to be produced\n",
    "    adv_rounds: adversarial instance injecting frequency\n",
    "    '''\n",
    "    # temp lgbm file\n",
    "    temp = output_model_file+\".tmp\"\n",
    "    \n",
    "    # get groups and remove instance ids\n",
    "    atk_groups = atk_train['instance_id'].value_counts().sort_index().values\n",
    "    atk_valid_groups = atk_valid['instance_id'].value_counts().sort_index().values\n",
    "    \n",
    "    # prepare data (avoiding pandas)\n",
    "    atk_data   = atk_train.iloc[:,1:] #.values\n",
    "    atk_valid  = atk_valid.iloc[:,1:] #.values\n",
    "\n",
    "    # train first trees\n",
    "    original_ids = np.cumsum(atk_groups[:-1])\n",
    "    original_ids = np.insert(original_ids, 0, 0)\n",
    "    \n",
    "    original_valid_ids = np.cumsum(atk_valid_groups[:-1])\n",
    "    original_valid_ids = np.insert(original_valid_ids, 0, 0)\n",
    "    \n",
    "    model, model_info = extend_adv_boosting_model(atk_data.iloc[original_ids, :], \n",
    "                                                  atk_valid.iloc[original_valid_ids, :],\n",
    "                                                  input_model=None, \n",
    "                                                  num_trees=adv_rounds, \n",
    "                                                  params=params)\n",
    "    \n",
    "    adopted_metric = list(model_info['valid'].keys())[0] #'avg_binary_log_loss', 'l2'    \n",
    "    best_model = model\n",
    "    best_info  = model_info\n",
    "    best_loss  = np.min(model_info['valid'][adopted_metric])\n",
    "    best_round = 1\n",
    "        \n",
    "    # train remaining trees\n",
    "    for t in range(adv_rounds+1, trees+1, adv_rounds):\n",
    "        # attack dataset\n",
    "        adv_data, _       = gen_adv_boosting_data(model, atk_data, atk_groups)\n",
    "        adv_valid_data, _ = gen_adv_boosting_data(model, atk_valid, atk_valid_groups)\n",
    "        \n",
    "        # train additional trees\n",
    "        model.save_model(temp)\n",
    "        model, model_info = extend_adv_boosting_model(adv_data, \n",
    "                                                      adv_valid_data,\n",
    "                                                      input_model=temp, \n",
    "                                                      num_trees=adv_rounds, \n",
    "                                                      params=params)\n",
    "\n",
    "        if np.min(model_info['valid'][adopted_metric]) < best_loss:\n",
    "            best_model = model\n",
    "            best_info  = model_info\n",
    "            best_loss  = np.min(model_info['valid'][adopted_metric])\n",
    "            best_round = t\n",
    "            \n",
    "    \n",
    "    return best_model, best_info, best_loss, best_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adversarial_boosting(train_file, valid_file, test_file, output_model_file):\n",
    "    \n",
    "    exp = pd.DataFrame(columns=['num_trees', 'learning_rate', 'num_leaves', 'best_round', 'metric', 'filename'])\n",
    "    \n",
    "    # load train/valid/test\n",
    "    train, valid, test = load_atk_train_valid_test(train_file, valid_file, test_file)\n",
    "    \n",
    "    # train = train.iloc[:1000, :]\n",
    "    \n",
    "    assert \"instance_id\" in train.columns.values, \"Wrong training set file for GBDT\"\n",
    "\n",
    "    for num_trees in [100]:\n",
    "        for learning_rate in [0.05]: #[0.01, 0.05]:\n",
    "            for num_leaves in [24, 2**8]: #[16, 24]:\n",
    "                      \n",
    "                lgbm_params = { 'learning_rate': learning_rate, \n",
    "                                'num_leaves': num_leaves , \n",
    "                                'max_depth': 8,\n",
    "                                'objective': 'regression'\n",
    "                              } \n",
    "                \n",
    "                lgbm_model, lgbm_info, best_loss, best_valid_iter = AdvBoosting(train,\n",
    "                                                    valid,\n",
    "                                                    trees=num_trees,\n",
    "                                                    output_model_file=output_model_file, \n",
    "                                                    adv_rounds=1,\n",
    "                                                    params=lgbm_params)\n",
    "                \n",
    "                # save file\n",
    "                model_file_name = \"{:s}_T{:d}_S{:04d}_L{:d}_R{:d}.model\".format(output_model_file,\n",
    "                                                                                        num_trees,\n",
    "                                                                                        int(learning_rate*1000),\n",
    "                                                                                        num_leaves,\n",
    "                                                                                        best_valid_iter\n",
    "                                                                                       )\n",
    "                ####\n",
    "                # update experimental results\n",
    "                exp = exp.append({'num_trees': num_trees, \n",
    "                                  'learning_rate':learning_rate,\n",
    "                                  'num_leaves':num_leaves, \n",
    "                                  'best_round':best_valid_iter, \n",
    "                                  'metric':best_loss,\n",
    "                                  'filename': model_file_name},\n",
    "                                 ignore_index=True)\n",
    "        \n",
    "                lgbm_model.save_model(model_file_name)\n",
    "                print (\"Model saved to\", model_file_name)\n",
    "                \n",
    "    return exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"wine\"\n",
    "TRAINING_BUDGETS= [10, 20,40] #30,60\n",
    "\n",
    "DATASET_DIR=\"../data/{}\".format(DATASET_NAME)\n",
    "ATK_DIR=DATASET_DIR + \"/attacks\"\n",
    "MODELS_DIR=\"../out/models/{}\".format(DATASET_NAME)\n",
    "TRAINING_FILENAME=DATASET_DIR + \"/\" + \"train.csv.bz2\"\n",
    "TRAINING_FILENAME_ATT=ATK_DIR + \"/\" + \"train_B{}.atks.bz2\"\n",
    "VALIDATION_FILENAME=DATASET_DIR + \"/\" + \"valid.csv.bz2\"\n",
    "VALIDATION_FILENAME_ATT=ATK_DIR + \"/\" + \"valid_B{}.atks.bz2\"\n",
    "TEST_FILENAME=DATASET_DIR + \"/\" + \"test.csv.bz2\"\n",
    "TEST_FILENAME_ATT=ATK_DIR + \"/\" + \"test_B{}.atks.bz2\"\n",
    "MODEL_FILENAME=MODELS_DIR + \"/adv-boosting_{}_B{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing original files...\n",
      "Loading: ../data/wine/attacks/train_B10.atks.bz2\n",
      "Loading: ../data/wine/attacks/valid_B10.atks.bz2\n",
      "Loading: ../data/wine/attacks/test_B10.atks.bz2\n",
      "Train/Valid/Test sizes: (78494, 14) (7042, 14) (15641, 14)\n",
      "Train/Valid/Test split: 0.78 0.07 0.15\n",
      "   ... with instance ids\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (66428, 14) (19108, 14) (15641, 14)\n",
      "Train/Valid/Test split: 0.66 0.19 0.15\n",
      "Saving processed files *.atks.bz2\n",
      "[1]\ttrain's l2: 0.89492\tvalid's l2: 0.920141\n",
      "[2]\ttrain's l2: 0.928658\tvalid's l2: 0.961194\n",
      "[3]\ttrain's l2: 0.907845\tvalid's l2: 0.942824\n",
      "[4]\ttrain's l2: 0.886699\tvalid's l2: 0.923684\n",
      "[5]\ttrain's l2: 0.865813\tvalid's l2: 0.904137\n",
      "[6]\ttrain's l2: 0.846282\tvalid's l2: 0.888428\n",
      "[7]\ttrain's l2: 0.827173\tvalid's l2: 0.872421\n",
      "[8]\ttrain's l2: 0.809373\tvalid's l2: 0.857892\n",
      "[9]\ttrain's l2: 0.79318\tvalid's l2: 0.845318\n",
      "[10]\ttrain's l2: 0.779445\tvalid's l2: 0.833873\n",
      "[11]\ttrain's l2: 0.765486\tvalid's l2: 0.822104\n",
      "[12]\ttrain's l2: 0.752646\tvalid's l2: 0.813103\n",
      "[13]\ttrain's l2: 0.743263\tvalid's l2: 0.805843\n",
      "[14]\ttrain's l2: 0.732432\tvalid's l2: 0.798417\n",
      "[15]\ttrain's l2: 0.722274\tvalid's l2: 0.790825\n",
      "[16]\ttrain's l2: 0.71278\tvalid's l2: 0.783684\n",
      "[17]\ttrain's l2: 0.703605\tvalid's l2: 0.7775\n",
      "[18]\ttrain's l2: 0.69825\tvalid's l2: 0.772726\n",
      "[19]\ttrain's l2: 0.688498\tvalid's l2: 0.76568\n",
      "[20]\ttrain's l2: 0.682661\tvalid's l2: 0.761322\n",
      "[21]\ttrain's l2: 0.67783\tvalid's l2: 0.757526\n",
      "[22]\ttrain's l2: 0.672309\tvalid's l2: 0.75513\n",
      "[23]\ttrain's l2: 0.67164\tvalid's l2: 0.754635\n",
      "[24]\ttrain's l2: 0.66832\tvalid's l2: 0.75258\n",
      "[25]\ttrain's l2: 0.66518\tvalid's l2: 0.749552\n",
      "[26]\ttrain's l2: 0.659407\tvalid's l2: 0.746892\n",
      "[27]\ttrain's l2: 0.659458\tvalid's l2: 0.745916\n",
      "[28]\ttrain's l2: 0.653275\tvalid's l2: 0.743752\n",
      "[29]\ttrain's l2: 0.650748\tvalid's l2: 0.741276\n",
      "[30]\ttrain's l2: 0.647502\tvalid's l2: 0.740313\n",
      "[31]\ttrain's l2: 0.641646\tvalid's l2: 0.737011\n",
      "[32]\ttrain's l2: 0.635537\tvalid's l2: 0.733744\n",
      "[33]\ttrain's l2: 0.630088\tvalid's l2: 0.730423\n",
      "[34]\ttrain's l2: 0.624805\tvalid's l2: 0.72672\n",
      "[35]\ttrain's l2: 0.62009\tvalid's l2: 0.724608\n",
      "[36]\ttrain's l2: 0.614771\tvalid's l2: 0.721778\n",
      "[37]\ttrain's l2: 0.609724\tvalid's l2: 0.717701\n",
      "[38]\ttrain's l2: 0.604873\tvalid's l2: 0.714812\n",
      "[39]\ttrain's l2: 0.600892\tvalid's l2: 0.713021\n",
      "[40]\ttrain's l2: 0.5968\tvalid's l2: 0.710601\n",
      "[41]\ttrain's l2: 0.592723\tvalid's l2: 0.708589\n",
      "[42]\ttrain's l2: 0.588211\tvalid's l2: 0.705872\n",
      "[43]\ttrain's l2: 0.584045\tvalid's l2: 0.703781\n",
      "[44]\ttrain's l2: 0.580141\tvalid's l2: 0.70079\n",
      "[45]\ttrain's l2: 0.576378\tvalid's l2: 0.699149\n",
      "[46]\ttrain's l2: 0.572487\tvalid's l2: 0.697478\n",
      "[47]\ttrain's l2: 0.568658\tvalid's l2: 0.695196\n",
      "[48]\ttrain's l2: 0.565313\tvalid's l2: 0.69361\n",
      "[49]\ttrain's l2: 0.561318\tvalid's l2: 0.691055\n",
      "[50]\ttrain's l2: 0.558235\tvalid's l2: 0.690065\n",
      "[51]\ttrain's l2: 0.554861\tvalid's l2: 0.687015\n",
      "[52]\ttrain's l2: 0.552073\tvalid's l2: 0.685642\n",
      "[53]\ttrain's l2: 0.548581\tvalid's l2: 0.683059\n",
      "[54]\ttrain's l2: 0.545873\tvalid's l2: 0.682371\n",
      "[55]\ttrain's l2: 0.542445\tvalid's l2: 0.680632\n",
      "[56]\ttrain's l2: 0.539956\tvalid's l2: 0.679768\n",
      "[57]\ttrain's l2: 0.537531\tvalid's l2: 0.678876\n",
      "[58]\ttrain's l2: 0.534303\tvalid's l2: 0.677741\n",
      "[59]\ttrain's l2: 0.531274\tvalid's l2: 0.676052\n",
      "[60]\ttrain's l2: 0.52869\tvalid's l2: 0.675131\n",
      "[61]\ttrain's l2: 0.526162\tvalid's l2: 0.674801\n",
      "[62]\ttrain's l2: 0.524275\tvalid's l2: 0.674577\n",
      "[63]\ttrain's l2: 0.522324\tvalid's l2: 0.674066\n",
      "[64]\ttrain's l2: 0.519386\tvalid's l2: 0.672352\n",
      "[65]\ttrain's l2: 0.5173\tvalid's l2: 0.671831\n",
      "[66]\ttrain's l2: 0.514768\tvalid's l2: 0.671338\n",
      "[67]\ttrain's l2: 0.512968\tvalid's l2: 0.670693\n",
      "[68]\ttrain's l2: 0.510467\tvalid's l2: 0.669431\n",
      "[69]\ttrain's l2: 0.508607\tvalid's l2: 0.669427\n",
      "[70]\ttrain's l2: 0.506712\tvalid's l2: 0.668637\n",
      "[71]\ttrain's l2: 0.504959\tvalid's l2: 0.667454\n",
      "[72]\ttrain's l2: 0.503269\tvalid's l2: 0.666806\n",
      "[73]\ttrain's l2: 0.502313\tvalid's l2: 0.667022\n",
      "[74]\ttrain's l2: 0.500626\tvalid's l2: 0.666209\n",
      "[75]\ttrain's l2: 0.497964\tvalid's l2: 0.665543\n",
      "[76]\ttrain's l2: 0.495644\tvalid's l2: 0.664268\n",
      "[77]\ttrain's l2: 0.49387\tvalid's l2: 0.664155\n",
      "[78]\ttrain's l2: 0.491692\tvalid's l2: 0.663855\n",
      "[79]\ttrain's l2: 0.489328\tvalid's l2: 0.662476\n",
      "[80]\ttrain's l2: 0.487488\tvalid's l2: 0.662004\n",
      "[81]\ttrain's l2: 0.485407\tvalid's l2: 0.661457\n",
      "[82]\ttrain's l2: 0.483471\tvalid's l2: 0.66069\n",
      "[83]\ttrain's l2: 0.481515\tvalid's l2: 0.660773\n",
      "[84]\ttrain's l2: 0.479576\tvalid's l2: 0.659997\n",
      "[85]\ttrain's l2: 0.477498\tvalid's l2: 0.659876\n",
      "[86]\ttrain's l2: 0.475785\tvalid's l2: 0.660025\n",
      "[87]\ttrain's l2: 0.473801\tvalid's l2: 0.659444\n",
      "[88]\ttrain's l2: 0.471909\tvalid's l2: 0.658792\n",
      "[89]\ttrain's l2: 0.469939\tvalid's l2: 0.658157\n",
      "[90]\ttrain's l2: 0.467869\tvalid's l2: 0.65769\n",
      "[91]\ttrain's l2: 0.466923\tvalid's l2: 0.657358\n",
      "[92]\ttrain's l2: 0.4656\tvalid's l2: 0.657306\n",
      "[93]\ttrain's l2: 0.463891\tvalid's l2: 0.656846\n",
      "[94]\ttrain's l2: 0.462058\tvalid's l2: 0.656753\n",
      "[95]\ttrain's l2: 0.46047\tvalid's l2: 0.656911\n",
      "[96]\ttrain's l2: 0.458382\tvalid's l2: 0.655968\n",
      "[97]\ttrain's l2: 0.456954\tvalid's l2: 0.655233\n",
      "[98]\ttrain's l2: 0.45529\tvalid's l2: 0.655014\n",
      "[99]\ttrain's l2: 0.453693\tvalid's l2: 0.654474\n",
      "[100]\ttrain's l2: 0.452069\tvalid's l2: 0.653797\n",
      "Model saved to ../out/models/wine/adv-boosting_wine_B10_T100_S0050_L24_R100.model\n",
      "[1]\ttrain's l2: 0.887122\tvalid's l2: 0.915997\n",
      "[2]\ttrain's l2: 0.913737\tvalid's l2: 0.956728\n",
      "[3]\ttrain's l2: 0.883429\tvalid's l2: 0.933595\n",
      "[4]\ttrain's l2: 0.853702\tvalid's l2: 0.911066\n",
      "[5]\ttrain's l2: 0.824302\tvalid's l2: 0.889712\n",
      "[6]\ttrain's l2: 0.799653\tvalid's l2: 0.87434\n",
      "[7]\ttrain's l2: 0.776828\tvalid's l2: 0.857257\n",
      "[8]\ttrain's l2: 0.752454\tvalid's l2: 0.841692\n",
      "[9]\ttrain's l2: 0.731922\tvalid's l2: 0.828403\n",
      "[10]\ttrain's l2: 0.713419\tvalid's l2: 0.816268\n",
      "[11]\ttrain's l2: 0.691518\tvalid's l2: 0.803361\n",
      "[12]\ttrain's l2: 0.670857\tvalid's l2: 0.792262\n",
      "[13]\ttrain's l2: 0.653804\tvalid's l2: 0.782137\n",
      "[14]\ttrain's l2: 0.637973\tvalid's l2: 0.774293\n",
      "[15]\ttrain's l2: 0.621956\tvalid's l2: 0.764665\n",
      "[16]\ttrain's l2: 0.607668\tvalid's l2: 0.756567\n",
      "[17]\ttrain's l2: 0.598125\tvalid's l2: 0.752549\n",
      "[18]\ttrain's l2: 0.586347\tvalid's l2: 0.747674\n",
      "[19]\ttrain's l2: 0.574707\tvalid's l2: 0.741219\n",
      "[20]\ttrain's l2: 0.56203\tvalid's l2: 0.736356\n",
      "[21]\ttrain's l2: 0.553477\tvalid's l2: 0.731386\n",
      "[22]\ttrain's l2: 0.543531\tvalid's l2: 0.726585\n",
      "[23]\ttrain's l2: 0.53334\tvalid's l2: 0.721676\n",
      "[24]\ttrain's l2: 0.525492\tvalid's l2: 0.71756\n",
      "[25]\ttrain's l2: 0.516288\tvalid's l2: 0.714325\n",
      "[26]\ttrain's l2: 0.509525\tvalid's l2: 0.711421\n",
      "[27]\ttrain's l2: 0.501707\tvalid's l2: 0.707245\n",
      "[28]\ttrain's l2: 0.494607\tvalid's l2: 0.703987\n",
      "[29]\ttrain's l2: 0.48882\tvalid's l2: 0.701496\n",
      "[30]\ttrain's l2: 0.483142\tvalid's l2: 0.699704\n",
      "[31]\ttrain's l2: 0.478418\tvalid's l2: 0.69804\n",
      "[32]\ttrain's l2: 0.472553\tvalid's l2: 0.69552\n",
      "[33]\ttrain's l2: 0.464712\tvalid's l2: 0.691641\n",
      "[34]\ttrain's l2: 0.458885\tvalid's l2: 0.689128\n",
      "[35]\ttrain's l2: 0.455415\tvalid's l2: 0.68853\n",
      "[36]\ttrain's l2: 0.452854\tvalid's l2: 0.686826\n",
      "[37]\ttrain's l2: 0.44835\tvalid's l2: 0.684841\n",
      "[38]\ttrain's l2: 0.441955\tvalid's l2: 0.681613\n",
      "[39]\ttrain's l2: 0.436365\tvalid's l2: 0.680014\n",
      "[40]\ttrain's l2: 0.431931\tvalid's l2: 0.678015\n",
      "[41]\ttrain's l2: 0.427103\tvalid's l2: 0.675109\n",
      "[42]\ttrain's l2: 0.422605\tvalid's l2: 0.674775\n",
      "[43]\ttrain's l2: 0.419356\tvalid's l2: 0.673168\n",
      "[44]\ttrain's l2: 0.416555\tvalid's l2: 0.671575\n",
      "[45]\ttrain's l2: 0.412021\tvalid's l2: 0.669374\n",
      "[46]\ttrain's l2: 0.408912\tvalid's l2: 0.668401\n",
      "[47]\ttrain's l2: 0.40563\tvalid's l2: 0.66686\n",
      "[48]\ttrain's l2: 0.400399\tvalid's l2: 0.665057\n",
      "[49]\ttrain's l2: 0.398021\tvalid's l2: 0.665533\n",
      "[50]\ttrain's l2: 0.396167\tvalid's l2: 0.664311\n",
      "[51]\ttrain's l2: 0.393569\tvalid's l2: 0.663573\n",
      "[52]\ttrain's l2: 0.391354\tvalid's l2: 0.662422\n",
      "[53]\ttrain's l2: 0.386465\tvalid's l2: 0.660602\n",
      "[54]\ttrain's l2: 0.384636\tvalid's l2: 0.659664\n",
      "[55]\ttrain's l2: 0.380157\tvalid's l2: 0.658729\n",
      "[56]\ttrain's l2: 0.378255\tvalid's l2: 0.65777\n",
      "[57]\ttrain's l2: 0.374596\tvalid's l2: 0.656498\n",
      "[58]\ttrain's l2: 0.373007\tvalid's l2: 0.655472\n",
      "[59]\ttrain's l2: 0.369875\tvalid's l2: 0.654386\n",
      "[60]\ttrain's l2: 0.367075\tvalid's l2: 0.652836\n",
      "[61]\ttrain's l2: 0.365372\tvalid's l2: 0.651794\n",
      "[62]\ttrain's l2: 0.36046\tvalid's l2: 0.650152\n",
      "[63]\ttrain's l2: 0.359503\tvalid's l2: 0.649663\n",
      "[64]\ttrain's l2: 0.354827\tvalid's l2: 0.647449\n",
      "[65]\ttrain's l2: 0.352201\tvalid's l2: 0.647307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66]\ttrain's l2: 0.349089\tvalid's l2: 0.6461\n",
      "[67]\ttrain's l2: 0.346476\tvalid's l2: 0.645193\n",
      "[68]\ttrain's l2: 0.34438\tvalid's l2: 0.644985\n",
      "[69]\ttrain's l2: 0.341867\tvalid's l2: 0.644159\n",
      "[70]\ttrain's l2: 0.339984\tvalid's l2: 0.644726\n",
      "[71]\ttrain's l2: 0.337901\tvalid's l2: 0.644567\n",
      "[72]\ttrain's l2: 0.334381\tvalid's l2: 0.644345\n",
      "[73]\ttrain's l2: 0.333408\tvalid's l2: 0.64411\n",
      "[74]\ttrain's l2: 0.332156\tvalid's l2: 0.643588\n",
      "[75]\ttrain's l2: 0.331743\tvalid's l2: 0.643585\n",
      "[76]\ttrain's l2: 0.329864\tvalid's l2: 0.64332\n",
      "[77]\ttrain's l2: 0.327467\tvalid's l2: 0.643075\n",
      "[78]\ttrain's l2: 0.32386\tvalid's l2: 0.642201\n",
      "[79]\ttrain's l2: 0.322727\tvalid's l2: 0.642357\n",
      "[80]\ttrain's l2: 0.321006\tvalid's l2: 0.641474\n",
      "[81]\ttrain's l2: 0.318631\tvalid's l2: 0.641812\n",
      "[82]\ttrain's l2: 0.317549\tvalid's l2: 0.642072\n",
      "[83]\ttrain's l2: 0.316607\tvalid's l2: 0.642212\n",
      "[84]\ttrain's l2: 0.314915\tvalid's l2: 0.642316\n",
      "[85]\ttrain's l2: 0.312559\tvalid's l2: 0.64127\n",
      "[86]\ttrain's l2: 0.310828\tvalid's l2: 0.6416\n",
      "[87]\ttrain's l2: 0.309382\tvalid's l2: 0.641271\n",
      "[88]\ttrain's l2: 0.307752\tvalid's l2: 0.640791\n",
      "[89]\ttrain's l2: 0.306486\tvalid's l2: 0.640759\n",
      "[90]\ttrain's l2: 0.305965\tvalid's l2: 0.641111\n",
      "[91]\ttrain's l2: 0.30396\tvalid's l2: 0.640767\n",
      "[92]\ttrain's l2: 0.303446\tvalid's l2: 0.640894\n",
      "[93]\ttrain's l2: 0.301592\tvalid's l2: 0.640673\n",
      "[94]\ttrain's l2: 0.299772\tvalid's l2: 0.64052\n",
      "[95]\ttrain's l2: 0.298383\tvalid's l2: 0.641242\n",
      "[96]\ttrain's l2: 0.297013\tvalid's l2: 0.640939\n",
      "[97]\ttrain's l2: 0.296507\tvalid's l2: 0.640805\n",
      "[98]\ttrain's l2: 0.295842\tvalid's l2: 0.641076\n",
      "[99]\ttrain's l2: 0.294083\tvalid's l2: 0.640174\n",
      "[100]\ttrain's l2: 0.291191\tvalid's l2: 0.638942\n",
      "Model saved to ../out/models/wine/adv-boosting_wine_B10_T100_S0050_L256_R100.model\n",
      "  num_trees  learning_rate num_leaves best_round    metric  \\\n",
      "0       100           0.05         24        100  0.653797   \n",
      "1       100           0.05        256        100  0.638942   \n",
      "\n",
      "                                            filename  \n",
      "0  ../out/models/wine/adv-boosting_wine_B10_T100_...  \n",
      "1  ../out/models/wine/adv-boosting_wine_B10_T100_...  \n",
      "best model is: ../out/models/wine/adv-boosting_wine_B10_T100_S0050_L256_R100.model\n",
      "Pre-processing original files...\n",
      "Loading: ../data/wine/attacks/train_B20.atks.bz2\n",
      "Loading: ../data/wine/attacks/valid_B20.atks.bz2\n",
      "Loading: ../data/wine/attacks/test_B20.atks.bz2\n",
      "Train/Valid/Test sizes: (582734, 14) (35859, 14) (84936, 14)\n",
      "Train/Valid/Test split: 0.83 0.05 0.12\n",
      "   ... with instance ids\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (495137, 14) (123456, 14) (84936, 14)\n",
      "Train/Valid/Test split: 0.70 0.18 0.12\n",
      "Saving processed files *.atks.bz2\n",
      "[1]\ttrain's l2: 0.89492\tvalid's l2: 0.920141\n",
      "[2]\ttrain's l2: 0.934048\tvalid's l2: 0.964099\n",
      "[3]\ttrain's l2: 0.916969\tvalid's l2: 0.949218\n",
      "[4]\ttrain's l2: 0.901573\tvalid's l2: 0.933674\n",
      "[5]\ttrain's l2: 0.886018\tvalid's l2: 0.922187\n",
      "[6]\ttrain's l2: 0.873835\tvalid's l2: 0.90909\n",
      "[7]\ttrain's l2: 0.858165\tvalid's l2: 0.897022\n",
      "[8]\ttrain's l2: 0.842379\tvalid's l2: 0.882581\n",
      "[9]\ttrain's l2: 0.827752\tvalid's l2: 0.870408\n",
      "[10]\ttrain's l2: 0.813442\tvalid's l2: 0.859386\n",
      "[11]\ttrain's l2: 0.801572\tvalid's l2: 0.849713\n",
      "[12]\ttrain's l2: 0.788987\tvalid's l2: 0.839038\n",
      "[13]\ttrain's l2: 0.778281\tvalid's l2: 0.831403\n",
      "[14]\ttrain's l2: 0.766447\tvalid's l2: 0.82308\n",
      "[15]\ttrain's l2: 0.754185\tvalid's l2: 0.814225\n",
      "[16]\ttrain's l2: 0.743438\tvalid's l2: 0.805102\n",
      "[17]\ttrain's l2: 0.734895\tvalid's l2: 0.79849\n",
      "[18]\ttrain's l2: 0.725305\tvalid's l2: 0.790277\n",
      "[19]\ttrain's l2: 0.719065\tvalid's l2: 0.784816\n",
      "[20]\ttrain's l2: 0.714928\tvalid's l2: 0.78132\n",
      "[21]\ttrain's l2: 0.710476\tvalid's l2: 0.778294\n",
      "[22]\ttrain's l2: 0.707444\tvalid's l2: 0.776999\n",
      "[23]\ttrain's l2: 0.702752\tvalid's l2: 0.77422\n",
      "[24]\ttrain's l2: 0.70009\tvalid's l2: 0.77212\n",
      "[25]\ttrain's l2: 0.698193\tvalid's l2: 0.770662\n",
      "[26]\ttrain's l2: 0.695513\tvalid's l2: 0.769308\n",
      "[27]\ttrain's l2: 0.688646\tvalid's l2: 0.763995\n",
      "[28]\ttrain's l2: 0.681316\tvalid's l2: 0.759347\n",
      "[29]\ttrain's l2: 0.674849\tvalid's l2: 0.754394\n",
      "[30]\ttrain's l2: 0.668297\tvalid's l2: 0.750416\n",
      "[31]\ttrain's l2: 0.661908\tvalid's l2: 0.747229\n",
      "[32]\ttrain's l2: 0.656234\tvalid's l2: 0.743383\n",
      "[33]\ttrain's l2: 0.651034\tvalid's l2: 0.74085\n",
      "[34]\ttrain's l2: 0.645209\tvalid's l2: 0.737095\n",
      "[35]\ttrain's l2: 0.640738\tvalid's l2: 0.735093\n",
      "[36]\ttrain's l2: 0.635559\tvalid's l2: 0.732048\n",
      "[37]\ttrain's l2: 0.631028\tvalid's l2: 0.73016\n",
      "[38]\ttrain's l2: 0.626548\tvalid's l2: 0.727185\n",
      "[39]\ttrain's l2: 0.621824\tvalid's l2: 0.724539\n",
      "[40]\ttrain's l2: 0.617457\tvalid's l2: 0.721939\n",
      "[41]\ttrain's l2: 0.612464\tvalid's l2: 0.718776\n",
      "[42]\ttrain's l2: 0.608707\tvalid's l2: 0.716619\n",
      "[43]\ttrain's l2: 0.605097\tvalid's l2: 0.715034\n",
      "[44]\ttrain's l2: 0.600817\tvalid's l2: 0.713215\n",
      "[45]\ttrain's l2: 0.597549\tvalid's l2: 0.712326\n",
      "[46]\ttrain's l2: 0.593716\tvalid's l2: 0.710286\n",
      "[47]\ttrain's l2: 0.589309\tvalid's l2: 0.707739\n",
      "[48]\ttrain's l2: 0.586034\tvalid's l2: 0.705557\n",
      "[49]\ttrain's l2: 0.583132\tvalid's l2: 0.704598\n",
      "[50]\ttrain's l2: 0.579222\tvalid's l2: 0.703345\n",
      "[51]\ttrain's l2: 0.576321\tvalid's l2: 0.702625\n",
      "[52]\ttrain's l2: 0.572406\tvalid's l2: 0.700686\n",
      "[53]\ttrain's l2: 0.569041\tvalid's l2: 0.698974\n",
      "[54]\ttrain's l2: 0.566342\tvalid's l2: 0.697798\n",
      "[55]\ttrain's l2: 0.562806\tvalid's l2: 0.695719\n",
      "[56]\ttrain's l2: 0.559341\tvalid's l2: 0.694578\n",
      "[57]\ttrain's l2: 0.556621\tvalid's l2: 0.693009\n",
      "[58]\ttrain's l2: 0.553463\tvalid's l2: 0.69039\n",
      "[59]\ttrain's l2: 0.551523\tvalid's l2: 0.689528\n",
      "[60]\ttrain's l2: 0.55106\tvalid's l2: 0.689965\n",
      "[61]\ttrain's l2: 0.548355\tvalid's l2: 0.688931\n",
      "[62]\ttrain's l2: 0.545785\tvalid's l2: 0.688463\n",
      "[63]\ttrain's l2: 0.542974\tvalid's l2: 0.687514\n",
      "[64]\ttrain's l2: 0.540063\tvalid's l2: 0.68666\n",
      "[65]\ttrain's l2: 0.538191\tvalid's l2: 0.686118\n",
      "[66]\ttrain's l2: 0.536035\tvalid's l2: 0.685336\n",
      "[67]\ttrain's l2: 0.534029\tvalid's l2: 0.685956\n",
      "[68]\ttrain's l2: 0.531638\tvalid's l2: 0.685274\n",
      "[69]\ttrain's l2: 0.529366\tvalid's l2: 0.684696\n",
      "[70]\ttrain's l2: 0.526787\tvalid's l2: 0.683664\n",
      "[71]\ttrain's l2: 0.524487\tvalid's l2: 0.682958\n",
      "[72]\ttrain's l2: 0.522105\tvalid's l2: 0.682022\n",
      "[73]\ttrain's l2: 0.520155\tvalid's l2: 0.681592\n",
      "[74]\ttrain's l2: 0.517154\tvalid's l2: 0.680455\n",
      "[75]\ttrain's l2: 0.515213\tvalid's l2: 0.681389\n",
      "[76]\ttrain's l2: 0.512849\tvalid's l2: 0.680372\n",
      "[77]\ttrain's l2: 0.510667\tvalid's l2: 0.679063\n",
      "[78]\ttrain's l2: 0.50873\tvalid's l2: 0.679528\n",
      "[79]\ttrain's l2: 0.506682\tvalid's l2: 0.679118\n",
      "[80]\ttrain's l2: 0.504257\tvalid's l2: 0.677859\n",
      "[81]\ttrain's l2: 0.502139\tvalid's l2: 0.677457\n",
      "[82]\ttrain's l2: 0.500394\tvalid's l2: 0.676641\n",
      "[83]\ttrain's l2: 0.498398\tvalid's l2: 0.676191\n",
      "[84]\ttrain's l2: 0.49685\tvalid's l2: 0.676082\n",
      "[85]\ttrain's l2: 0.495047\tvalid's l2: 0.676593\n",
      "[86]\ttrain's l2: 0.492506\tvalid's l2: 0.676349\n",
      "[87]\ttrain's l2: 0.490765\tvalid's l2: 0.676796\n",
      "[88]\ttrain's l2: 0.489272\tvalid's l2: 0.676598\n",
      "[89]\ttrain's l2: 0.487342\tvalid's l2: 0.676477\n",
      "[90]\ttrain's l2: 0.485712\tvalid's l2: 0.675752\n",
      "[91]\ttrain's l2: 0.483486\tvalid's l2: 0.674692\n",
      "[92]\ttrain's l2: 0.481172\tvalid's l2: 0.673761\n",
      "[93]\ttrain's l2: 0.479285\tvalid's l2: 0.673021\n",
      "[94]\ttrain's l2: 0.477317\tvalid's l2: 0.672108\n",
      "[95]\ttrain's l2: 0.475917\tvalid's l2: 0.672074\n",
      "[96]\ttrain's l2: 0.474587\tvalid's l2: 0.672404\n",
      "[97]\ttrain's l2: 0.472875\tvalid's l2: 0.672063\n",
      "[98]\ttrain's l2: 0.471623\tvalid's l2: 0.673076\n",
      "[99]\ttrain's l2: 0.469301\tvalid's l2: 0.672021\n",
      "[100]\ttrain's l2: 0.46818\tvalid's l2: 0.671859\n",
      "Model saved to ../out/models/wine/adv-boosting_wine_B20_T100_S0050_L24_R100.model\n",
      "[1]\ttrain's l2: 0.887122\tvalid's l2: 0.915997\n",
      "[2]\ttrain's l2: 0.921332\tvalid's l2: 0.961165\n",
      "[3]\ttrain's l2: 0.888456\tvalid's l2: 0.939625\n",
      "[4]\ttrain's l2: 0.856823\tvalid's l2: 0.917155\n",
      "[5]\ttrain's l2: 0.829363\tvalid's l2: 0.897687\n",
      "[6]\ttrain's l2: 0.804651\tvalid's l2: 0.880835\n",
      "[7]\ttrain's l2: 0.779711\tvalid's l2: 0.863236\n",
      "[8]\ttrain's l2: 0.761775\tvalid's l2: 0.850524\n",
      "[9]\ttrain's l2: 0.743232\tvalid's l2: 0.838765\n",
      "[10]\ttrain's l2: 0.728473\tvalid's l2: 0.829646\n",
      "[11]\ttrain's l2: 0.714246\tvalid's l2: 0.820598\n",
      "[12]\ttrain's l2: 0.699688\tvalid's l2: 0.812374\n",
      "[13]\ttrain's l2: 0.685918\tvalid's l2: 0.804455\n",
      "[14]\ttrain's l2: 0.675316\tvalid's l2: 0.79917\n",
      "[15]\ttrain's l2: 0.660577\tvalid's l2: 0.790369\n",
      "[16]\ttrain's l2: 0.650001\tvalid's l2: 0.785999\n",
      "[17]\ttrain's l2: 0.634478\tvalid's l2: 0.775947\n",
      "[18]\ttrain's l2: 0.622889\tvalid's l2: 0.769423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19]\ttrain's l2: 0.610856\tvalid's l2: 0.763244\n",
      "[20]\ttrain's l2: 0.59842\tvalid's l2: 0.757955\n",
      "[21]\ttrain's l2: 0.587662\tvalid's l2: 0.752719\n",
      "[22]\ttrain's l2: 0.574428\tvalid's l2: 0.747934\n",
      "[23]\ttrain's l2: 0.564405\tvalid's l2: 0.745307\n",
      "[24]\ttrain's l2: 0.554743\tvalid's l2: 0.740155\n",
      "[25]\ttrain's l2: 0.548114\tvalid's l2: 0.738986\n",
      "[26]\ttrain's l2: 0.539405\tvalid's l2: 0.734961\n",
      "[27]\ttrain's l2: 0.532314\tvalid's l2: 0.731369\n",
      "[28]\ttrain's l2: 0.524669\tvalid's l2: 0.72853\n",
      "[29]\ttrain's l2: 0.518087\tvalid's l2: 0.725117\n",
      "[30]\ttrain's l2: 0.51094\tvalid's l2: 0.721837\n",
      "[31]\ttrain's l2: 0.50564\tvalid's l2: 0.719449\n",
      "[32]\ttrain's l2: 0.500871\tvalid's l2: 0.716912\n",
      "[33]\ttrain's l2: 0.497818\tvalid's l2: 0.716191\n",
      "[34]\ttrain's l2: 0.493538\tvalid's l2: 0.714281\n",
      "[35]\ttrain's l2: 0.488788\tvalid's l2: 0.711996\n",
      "[36]\ttrain's l2: 0.482259\tvalid's l2: 0.709273\n",
      "[37]\ttrain's l2: 0.478344\tvalid's l2: 0.707929\n",
      "[38]\ttrain's l2: 0.474002\tvalid's l2: 0.706022\n",
      "[39]\ttrain's l2: 0.467525\tvalid's l2: 0.703906\n",
      "[40]\ttrain's l2: 0.463749\tvalid's l2: 0.702631\n",
      "[41]\ttrain's l2: 0.46039\tvalid's l2: 0.701425\n",
      "[42]\ttrain's l2: 0.456958\tvalid's l2: 0.700317\n",
      "[43]\ttrain's l2: 0.453084\tvalid's l2: 0.699788\n",
      "[44]\ttrain's l2: 0.44944\tvalid's l2: 0.698491\n",
      "[45]\ttrain's l2: 0.445541\tvalid's l2: 0.696639\n",
      "[46]\ttrain's l2: 0.44235\tvalid's l2: 0.694981\n",
      "[47]\ttrain's l2: 0.438843\tvalid's l2: 0.693582\n",
      "[48]\ttrain's l2: 0.43435\tvalid's l2: 0.691145\n",
      "[49]\ttrain's l2: 0.427173\tvalid's l2: 0.688634\n",
      "[50]\ttrain's l2: 0.421935\tvalid's l2: 0.686946\n",
      "[51]\ttrain's l2: 0.41652\tvalid's l2: 0.685816\n",
      "[52]\ttrain's l2: 0.411953\tvalid's l2: 0.685391\n",
      "[53]\ttrain's l2: 0.408109\tvalid's l2: 0.683387\n",
      "[54]\ttrain's l2: 0.401899\tvalid's l2: 0.680799\n",
      "[55]\ttrain's l2: 0.39889\tvalid's l2: 0.679904\n",
      "[56]\ttrain's l2: 0.396165\tvalid's l2: 0.678827\n",
      "[57]\ttrain's l2: 0.393228\tvalid's l2: 0.678049\n",
      "[58]\ttrain's l2: 0.389998\tvalid's l2: 0.677064\n",
      "[59]\ttrain's l2: 0.387064\tvalid's l2: 0.676966\n",
      "[60]\ttrain's l2: 0.38389\tvalid's l2: 0.675584\n",
      "[61]\ttrain's l2: 0.381204\tvalid's l2: 0.674736\n",
      "[62]\ttrain's l2: 0.378604\tvalid's l2: 0.674272\n",
      "[63]\ttrain's l2: 0.374165\tvalid's l2: 0.67351\n",
      "[64]\ttrain's l2: 0.371793\tvalid's l2: 0.673258\n",
      "[65]\ttrain's l2: 0.368802\tvalid's l2: 0.672696\n",
      "[66]\ttrain's l2: 0.367619\tvalid's l2: 0.672905\n",
      "[67]\ttrain's l2: 0.362993\tvalid's l2: 0.670415\n",
      "[68]\ttrain's l2: 0.361264\tvalid's l2: 0.669823\n",
      "[69]\ttrain's l2: 0.358451\tvalid's l2: 0.668517\n",
      "[70]\ttrain's l2: 0.355859\tvalid's l2: 0.667629\n",
      "[71]\ttrain's l2: 0.354635\tvalid's l2: 0.668105\n",
      "[72]\ttrain's l2: 0.351727\tvalid's l2: 0.667923\n",
      "[73]\ttrain's l2: 0.349407\tvalid's l2: 0.668631\n",
      "[74]\ttrain's l2: 0.347685\tvalid's l2: 0.668256\n",
      "[75]\ttrain's l2: 0.346069\tvalid's l2: 0.668351\n",
      "[76]\ttrain's l2: 0.343301\tvalid's l2: 0.66763\n",
      "[77]\ttrain's l2: 0.341901\tvalid's l2: 0.667603\n",
      "[78]\ttrain's l2: 0.338528\tvalid's l2: 0.666669\n",
      "[79]\ttrain's l2: 0.337058\tvalid's l2: 0.666819\n",
      "[80]\ttrain's l2: 0.333758\tvalid's l2: 0.666594\n",
      "[81]\ttrain's l2: 0.333978\tvalid's l2: 0.666757\n",
      "[82]\ttrain's l2: 0.333114\tvalid's l2: 0.666672\n",
      "[83]\ttrain's l2: 0.3307\tvalid's l2: 0.665684\n",
      "[84]\ttrain's l2: 0.33065\tvalid's l2: 0.666608\n",
      "[85]\ttrain's l2: 0.329267\tvalid's l2: 0.666507\n",
      "[86]\ttrain's l2: 0.327585\tvalid's l2: 0.665534\n",
      "[87]\ttrain's l2: 0.325717\tvalid's l2: 0.664863\n",
      "[88]\ttrain's l2: 0.324979\tvalid's l2: 0.66451\n",
      "[89]\ttrain's l2: 0.32359\tvalid's l2: 0.665069\n",
      "[90]\ttrain's l2: 0.322368\tvalid's l2: 0.665036\n",
      "[91]\ttrain's l2: 0.321069\tvalid's l2: 0.664264\n",
      "[92]\ttrain's l2: 0.319382\tvalid's l2: 0.664569\n",
      "[93]\ttrain's l2: 0.317809\tvalid's l2: 0.663903\n",
      "[94]\ttrain's l2: 0.315648\tvalid's l2: 0.663832\n",
      "[95]\ttrain's l2: 0.314144\tvalid's l2: 0.663816\n",
      "[96]\ttrain's l2: 0.312624\tvalid's l2: 0.663992\n",
      "[97]\ttrain's l2: 0.312012\tvalid's l2: 0.664399\n",
      "[98]\ttrain's l2: 0.310948\tvalid's l2: 0.664784\n",
      "[99]\ttrain's l2: 0.31042\tvalid's l2: 0.665974\n",
      "[100]\ttrain's l2: 0.309724\tvalid's l2: 0.66627\n",
      "Model saved to ../out/models/wine/adv-boosting_wine_B20_T100_S0050_L256_R95.model\n",
      "  num_trees  learning_rate num_leaves best_round    metric  \\\n",
      "0       100           0.05         24        100  0.671859   \n",
      "1       100           0.05        256         95  0.663816   \n",
      "\n",
      "                                            filename  \n",
      "0  ../out/models/wine/adv-boosting_wine_B20_T100_...  \n",
      "1  ../out/models/wine/adv-boosting_wine_B20_T100_...  \n",
      "best model is: ../out/models/wine/adv-boosting_wine_B20_T100_S0050_L256_R95.model\n",
      "Pre-processing original files...\n",
      "Loading: ../data/wine/attacks/train_B40.atks.bz2\n",
      "Loading: ../data/wine/attacks/valid_B40.atks.bz2\n",
      "Loading: ../data/wine/attacks/test_B40.atks.bz2\n",
      "Train/Valid/Test sizes: (3418858, 14) (136964, 14) (404465, 14)\n",
      "Train/Valid/Test split: 0.86 0.03 0.10\n",
      "   ... with instance ids\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (3075041, 14) (480781, 14) (404465, 14)\n",
      "Train/Valid/Test split: 0.78 0.12 0.10\n",
      "Saving processed files *.atks.bz2\n",
      "[1]\ttrain's l2: 0.89492\tvalid's l2: 0.920141\n",
      "[2]\ttrain's l2: 0.934872\tvalid's l2: 0.965673\n",
      "[3]\ttrain's l2: 0.916089\tvalid's l2: 0.949527\n",
      "[4]\ttrain's l2: 0.899686\tvalid's l2: 0.932881\n",
      "[5]\ttrain's l2: 0.888595\tvalid's l2: 0.924264\n",
      "[6]\ttrain's l2: 0.879717\tvalid's l2: 0.917925\n",
      "[7]\ttrain's l2: 0.864023\tvalid's l2: 0.903615\n",
      "[8]\ttrain's l2: 0.848564\tvalid's l2: 0.891896\n",
      "[9]\ttrain's l2: 0.832874\tvalid's l2: 0.879945\n",
      "[10]\ttrain's l2: 0.819665\tvalid's l2: 0.868527\n",
      "[11]\ttrain's l2: 0.806253\tvalid's l2: 0.858738\n",
      "[12]\ttrain's l2: 0.794535\tvalid's l2: 0.848535\n",
      "[13]\ttrain's l2: 0.784506\tvalid's l2: 0.838154\n",
      "[14]\ttrain's l2: 0.782368\tvalid's l2: 0.836864\n",
      "[15]\ttrain's l2: 0.773734\tvalid's l2: 0.831693\n",
      "[16]\ttrain's l2: 0.762924\tvalid's l2: 0.823107\n",
      "[17]\ttrain's l2: 0.752041\tvalid's l2: 0.81515\n",
      "[18]\ttrain's l2: 0.741483\tvalid's l2: 0.806486\n",
      "[19]\ttrain's l2: 0.731461\tvalid's l2: 0.798397\n",
      "[20]\ttrain's l2: 0.725178\tvalid's l2: 0.794773\n",
      "[21]\ttrain's l2: 0.716013\tvalid's l2: 0.789082\n",
      "[22]\ttrain's l2: 0.707978\tvalid's l2: 0.782942\n",
      "[23]\ttrain's l2: 0.699701\tvalid's l2: 0.777256\n",
      "[24]\ttrain's l2: 0.692627\tvalid's l2: 0.773167\n",
      "[25]\ttrain's l2: 0.684686\tvalid's l2: 0.766097\n",
      "[26]\ttrain's l2: 0.677625\tvalid's l2: 0.76331\n",
      "[27]\ttrain's l2: 0.670789\tvalid's l2: 0.757904\n",
      "[28]\ttrain's l2: 0.664641\tvalid's l2: 0.753235\n",
      "[29]\ttrain's l2: 0.659059\tvalid's l2: 0.749691\n",
      "[30]\ttrain's l2: 0.653415\tvalid's l2: 0.746047\n",
      "[31]\ttrain's l2: 0.64851\tvalid's l2: 0.742731\n",
      "[32]\ttrain's l2: 0.643171\tvalid's l2: 0.738613\n",
      "[33]\ttrain's l2: 0.637754\tvalid's l2: 0.736921\n",
      "[34]\ttrain's l2: 0.632759\tvalid's l2: 0.73452\n",
      "[35]\ttrain's l2: 0.627771\tvalid's l2: 0.732271\n",
      "[36]\ttrain's l2: 0.622375\tvalid's l2: 0.728025\n",
      "[37]\ttrain's l2: 0.618592\tvalid's l2: 0.726323\n",
      "[38]\ttrain's l2: 0.614294\tvalid's l2: 0.724064\n",
      "[39]\ttrain's l2: 0.609621\tvalid's l2: 0.720598\n",
      "[40]\ttrain's l2: 0.604749\tvalid's l2: 0.717852\n",
      "[41]\ttrain's l2: 0.600882\tvalid's l2: 0.716841\n",
      "[42]\ttrain's l2: 0.596446\tvalid's l2: 0.715044\n",
      "[43]\ttrain's l2: 0.592986\tvalid's l2: 0.713631\n",
      "[44]\ttrain's l2: 0.589728\tvalid's l2: 0.711998\n",
      "[45]\ttrain's l2: 0.586097\tvalid's l2: 0.710187\n",
      "[46]\ttrain's l2: 0.582217\tvalid's l2: 0.708571\n",
      "[47]\ttrain's l2: 0.578411\tvalid's l2: 0.707618\n",
      "[48]\ttrain's l2: 0.575263\tvalid's l2: 0.705746\n",
      "[49]\ttrain's l2: 0.571091\tvalid's l2: 0.70324\n",
      "[50]\ttrain's l2: 0.56889\tvalid's l2: 0.702752\n",
      "[51]\ttrain's l2: 0.565345\tvalid's l2: 0.701001\n",
      "[52]\ttrain's l2: 0.563243\tvalid's l2: 0.700414\n",
      "[53]\ttrain's l2: 0.560642\tvalid's l2: 0.698781\n",
      "[54]\ttrain's l2: 0.557691\tvalid's l2: 0.69761\n",
      "[55]\ttrain's l2: 0.555272\tvalid's l2: 0.696738\n",
      "[56]\ttrain's l2: 0.552032\tvalid's l2: 0.695217\n",
      "[57]\ttrain's l2: 0.549337\tvalid's l2: 0.693699\n",
      "[58]\ttrain's l2: 0.54548\tvalid's l2: 0.691036\n",
      "[59]\ttrain's l2: 0.543696\tvalid's l2: 0.691626\n",
      "[60]\ttrain's l2: 0.541391\tvalid's l2: 0.691857\n",
      "[61]\ttrain's l2: 0.54136\tvalid's l2: 0.691116\n",
      "[62]\ttrain's l2: 0.540465\tvalid's l2: 0.690927\n",
      "[63]\ttrain's l2: 0.540314\tvalid's l2: 0.691165\n",
      "[64]\ttrain's l2: 0.540346\tvalid's l2: 0.691875\n",
      "[65]\ttrain's l2: 0.540359\tvalid's l2: 0.692943\n",
      "[66]\ttrain's l2: 0.539623\tvalid's l2: 0.692937\n",
      "[67]\ttrain's l2: 0.539859\tvalid's l2: 0.692584\n",
      "[68]\ttrain's l2: 0.538928\tvalid's l2: 0.692315\n",
      "[69]\ttrain's l2: 0.541285\tvalid's l2: 0.695375\n",
      "[70]\ttrain's l2: 0.53954\tvalid's l2: 0.695035\n",
      "[71]\ttrain's l2: 0.539584\tvalid's l2: 0.696647\n",
      "[72]\ttrain's l2: 0.538352\tvalid's l2: 0.696592\n",
      "[73]\ttrain's l2: 0.538036\tvalid's l2: 0.697366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[74]\ttrain's l2: 0.537951\tvalid's l2: 0.697403\n",
      "[75]\ttrain's l2: 0.53771\tvalid's l2: 0.698238\n",
      "[76]\ttrain's l2: 0.536463\tvalid's l2: 0.697508\n",
      "[77]\ttrain's l2: 0.536338\tvalid's l2: 0.697002\n",
      "[78]\ttrain's l2: 0.53523\tvalid's l2: 0.696566\n",
      "[79]\ttrain's l2: 0.535551\tvalid's l2: 0.696673\n",
      "[80]\ttrain's l2: 0.536207\tvalid's l2: 0.698159\n",
      "[81]\ttrain's l2: 0.53509\tvalid's l2: 0.697902\n",
      "[82]\ttrain's l2: 0.534719\tvalid's l2: 0.697906\n",
      "[83]\ttrain's l2: 0.534222\tvalid's l2: 0.697377\n",
      "[84]\ttrain's l2: 0.533826\tvalid's l2: 0.69826\n",
      "[85]\ttrain's l2: 0.53247\tvalid's l2: 0.698975\n",
      "[86]\ttrain's l2: 0.529953\tvalid's l2: 0.697806\n",
      "[87]\ttrain's l2: 0.52757\tvalid's l2: 0.697594\n",
      "[88]\ttrain's l2: 0.525465\tvalid's l2: 0.696221\n",
      "[89]\ttrain's l2: 0.523233\tvalid's l2: 0.696669\n",
      "[90]\ttrain's l2: 0.520592\tvalid's l2: 0.696593\n",
      "[91]\ttrain's l2: 0.518454\tvalid's l2: 0.696531\n",
      "[92]\ttrain's l2: 0.51609\tvalid's l2: 0.695657\n",
      "[93]\ttrain's l2: 0.514157\tvalid's l2: 0.695239\n",
      "[94]\ttrain's l2: 0.512081\tvalid's l2: 0.694592\n",
      "[95]\ttrain's l2: 0.509836\tvalid's l2: 0.693862\n",
      "[96]\ttrain's l2: 0.507774\tvalid's l2: 0.693204\n",
      "[97]\ttrain's l2: 0.506163\tvalid's l2: 0.692915\n",
      "[98]\ttrain's l2: 0.503971\tvalid's l2: 0.691489\n",
      "[99]\ttrain's l2: 0.501588\tvalid's l2: 0.690635\n",
      "[100]\ttrain's l2: 0.500432\tvalid's l2: 0.689871\n",
      "Model saved to ../out/models/wine/adv-boosting_wine_B40_T100_S0050_L24_R100.model\n",
      "[1]\ttrain's l2: 0.887122\tvalid's l2: 0.915997\n",
      "[2]\ttrain's l2: 0.922484\tvalid's l2: 0.96431\n",
      "[3]\ttrain's l2: 0.892646\tvalid's l2: 0.942155\n",
      "[4]\ttrain's l2: 0.870208\tvalid's l2: 0.9251\n",
      "[5]\ttrain's l2: 0.846173\tvalid's l2: 0.908334\n",
      "[6]\ttrain's l2: 0.821354\tvalid's l2: 0.890789\n",
      "[7]\ttrain's l2: 0.799759\tvalid's l2: 0.878091\n",
      "[8]\ttrain's l2: 0.774915\tvalid's l2: 0.861315\n",
      "[9]\ttrain's l2: 0.751217\tvalid's l2: 0.846681\n",
      "[10]\ttrain's l2: 0.728952\tvalid's l2: 0.832229\n",
      "[11]\ttrain's l2: 0.709981\tvalid's l2: 0.821113\n",
      "[12]\ttrain's l2: 0.691436\tvalid's l2: 0.810296\n",
      "[13]\ttrain's l2: 0.675531\tvalid's l2: 0.800863\n",
      "[14]\ttrain's l2: 0.656621\tvalid's l2: 0.79064\n",
      "[15]\ttrain's l2: 0.640644\tvalid's l2: 0.782398\n",
      "[16]\ttrain's l2: 0.627745\tvalid's l2: 0.774962\n",
      "[17]\ttrain's l2: 0.612399\tvalid's l2: 0.767494\n",
      "[18]\ttrain's l2: 0.59939\tvalid's l2: 0.761245\n",
      "[19]\ttrain's l2: 0.586998\tvalid's l2: 0.754222\n",
      "[20]\ttrain's l2: 0.57598\tvalid's l2: 0.748898\n",
      "[21]\ttrain's l2: 0.565276\tvalid's l2: 0.745466\n",
      "[22]\ttrain's l2: 0.554418\tvalid's l2: 0.741694\n",
      "[23]\ttrain's l2: 0.544685\tvalid's l2: 0.737918\n",
      "[24]\ttrain's l2: 0.537148\tvalid's l2: 0.734053\n",
      "[25]\ttrain's l2: 0.52688\tvalid's l2: 0.729367\n",
      "[26]\ttrain's l2: 0.519741\tvalid's l2: 0.726013\n",
      "[27]\ttrain's l2: 0.517177\tvalid's l2: 0.726909\n",
      "[28]\ttrain's l2: 0.509775\tvalid's l2: 0.722697\n",
      "[29]\ttrain's l2: 0.505719\tvalid's l2: 0.721201\n",
      "[30]\ttrain's l2: 0.501066\tvalid's l2: 0.721013\n",
      "[31]\ttrain's l2: 0.494682\tvalid's l2: 0.716828\n",
      "[32]\ttrain's l2: 0.492689\tvalid's l2: 0.718761\n",
      "[33]\ttrain's l2: 0.488472\tvalid's l2: 0.716205\n",
      "[34]\ttrain's l2: 0.485997\tvalid's l2: 0.715998\n",
      "[35]\ttrain's l2: 0.484826\tvalid's l2: 0.716277\n",
      "[36]\ttrain's l2: 0.480855\tvalid's l2: 0.714295\n",
      "[37]\ttrain's l2: 0.478842\tvalid's l2: 0.713609\n",
      "[38]\ttrain's l2: 0.475721\tvalid's l2: 0.713277\n",
      "[39]\ttrain's l2: 0.473114\tvalid's l2: 0.711404\n",
      "[40]\ttrain's l2: 0.470388\tvalid's l2: 0.710287\n",
      "[41]\ttrain's l2: 0.465817\tvalid's l2: 0.707319\n",
      "[42]\ttrain's l2: 0.462715\tvalid's l2: 0.707053\n",
      "[43]\ttrain's l2: 0.459918\tvalid's l2: 0.706356\n",
      "[44]\ttrain's l2: 0.457365\tvalid's l2: 0.706521\n",
      "[45]\ttrain's l2: 0.455869\tvalid's l2: 0.705883\n",
      "[46]\ttrain's l2: 0.455579\tvalid's l2: 0.706613\n",
      "[47]\ttrain's l2: 0.452193\tvalid's l2: 0.704324\n",
      "[48]\ttrain's l2: 0.448342\tvalid's l2: 0.703281\n",
      "[49]\ttrain's l2: 0.444228\tvalid's l2: 0.701136\n",
      "[50]\ttrain's l2: 0.4398\tvalid's l2: 0.699739\n",
      "[51]\ttrain's l2: 0.439475\tvalid's l2: 0.700469\n",
      "[52]\ttrain's l2: 0.437215\tvalid's l2: 0.700697\n",
      "[53]\ttrain's l2: 0.431459\tvalid's l2: 0.697592\n",
      "[54]\ttrain's l2: 0.427839\tvalid's l2: 0.695286\n",
      "[55]\ttrain's l2: 0.424453\tvalid's l2: 0.693519\n",
      "[56]\ttrain's l2: 0.420588\tvalid's l2: 0.693058\n",
      "[57]\ttrain's l2: 0.416444\tvalid's l2: 0.69101\n",
      "[58]\ttrain's l2: 0.412184\tvalid's l2: 0.688676\n",
      "[59]\ttrain's l2: 0.40909\tvalid's l2: 0.6874\n",
      "[60]\ttrain's l2: 0.406407\tvalid's l2: 0.686879\n",
      "[61]\ttrain's l2: 0.403945\tvalid's l2: 0.686489\n",
      "[62]\ttrain's l2: 0.401432\tvalid's l2: 0.685796\n",
      "[63]\ttrain's l2: 0.398434\tvalid's l2: 0.684806\n",
      "[64]\ttrain's l2: 0.395545\tvalid's l2: 0.6844\n",
      "[65]\ttrain's l2: 0.393161\tvalid's l2: 0.684162\n",
      "[66]\ttrain's l2: 0.38977\tvalid's l2: 0.684003\n",
      "[67]\ttrain's l2: 0.387503\tvalid's l2: 0.684667\n",
      "[68]\ttrain's l2: 0.385981\tvalid's l2: 0.68435\n",
      "[69]\ttrain's l2: 0.383289\tvalid's l2: 0.683657\n",
      "[70]\ttrain's l2: 0.379945\tvalid's l2: 0.683613\n",
      "[71]\ttrain's l2: 0.378979\tvalid's l2: 0.68303\n",
      "[72]\ttrain's l2: 0.377287\tvalid's l2: 0.682677\n",
      "[73]\ttrain's l2: 0.37424\tvalid's l2: 0.681187\n",
      "[74]\ttrain's l2: 0.372053\tvalid's l2: 0.680795\n",
      "[75]\ttrain's l2: 0.368543\tvalid's l2: 0.679803\n",
      "[76]\ttrain's l2: 0.366831\tvalid's l2: 0.679825\n",
      "[77]\ttrain's l2: 0.365281\tvalid's l2: 0.679569\n",
      "[78]\ttrain's l2: 0.364216\tvalid's l2: 0.67918\n",
      "[79]\ttrain's l2: 0.362151\tvalid's l2: 0.678662\n",
      "[80]\ttrain's l2: 0.360618\tvalid's l2: 0.677939\n",
      "[81]\ttrain's l2: 0.359827\tvalid's l2: 0.677816\n",
      "[82]\ttrain's l2: 0.358783\tvalid's l2: 0.677546\n",
      "[83]\ttrain's l2: 0.357766\tvalid's l2: 0.67797\n",
      "[84]\ttrain's l2: 0.356028\tvalid's l2: 0.677725\n",
      "[85]\ttrain's l2: 0.354445\tvalid's l2: 0.677542\n",
      "[86]\ttrain's l2: 0.353719\tvalid's l2: 0.677798\n",
      "[87]\ttrain's l2: 0.350711\tvalid's l2: 0.676912\n",
      "[88]\ttrain's l2: 0.349158\tvalid's l2: 0.676872\n",
      "[89]\ttrain's l2: 0.347935\tvalid's l2: 0.676357\n",
      "[90]\ttrain's l2: 0.344109\tvalid's l2: 0.67511\n",
      "[91]\ttrain's l2: 0.342996\tvalid's l2: 0.675415\n",
      "[92]\ttrain's l2: 0.342201\tvalid's l2: 0.675466\n",
      "[93]\ttrain's l2: 0.33976\tvalid's l2: 0.674977\n",
      "[94]\ttrain's l2: 0.339042\tvalid's l2: 0.674253\n",
      "[95]\ttrain's l2: 0.337437\tvalid's l2: 0.674523\n",
      "[96]\ttrain's l2: 0.336545\tvalid's l2: 0.674484\n",
      "[97]\ttrain's l2: 0.334906\tvalid's l2: 0.674389\n",
      "[98]\ttrain's l2: 0.332473\tvalid's l2: 0.673863\n",
      "[99]\ttrain's l2: 0.330681\tvalid's l2: 0.674206\n",
      "[100]\ttrain's l2: 0.329478\tvalid's l2: 0.674194\n",
      "Model saved to ../out/models/wine/adv-boosting_wine_B40_T100_S0050_L256_R98.model\n",
      "  num_trees  learning_rate num_leaves best_round    metric  \\\n",
      "0       100           0.05         24        100  0.689871   \n",
      "1       100           0.05        256         98  0.673863   \n",
      "\n",
      "                                            filename  \n",
      "0  ../out/models/wine/adv-boosting_wine_B40_T100_...  \n",
      "1  ../out/models/wine/adv-boosting_wine_B40_T100_...  \n",
      "best model is: ../out/models/wine/adv-boosting_wine_B40_T100_S0050_L256_R98.model\n"
     ]
    }
   ],
   "source": [
    "for B in TRAINING_BUDGETS:\n",
    "\n",
    "        experiments = train_adversarial_boosting(TRAINING_FILENAME_ATT.format(B),\n",
    "                                                 VALIDATION_FILENAME_ATT.format(B),\n",
    "                                                 TEST_FILENAME_ATT.format(B),\n",
    "                                                 MODEL_FILENAME.format(DATASET_NAME, B))  \n",
    "\n",
    "        experiments.to_csv(MODEL_FILENAME.format(DATASET_NAME, B) + \".csv\", index=False)\n",
    "\n",
    "        print(experiments)\n",
    "        print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"census\"\n",
    "TRAINING_BUDGETS= [30, 60]\n",
    "\n",
    "DATASET_DIR=\"../data/{}\".format(DATASET_NAME)\n",
    "ATK_DIR=DATASET_DIR + \"/attacks\"\n",
    "MODELS_DIR=\"../out/models/{}\".format(DATASET_NAME)\n",
    "TRAINING_FILENAME=DATASET_DIR + \"/\" + \"train.csv.bz2\"\n",
    "TRAINING_FILENAME_ATT=ATK_DIR + \"/\" + \"train_B{}.atks.bz2\"\n",
    "VALIDATION_FILENAME=DATASET_DIR + \"/\" + \"valid.csv.bz2\"\n",
    "VALIDATION_FILENAME_ATT=ATK_DIR + \"/\" + \"valid_B{}.atks.bz2\"\n",
    "TEST_FILENAME=DATASET_DIR + \"/\" + \"test.csv.bz2\"\n",
    "TEST_FILENAME_ATT=ATK_DIR + \"/\" + \"test_B{}.atks.bz2\"\n",
    "MODEL_FILENAME=MODELS_DIR + \"/adv-boosting_{}_B{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for B in TRAINING_BUDGETS:\n",
    "\n",
    "        experiments = train_adversarial_boosting(TRAINING_FILENAME_ATT.format(B),\n",
    "                                                 VALIDATION_FILENAME_ATT.format(B),\n",
    "                                                 TEST_FILENAME_ATT.format(B),\n",
    "                                                 MODEL_FILENAME.format(DATASET_NAME, B))  \n",
    "\n",
    "        experiments.to_csv(MODEL_FILENAME.format(DATASET_NAME, B) + \".csv\", index=False)\n",
    "\n",
    "        print(experiments)\n",
    "        print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
