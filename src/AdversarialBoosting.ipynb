{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "\n",
    " - http://lightgbm.readthedocs.io/en/latest/\n",
    " - http://lightgbm.readthedocs.io/en/latest/Python-Intro.html\n",
    " - https://github.com/Microsoft/LightGBM/tree/master/examples/python-guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm\n",
    "import pickle\n",
    "import json\n",
    "import functools\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from nilib import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_adv_boosting_data(model, data, groups, num_atks=1):\n",
    "    ''' \n",
    "    model  : is the LightGBM Model\n",
    "    data   : data matrix with all valid attacks (last column is label)\n",
    "    groups : grouping of same attacked instance \n",
    "    returns the new data matrix and new groups\n",
    "    \n",
    "    WARNING: currently works only for binary classification\n",
    "    '''\n",
    "    # score the datataset\n",
    "    labels = data.iloc[:,-1]\n",
    "    \n",
    "    # check mispredictions\n",
    "    predictions = model.predict(data.iloc[:,:-1]) # exclude labels\n",
    "    matchings = labels * predictions\n",
    "    \n",
    "    # select original data + attacked instances\n",
    "    new_selected = [] # id of selected instances\n",
    "    new_groups   = []\n",
    "    \n",
    "    offset = 0\n",
    "    for g in groups:\n",
    "        if g==0:\n",
    "            print (\"Error !!!!\")\n",
    "        elif g==1:\n",
    "            # there are no attacks, just add original\n",
    "            new_selected += [offset]\n",
    "            new_groups   += [1]\n",
    "        else:\n",
    "            # get a slice of the matching scores\n",
    "            g_matchings = matchings[offset:offset+g]\n",
    "\n",
    "            # most misclassified (smallest margin)\n",
    "            # skip original\n",
    "            #adv_instance = np.argmin(g_matchings[1:])+1\n",
    "            adv_instances = np.argsort(g_matchings[1:])\n",
    "            adv_instances = adv_instances[:num_atks]\n",
    "            adv_instances += offset +1\n",
    "\n",
    "            # add original and adversarial\n",
    "            new_selected += [offset] + list(adv_instances)\n",
    "            new_groups   += [1 + len(adv_instances)]\n",
    "        \n",
    "        offset += g\n",
    "    \n",
    "    new_dataset = data.iloc[new_selected,:]\n",
    "    \n",
    "    return new_dataset, new_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_adv_boosting_model(train, valid, input_model=None, num_trees=1, params=None):\n",
    "    ''' \n",
    "    model  : is the LightGBM Model\n",
    "    data   : data matrix with all valid attacks (last column is label)\n",
    "    returns the new model (is model modified inplace?)\n",
    "    '''\n",
    "    \n",
    "    assert train.shape[1]==valid.shape[1], \"Train/Valid Mismatch!\"\n",
    "\n",
    "    lgbm_train = lightgbm.Dataset(data=train.iloc[:,:-1], \n",
    "                                  label=train.iloc[:,-1])\n",
    "    \n",
    "    lgbm_valid = lightgbm.Dataset(data=valid.iloc[:,:-1], \n",
    "                                  label=valid.iloc[:,-1])\n",
    "    \n",
    "    lgbm_info = {}\n",
    "    lgbm_model = lightgbm.train(params, lgbm_train, \n",
    "                                num_boost_round = num_trees, \n",
    "                                init_model = input_model,\n",
    "#                                 fobj = optimize_log_loss,\n",
    "#                                 feval = avg_log_loss,\n",
    "                                evals_result = lgbm_info,\n",
    "                                valid_sets   = [lgbm_train, lgbm_valid], \n",
    "                                valid_names  = ['train', 'valid'],\n",
    "                                verbose_eval=20)\n",
    "\n",
    "    return lgbm_model, lgbm_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdvBoosting(atk_train, atk_valid, trees,\n",
    "                 params,\n",
    "                 output_model_file,\n",
    "                 partial_save=1000, \n",
    "                 adv_rounds=1):\n",
    "    ''' \n",
    "    atk_data: full dataset including all valid attacks\n",
    "    atk_groups: lenght of each attack set\n",
    "    trees: total number of trees to be produced\n",
    "    adv_rounds: adversarial instance injecting frequency\n",
    "    '''\n",
    "    # temp lgbm file\n",
    "    temp = output_model_file+\".tmp\"\n",
    "    \n",
    "    # get groups and remove instance ids\n",
    "    atk_groups = atk_train['instance_id'].value_counts().sort_index().values\n",
    "    atk_valid_groups = atk_valid['instance_id'].value_counts().sort_index().values\n",
    "    \n",
    "    # prepare data (avoiding pandas)\n",
    "    atk_data   = atk_train.iloc[:,1:] #.values\n",
    "    atk_valid  = atk_valid.iloc[:,1:] #.values\n",
    "\n",
    "    # train first trees\n",
    "    original_ids = np.cumsum(atk_groups[:-1])\n",
    "    original_ids = np.insert(original_ids, 0, 0)\n",
    "    \n",
    "    original_valid_ids = np.cumsum(atk_valid_groups[:-1])\n",
    "    original_valid_ids = np.insert(original_valid_ids, 0, 0)\n",
    "    \n",
    "    model, model_info = extend_adv_boosting_model(atk_data.iloc[original_ids, :], \n",
    "                                                  atk_valid.iloc[original_valid_ids, :],\n",
    "                                                  input_model=None, \n",
    "                                                  num_trees=adv_rounds, \n",
    "                                                  params=params)\n",
    "    \n",
    "    adopted_metric = list(model_info['valid'].keys())[0] #'avg_binary_log_loss', 'l2'    \n",
    "    best_model = model\n",
    "    best_info  = model_info\n",
    "    best_loss  = np.min(model_info['valid'][adopted_metric])\n",
    "    best_round = 1\n",
    "        \n",
    "    # train remaining trees\n",
    "    for t in range(adv_rounds+1, trees+1, adv_rounds):\n",
    "        # attack dataset\n",
    "        adv_data, _       = gen_adv_boosting_data(model, atk_data, atk_groups)\n",
    "        adv_valid_data, _ = gen_adv_boosting_data(model, atk_valid, atk_valid_groups)\n",
    "        \n",
    "        # train additional trees\n",
    "        model.save_model(temp)\n",
    "        model, model_info = extend_adv_boosting_model(adv_data, \n",
    "                                                      adv_valid_data,\n",
    "                                                      input_model=temp, \n",
    "                                                      num_trees=adv_rounds, \n",
    "                                                      params=params)\n",
    "\n",
    "        if np.min(model_info['valid'][adopted_metric]) < best_loss:\n",
    "            best_model = model\n",
    "            best_info  = model_info\n",
    "            best_loss  = np.min(model_info['valid'][adopted_metric])\n",
    "            best_round = t\n",
    "            \n",
    "    \n",
    "    return best_model, best_info, best_loss, best_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adversarial_boosting(train_file, valid_file, test_file, output_model_file):\n",
    "    \n",
    "    exp = pd.DataFrame(columns=['num_trees', 'learning_rate', 'num_leaves', 'best_round', 'metric', 'filename'])\n",
    "    \n",
    "    # load train/valid/test\n",
    "    train, valid, test = load_atk_train_valid_test(train_file, valid_file, test_file)\n",
    "    \n",
    "    # train = train.iloc[:1000, :]\n",
    "    \n",
    "    assert \"instance_id\" in train.columns.values, \"Wrong training set file for GBDT\"\n",
    "\n",
    "    for num_trees in [100]:\n",
    "        for learning_rate in [0.05]: #[0.01, 0.05]:\n",
    "            for num_leaves in [2**8]: #[16, 24]:\n",
    "                      \n",
    "                lgbm_params = { 'learning_rate': learning_rate, \n",
    "                                'num_leaves': num_leaves , \n",
    "                                'max_depth': 8,\n",
    "                                'objective': 'regression'\n",
    "                              } \n",
    "                \n",
    "                lgbm_model, lgbm_info, best_loss, best_valid_iter = AdvBoosting(train,\n",
    "                                                    valid,\n",
    "                                                    trees=num_trees,\n",
    "                                                    output_model_file=output_model_file, \n",
    "                                                    adv_rounds=1,\n",
    "                                                    params=lgbm_params)\n",
    "                \n",
    "                # save file\n",
    "                model_file_name = \"{:s}_T{:d}_S{:04d}_L{:d}_R{:d}.model\".format(output_model_file,\n",
    "                                                                                        num_trees,\n",
    "                                                                                        int(learning_rate*1000),\n",
    "                                                                                        num_leaves,\n",
    "                                                                                        best_valid_iter\n",
    "                                                                                       )\n",
    "                ####\n",
    "                # update experimental results\n",
    "                exp = exp.append({'num_trees': num_trees, \n",
    "                                  'learning_rate':learning_rate,\n",
    "                                  'num_leaves':num_leaves, \n",
    "                                  'best_round':best_valid_iter, \n",
    "                                  'metric':best_loss,\n",
    "                                  'filename': model_file_name},\n",
    "                                 ignore_index=True)\n",
    "        \n",
    "                lgbm_model.save_model(model_file_name)\n",
    "                print (\"Model saved to\", model_file_name)\n",
    "                \n",
    "    return exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WINE Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"wine\"\n",
    "TRAINING_BUDGETS= [10, 20]\n",
    "\n",
    "DATASET_DIR=\"../data/{}\".format(DATASET_NAME)\n",
    "ATK_DIR=DATASET_DIR + \"/attacks\"\n",
    "MODELS_DIR=\"../out/models/{}\".format(DATASET_NAME)\n",
    "TRAINING_FILENAME=DATASET_DIR + \"/\" + \"train.csv.bz2\"\n",
    "TRAINING_FILENAME_ATT=ATK_DIR + \"/\" + \"train_B{}.atks.bz2\"\n",
    "VALIDATION_FILENAME=DATASET_DIR + \"/\" + \"valid.csv.bz2\"\n",
    "VALIDATION_FILENAME_ATT=ATK_DIR + \"/\" + \"valid_B{}.atks.bz2\"\n",
    "TEST_FILENAME=DATASET_DIR + \"/\" + \"test.csv.bz2\"\n",
    "TEST_FILENAME_ATT=ATK_DIR + \"/\" + \"test_B{}.atks.bz2\"\n",
    "MODEL_FILENAME=MODELS_DIR + \"/adv-boosting_{}_B{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for B in TRAINING_BUDGETS:\n",
    "\n",
    "        experiments = train_adversarial_boosting(TRAINING_FILENAME_ATT.format(B),\n",
    "                                                 VALIDATION_FILENAME_ATT.format(B),\n",
    "                                                 TEST_FILENAME_ATT.format(B),\n",
    "                                                 MODEL_FILENAME.format(DATASET_NAME, B))  \n",
    "\n",
    "        experiments.to_csv(MODEL_FILENAME.format(DATASET_NAME, B) + \".csv\", index=False)\n",
    "\n",
    "        print(experiments)\n",
    "        print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CENSUS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"census\"\n",
    "TRAINING_BUDGETS= [90]\n",
    "\n",
    "DATASET_DIR=\"../data/{}\".format(DATASET_NAME)\n",
    "ATK_DIR=DATASET_DIR + \"/attacks\"\n",
    "MODELS_DIR=\"../out/models/{}\".format(DATASET_NAME)\n",
    "TRAINING_FILENAME=DATASET_DIR + \"/\" + \"train.csv.bz2\"\n",
    "TRAINING_FILENAME_ATT=ATK_DIR + \"/\" + \"train_B{}.atks.bz2\"\n",
    "VALIDATION_FILENAME=DATASET_DIR + \"/\" + \"valid.csv.bz2\"\n",
    "VALIDATION_FILENAME_ATT=ATK_DIR + \"/\" + \"valid_B{}.atks.bz2\"\n",
    "TEST_FILENAME=DATASET_DIR + \"/\" + \"test.csv.bz2\"\n",
    "TEST_FILENAME_ATT=ATK_DIR + \"/\" + \"test_B{}.atks.bz2\"\n",
    "MODEL_FILENAME=MODELS_DIR + \"/adv-boosting_{}_B{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for B in TRAINING_BUDGETS:\n",
    "\n",
    "        experiments = train_adversarial_boosting(TRAINING_FILENAME_ATT.format(B),\n",
    "                                                 VALIDATION_FILENAME_ATT.format(B),\n",
    "                                                 TEST_FILENAME_ATT.format(B),\n",
    "                                                 MODEL_FILENAME.format(DATASET_NAME, B))  \n",
    "\n",
    "        experiments.to_csv(MODEL_FILENAME.format(DATASET_NAME, B) + \".csv\", index=False)\n",
    "\n",
    "        print(experiments)\n",
    "        print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREDIT Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"credit\"\n",
    "TRAINING_BUDGETS= [10,30,60]\n",
    "\n",
    "DATASET_DIR=\"../data/{}\".format(DATASET_NAME)\n",
    "ATK_DIR=DATASET_DIR + \"/attacks\"\n",
    "MODELS_DIR=\"../out/models/{}\".format(DATASET_NAME)\n",
    "TRAINING_FILENAME=DATASET_DIR + \"/\" + \"train.csv.bz2\"\n",
    "TRAINING_FILENAME_ATT=ATK_DIR + \"/\" + \"train_B{}.atks.bz2\"\n",
    "VALIDATION_FILENAME=DATASET_DIR + \"/\" + \"valid.csv.bz2\"\n",
    "VALIDATION_FILENAME_ATT=ATK_DIR + \"/\" + \"valid_B{}.atks.bz2\"\n",
    "TEST_FILENAME=DATASET_DIR + \"/\" + \"test.csv.bz2\"\n",
    "TEST_FILENAME_ATT=ATK_DIR + \"/\" + \"test_B{}.atks.bz2\"\n",
    "MODEL_FILENAME=MODELS_DIR + \"/adv-boosting_{}_B{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing original files...\n",
      "Loading: ../data/credit/attacks/train_B10.atks.bz2\n",
      "Loading: ../data/credit/attacks/valid_B10.atks.bz2\n",
      "Loading: ../data/credit/attacks/test_B10.atks.bz2\n",
      "Train/Valid/Test sizes: (55231, 25) (17006, 25) (19669, 25)\n",
      "Train/Valid/Test split: 0.60 0.19 0.21\n",
      "   ... with instance ids\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (62575, 25) (13186, 25) (16145, 25)\n",
      "Train/Valid/Test split: 0.68 0.14 0.18\n",
      "Saving processed files *.atks.bz2\n",
      "[20]\ttrain's l2: 0.513871\tvalid's l2: 0.54948\n",
      "[40]\ttrain's l2: 0.42955\tvalid's l2: 0.528264\n",
      "[60]\ttrain's l2: 0.383467\tvalid's l2: 0.527033\n",
      "[80]\ttrain's l2: 0.360219\tvalid's l2: 0.527755\n",
      "[100]\ttrain's l2: 0.340352\tvalid's l2: 0.532288\n",
      "Model saved to ../out/models/credit/adv-boosting_credit_B10_T100_S0050_L256_R63.model\n",
      "  num_trees  learning_rate num_leaves best_round    metric  \\\n",
      "0       100           0.05        256         63  0.526665   \n",
      "\n",
      "                                            filename  \n",
      "0  ../out/models/credit/adv-boosting_credit_B10_T...  \n",
      "best model is: ../out/models/credit/adv-boosting_credit_B10_T100_S0050_L256_R63.model\n",
      "Pre-processing original files...\n",
      "Loading: ../data/credit/attacks/train_B30.atks.bz2\n",
      "Loading: ../data/credit/attacks/valid_B30.atks.bz2\n",
      "Loading: ../data/credit/attacks/test_B30.atks.bz2\n",
      "Train/Valid/Test sizes: (335485, 25) (86263, 25) (101448, 25)\n",
      "Train/Valid/Test split: 0.64 0.16 0.19\n",
      "   ... with instance ids\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (379024, 25) (60308, 25) (83864, 25)\n",
      "Train/Valid/Test split: 0.72 0.12 0.16\n",
      "Saving processed files *.atks.bz2\n",
      "[20]\ttrain's l2: 0.553664\tvalid's l2: 0.566259\n",
      "[40]\ttrain's l2: 0.484504\tvalid's l2: 0.546653\n",
      "[60]\ttrain's l2: 0.433587\tvalid's l2: 0.547239\n",
      "[80]\ttrain's l2: 0.402527\tvalid's l2: 0.548698\n",
      "[100]\ttrain's l2: 0.382457\tvalid's l2: 0.552958\n",
      "Model saved to ../out/models/credit/adv-boosting_credit_B30_T100_S0050_L256_R44.model\n",
      "  num_trees  learning_rate num_leaves best_round    metric  \\\n",
      "0       100           0.05        256         44  0.545086   \n",
      "\n",
      "                                            filename  \n",
      "0  ../out/models/credit/adv-boosting_credit_B30_T...  \n",
      "best model is: ../out/models/credit/adv-boosting_credit_B30_T100_S0050_L256_R44.model\n",
      "Pre-processing original files...\n",
      "Loading: ../data/credit/attacks/train_B60.atks.bz2\n",
      "Loading: ../data/credit/attacks/valid_B60.atks.bz2\n",
      "Loading: ../data/credit/attacks/test_B60.atks.bz2\n",
      "Train/Valid/Test sizes: (1130917, 25) (221334, 25) (262472, 25)\n",
      "Train/Valid/Test split: 0.70 0.14 0.16\n",
      "   ... with instance ids\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (1259129, 25) (141715, 25) (213879, 25)\n",
      "Train/Valid/Test split: 0.78 0.09 0.13\n",
      "Saving processed files *.atks.bz2\n",
      "[20]\ttrain's l2: 0.578514\tvalid's l2: 0.593459\n",
      "[40]\ttrain's l2: 0.489067\tvalid's l2: 0.584515\n",
      "[60]\ttrain's l2: 0.445667\tvalid's l2: 0.588105\n",
      "[80]\ttrain's l2: 0.418165\tvalid's l2: 0.590029\n",
      "[100]\ttrain's l2: 0.401542\tvalid's l2: 0.593273\n",
      "Model saved to ../out/models/credit/adv-boosting_credit_B60_T100_S0050_L256_R43.model\n",
      "  num_trees  learning_rate num_leaves best_round    metric  \\\n",
      "0       100           0.05        256         43  0.583272   \n",
      "\n",
      "                                            filename  \n",
      "0  ../out/models/credit/adv-boosting_credit_B60_T...  \n",
      "best model is: ../out/models/credit/adv-boosting_credit_B60_T100_S0050_L256_R43.model\n"
     ]
    }
   ],
   "source": [
    "for B in TRAINING_BUDGETS:\n",
    "\n",
    "        experiments = train_adversarial_boosting(TRAINING_FILENAME_ATT.format(B),\n",
    "                                                 VALIDATION_FILENAME_ATT.format(B),\n",
    "                                                 TEST_FILENAME_ATT.format(B),\n",
    "                                                 MODEL_FILENAME.format(DATASET_NAME, B))  \n",
    "\n",
    "        experiments.to_csv(MODEL_FILENAME.format(DATASET_NAME, B) + \".csv\", index=False)\n",
    "\n",
    "        print(experiments)\n",
    "        print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
